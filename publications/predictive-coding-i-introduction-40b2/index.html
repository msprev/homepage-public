<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Predictive coding I: Introduction | Mark Sprevak</title>
        <meta name="description" content="">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" href="https://marksprevak.com/kube/css/kube.min.css" />
<link rel="stylesheet" href="https://marksprevak.com/css-customisations/sprevak.css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<title>Mark Sprevak</title>
<base href="https://marksprevak.com/">
<link rel="canonical" href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,700%7CLato:400,700" rel="stylesheet">

    </head>
    <body>
        <div class="page wrapper">

            <header class="header">
                <div class="is-navbar-container" style="padding-bottom: 6px; padding-top: 0px; border-bottom: 1px solid; border-color: rgba(0, 0, 0, 0.3);">
    <div class="is-brand">
        <div class="titlebar"><a href="https://marksprevak.com/">Mark&nbsp;Sprevak</a></div>
        
        <a href="#"
                style="color: rgba(0, 0, 0, 0.8); text-decoration: none; border-bottom: none; font-size:18px;"
                class="is-hidden-print nav-toggle is-push-right-mobile is-shown-mobile icon-kube-menu"
                data-kube="toggle"
                data-target="#top-navbar"></a>
    </div>
    <div id="top-navbar" class="is-navbar is-hidden-print is-hidden-mobile">
        <nav class="is-push-right">
            <ul style="text-align: right;">
                
                
                
                
                
                <li  >
                    <a href="https://marksprevak.com/publications/" style="text-decoration: none; border-bottom: none;">Publications</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/talks/" style="text-decoration: none; border-bottom: none;">Talks</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/outreach/" style="text-decoration: none; border-bottom: none;">Outreach</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/extras/" style="text-decoration: none; border-bottom: none;">Extras</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/cv/" style="text-decoration: none; border-bottom: none;">CV</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/phds/" style="text-decoration: none; border-bottom: none;">PhD study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/mscs/" style="text-decoration: none; border-bottom: none;">MSc study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/teaching/" style="text-decoration: none; border-bottom: none;">Teaching</a>
                </li>
                
                
            </ul>
        </nav>
    </div>
</div>

            </header>

            <main class="main">
                <div class="is-row">

                    <div class="is-col is-67">     

                        <div style="padding-bottom: 30px;">
                            <div style="margin-bottom: 10px;">
                                <h1 class="is-color-black" style="margin-top: 0px; margin-bottom: 0px;">Predictive coding I: Introduction</h1>
                                
                                <p class="is-muted" style="margin-top: 10px;">
                                    
                                        2024  &nbsp;
                                    
                                    <em>Philosophy Compass</em>, e12950
                                </p>
                                <p class="is-small" style="margin-top: 10px;">
                                    <span>Last updated 20 March 2024</span>
                                    
                                </p>
                            </div>
                            <div class="is-hidden-print">
                                
<a href="https://marksprevak.com/pdf/paper/Sprevak--Predictive-Coding-1-Introduction.pdf" target="_blank" class="label is-primary is-focus" style="margin-left: 0px; margin-right:5px;">
    <i class="far fa-file-pdf" style="font-size: 12px;"></i>
    &nbsp;PDF
</a>




<a href="https://dx.doi.org/10.1111/phc3.12950" target="_blank" class="label is-tertiary is-focus" style="margin-left: 0; padding-left: 0; margin-right:2px;">
    doi&nbsp;
    <i class="fas fa-external-link-alt"></i>
</a>


                            </div>
                        </div>

                        <div class="is-hidden-mobile">
                            
                            <div class="article-style" style="margin-left: 30px; margin-right: 30px; margin-bottom: 30px;">
                                <p>Predictive coding – sometimes also known as ‘predictive processing’,
‘free energy minimisation’, or ‘prediction error minimisation’ – claims
to offer a complete, unified theory of cognition that stretches all the
way from cellular biology to phenomenology. However, the exact content
of the view, and how it might achieve its ambitions, is not clear. This
series of articles examines predictive coding and attempts to identify
its key commitments and justification. The present article begins by
focusing on possible confounds with predictive coding: claims that are
often identified with predictive coding, but which are not predictive
coding. These include the idea that the brain employs an efficient
scheme for encoding its incoming sensory signals; that perceptual
experience is shaped by prior beliefs; that cognition involves
minimisation of prediction error; that the brain is a probabilistic
inference engine; and that the brain learns and employs a generative
model of the world. These ideas have garnered widespread support in
modern cognitive neuroscience, but it is important not to conflate them
with predictive coding.</p>

                            </div>
                            
                        </div>
                        <div class="is-shown-mobile">
                            
                            
                            <div class="is-hidden-print" style="border-bottom: 0; margin-top: 5px; padding-bottom: 10px; padding-right: 20px; width:33%; float: left;">
                                <img src="https://marksprevak.com/img/pubs/phil-compass.jpg" alt="">
                            </div>
                            
                            <div class="is-muted is-smaller is-hidden-print">
                                Abstract:
                            </div>
                            <div class="article-style" style="margin-bottom: 30px;">
                                <p>Predictive coding – sometimes also known as ‘predictive processing’,
‘free energy minimisation’, or ‘prediction error minimisation’ – claims
to offer a complete, unified theory of cognition that stretches all the
way from cellular biology to phenomenology. However, the exact content
of the view, and how it might achieve its ambitions, is not clear. This
series of articles examines predictive coding and attempts to identify
its key commitments and justification. The present article begins by
focusing on possible confounds with predictive coding: claims that are
often identified with predictive coding, but which are not predictive
coding. These include the idea that the brain employs an efficient
scheme for encoding its incoming sensory signals; that perceptual
experience is shaped by prior beliefs; that cognition involves
minimisation of prediction error; that the brain is a probabilistic
inference engine; and that the brain learns and employs a generative
model of the world. These ideas have garnered widespread support in
modern cognitive neuroscience, but it is important not to conflate them
with predictive coding.</p>

                            </div>
                            
                        </div>

                        <div>
                            
                            <div class="is-shown-mobile">
                                
                                    <h1 style="margin-top: 0px;" id="internal-mds-toc">Contents</h1>
                                    <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#efficient-neural-coding"><span style="visibility: visible;">2</span> &nbsp;  Efficient neural coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#top-down-expectation-driven-effects-in-perception"><span style="visibility: visible;">3</span> &nbsp;  Top-down, expectation-driven effects in perception</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#minimising-prediction-error"><span style="visibility: visible;">4</span> &nbsp;  Minimising prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#cognition-as-a-form-of-probabilistic-inference"><span style="visibility: visible;">5</span> &nbsp;  Cognition as a form of probabilistic inference</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#cognition-uses-a-generative-model"><span style="visibility: visible;">6</span> &nbsp;  Cognition uses a generative model</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#conclusion"><span style="visibility: visible;">7</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                                
                                
                            </div>
                            <div class="article-style">
                                <div>
<h1 data-number="1" id="introduction"><span
class="header-section-number">1</span> Introduction</h1>
<p>Predictive coding is a computational model of cognition. Like other
computational models, it attempts to explain human thought and behaviour
in terms of computations performed by the brain. It differs from more
traditional approaches in at least three respects. First, it aspires to
be <em>comprehensive</em>: it aims to explain, not just one domain of
human cognition, but all of it – perception, motor control, decision
making, planning, reasoning, attention, and so on. Second, it aims to
<em>unify</em>: rather than explain cognition in terms of many different
kinds of computation, it explains by appeal to a single, unified
computation – one computational task and one computational algorithm are
claimed to underlie all aspects of cognition. Third, it aims to be
<em>complete</em>: it offers not just part of the story about cognition,
but one that stretches all the way from the details of neuromodulator
release to abstract principles of rational action governing whole
agents.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<p>However, understanding precisely what predictive coding says, and
whether it can achieve these ambitions, is not straightforward. For one
thing, the term ‘predictive coding’ means different things to different
people.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> For another, important features of
the view, whatever its name, are liable to change or are underspecified
in important respects. In this article and those that follow it, my aim
is to sketch what predictive coding is, and how it might fulfil these
ambitions.</p>
<p>I argue that predictive coding should be understood as a loose
alliance of three claims. These claims, each of which may be precisified
or qualified in variety of ways, are made at Marr’s
<em>computational</em>, <em>algorithmic</em>, and
<em>implementation</em> levels of description.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> At
Marr’s computational level, the claim is that the computational
<em>task</em> facing the brain is to minimise sensory prediction error.
At the algorithmic level, the claim is that the <em>algorithm</em> by
which our brain attempts to solve this task involves the action of a
hierarchical network of abstract prediction and error units. This
network may be viewed, in a further step, as running a variational
algorithm for approximate Bayesian inference. At Marr’s implementation
level, the claim is that the <em>physical resources</em> that implement
the algorithm are primarily located in the neocortex: anatomically
distinct cell populations inside neocortical areas implement distinct
prediction and error units.</p>
<p>Each of these claims needs to be qualified in certain respects and
supplemented by further details. Each needs to be stated more precisely
and ideally associated with a quantitative mathematical formalisation. A
path needs to be forged from the claims to supporting empirical
evidence. Finally, one needs to show that the resultant model delivers
the kinds of benefits originally promised – a comprehensive, unifying,
and complete account of cognition. Different researchers within the
predictive coding community have different opinions about how to do
this, and many details are currently left open. This means that the
exact commitments of predictive coding are, to put it mildly,
contentious. For these reasons, it is more accurate to think of
predictive coding as an ongoing research programme rather than a mature
theory that can be fully stated now. The aim of the research programme
is to articulate and defend some sophisticated – likely heavily modified
and precisified – descendent of the three claims above. As with any such
programme, the merits of predictive coding should be judged in the round
and, to some degree, prospectively: not just in terms of the raw
predictive power and confirmation of what it says now, but also in terms
of its future potential, and its ability to inspire and guide fruitful
research.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></p>
<p>Before saying what predictive coding is, it is first helpful to say
what it is not. In this article, I outline five ideas that are often
presented alongside predictive coding, but which should be distinguished
from it. In the three articles that follow, I focus primarily on the
positive content of the view. These explore predictive coding’s claims
at Marr’s computational, algorithmic, and implementation levels
respectively <span class="citation"
data-cites="Sprevak20b Sprevak20c Sprevak20d">(Sprevak forthcoming,
forthcoming, forthcoming)</span>. As we will see, there are many ways in
which its basic ideas may be elaborated and refined. My strategy is to
present what, in my opinion, are the ‘bare bones’ of the approach. For
readers new to this topic, I hope that this will provide you with a
scaffold on which to drape a more nuanced future understanding of the
view.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>For the remainder of this article, I focus on five ideas that feature
prominently in expositions of predictive coding, but which should be
distinguished from predictive coding. These ideas are: (i) that the
brain employs an efficient coding scheme; (ii) that perception has
top-down, expectation-driven effects; (iii) that cognition involves
minimisation of prediction error; (iv) that cognition is a form of
probabilistic inference; (v) that cognition makes use of generative
models. All these ideas are used by predictive coding but, I argue, they
are also shared by a variety of other computational approaches. They do
not reflect – taken either singly or jointly – what is distinctive about
predictive coding’s research programme. If one wishes to know what is
special about predictive coding, these ideas, whatever their intrinsic
value, can function as potential distractors. A corollary of this is
that evidence for predictive coding does not necessarily flow from
evidence that supports these more general ideas. Evidence for predictive
coding should aim to selectively support predictive coding with respect
to plausible contemporary rivals, not merely to confirm ideas that are
shared by a wide variety of other approaches.</p>
<p>The literature on predictive coding is vast. In what follows, I
ignore many interesting developments, proposals, and applications. My
description is also inevitably partisan: there is too much disagreement
within the primary literature to be able to characterise the view in a
wholly uncontroversial way. If you disagree with my description, I hope
that what I say at least provides a foil by which to triangulate your
own views.</p>
<p>In both the present article and those that follow, I only consider
predictive coding as a theory of subpersonal cognitive processing. I do
not consider how its computational model might be adapted or extended to
account for personal-level thought or conscious experience. Explaining
conscious experience with predictive coding is a relatively recent
development. However, it is a project that assumes we have a prior
understanding of what predictive coding’s computational model is. That
question is the focus of this review.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<h1 data-number="2" id="efficient-neural-coding"><span
class="header-section-number">2</span> Efficient neural coding</h1>
<p>A key idea that predictive coding employs is that the brain’s coding
scheme for storing and transmitting sensory information is, in a certain
sense, efficient. The relevant form of efficiency is quantified by the
degree to which the brain compresses incoming sensory information
(measured in terms of Shannon information theory). To compress
information, the sensory system should aim to transmit only what is
‘new’ or ‘unexpected’ or ‘unpredicted’ relative to its expectations. If
the sensory system were to encode certain assumptions about its incoming
sensory data, these would enable it to predict bits of that incoming
sensory stream. This means that fewer bits would need to be stored or
transmitted inwards from the sensory boundary, yielding a potential
reduction in the costs of the brain physically storing and transmitting
that data. The more accurately the brain’s internal assumptions reflect
its incoming sensory stream, the less information would need to be
stored or transmitted inwards from the sensory periphery. All that would
need to be sent inwards would be an error signal – what is new or
unexpected – with respect to those predictions. A similar idea underlies
coding schemes that allow electronic computers to store and transmit
images and videos across the Internet (e.g. JPEG or MPEG).</p>
<p>The notion that our brains use a sensory coding scheme that is
efficient in this respect dates back at least to the work of <span
class="citation" data-cites="Attneave54">Attneave (1954)</span> and
<span class="citation" data-cites="Barlow61a">Barlow (1961)</span>. They
argued that the brain uses a compressing, ‘redundancy reducing’ code for
encoding sensory information based partly on the grounds that neurons in
the early visual system have a limited physical dynamic range: the
action potentials they send inwards to cortical centres are precious and
should not be squandered to send information that those cortical centres
already have.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> Predictive coding adopts the same
basic perspective, but elevates it to a universal design principle: not
only the early stages of vision, but every aspect of cognition, should
be viewed as an attempt by the brain to compress its incoming sensory
data. To this, predictive coding adds a range of further assumptions
about (i) the algorithm by which the incoming sensory data are
compressed; (ii) how assumptions used for sensory compression are
changed during learning; (iii) where physically in the brain all this
takes place.</p>
<p>Predictive coding has particular views about how compression of
sensory signals works – see (i)–(iii) above. It also adopts the rather
extreme position that sensory compression is the brain’s <em>only</em>
goal. As Barlow made clear in his later work, even if one thinks that
compressing incoming sensory data is one thing that the brain does, it
is not obvious that it is the only thing. In some circumstances, it may
pay the brain <em>not</em> to compress:</p>
<blockquote>
<p>The point Attneave and I failed to appreciate is that the best way to
code information depends enormously on the use that is to be made of it
… if you simply want to transmit information to another location, then
redundancy-reducing codes economizing channel capacity are what you need
… But the brain is not just a communication system, and we now need to
survey cases where compression is not the best way to exploit
statistical structure. <span class="citation"
data-cites="Barlow01">(Barlow 2001 p. 246)</span>.</p>
</blockquote>
<p>One can appreciate Barlow’s point by considering what would count as
‘efficient’ coding for image data on a PC. If all one wishes to do is to
transmit an image across the Internet, then compressing it using a
redundancy reducing code (e.g. JPEG) might be a good solution, since it
would reduce the number of physical signals one would need to send.
Similarly, if one only wishes to store the image on a hard disk drive,
then compressing it would mean that fewer physical resources would be
required for its storage.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> However, if one wishes to
<em>transform</em> the image or <em>perform an inference</em> over it,
then a redundancy reducing code like JPEG may not be the best or most
efficient solution. Compressed data are often harder to work with. If
you ask a PC to rotate an image <span
class="math inline">\(23^\circ\)</span> clockwise, the machine will
generally not attempt to execute this operation on a compressed encoding
of the image data. Instead, it will switch to an uncompressed version of
the image (e.g. a two-dimensional array of RGB values at X, Y pixel
locations). Image processing algorithms defined over uncompressed data
tend to be shorter, simpler, and faster than those defined over their
more compressed counterparts.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a> Uncompressed images have
extra structure, and that structure can make the job of an algorithm
that operates on them easier, even if it adds extra overhead to store or
transmit.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<p>If all that matters to the brain in cognition are the costs of
transmitting and storing incoming sensory data, then it may make sense
for the brain to aim to maximally compress that incoming sensory data.
However, if speed, simplicity, and ease of inference matter, then it may
make sense to add or preserve redundant structure within incoming
sensory data.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a> Reducing redundancy is not the only
possible objective for a cognitive system that aims at efficient sensory
coding.</p>
<p>It is common for contemporary work on efficient coding to acknowledge
this point.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a> Predictive coding, in its strongest
and purest form, adopts a rather extreme view: it equates efficiency
with sensory redundancy reduction, and it claims that the entire brain
(not just certain areas in the sensory cortex) is devoted to this task;
it also claims that the sensory compression is accomplished by a
specific algorithm and representational scheme. Although predictive
coding employs the idea of efficient coding, the general idea is not
unique to predictive coding. Similarly, although evidence for efficient
sensory coding in, e.g. early stages in the visual cortex, may be
compatible with predictive coding, it may also be compatible with a
range of other, more modest proposals about efficient coding in
cognition.</p>
<h1 data-number="3"
id="top-down-expectation-driven-effects-in-perception"><span
class="header-section-number">3</span> Top-down, expectation-driven
effects in perception</h1>
<p>Top-down, expectation-driven effects in perception are instances in
which an agent’s prior beliefs systematically affect that agent’s
perceptual experience. Top-down, expectation-driven effects are
sometimes presented as a hallmark feature of predictive coding.
Predictive coding’s computational model is thought to imply that
perception is top-down or expectation-laden: ‘What we perceive (or think
we perceive) is heavily determined by what we know’ <span
class="citation" data-cites="Clark11">(Clark 2011)</span>. Evidence for
top-down effects in perception is also thought to somehow confirm
predictive coding’s computational model: we should give higher credence
to predictive coding’s computational proposal based on observation of
top-down effects in perception.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn13" class="footnote-ref"
id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>However, the relationship between predictive coding and top-down,
expectation-driven effects in perception is more complex and less direct
than this.</p>
<p>First, top-down effects in perception are standardly defined in terms
of a relationship between an agent’s <em>personal-level</em> states:
what an agent <em>believes</em> affects their <em>perceptual
experience</em>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> Predictive coding, at least in the
first instance, makes a claim about the agent’s subpersonal
computational states and processes. The ‘top’ and ‘bottom’ in predictive
coding’s computational model refer, as we will see, to subpersonal
computational states of the agent. ‘High-level’ neural representations
(implemented deep in the cortical hierarchy) are assumed to have a
‘top-down’ influence on ‘low-level’ representations (implemented in the
early sensory system). How this kind of subpersonal ‘top-down effect’
relates to personal-level top-down effects observed in psychology is
presently unclear.</p>
<p>One might argue that, at a minimum, personal-level top-down effects
require <em>some</em> subpersonal information to flow from high-level
cognitive centres to low-level sensory systems. However, it is difficult
to know what can be inferred from this assumption regarding
personal-level experience. Not every piece of subpersonal information
posited by predictive coding’s computational model features in the
contents of either personal-level belief or perceptual experience. Only
a tiny fraction of subpersonal information appears to be present at the
personal level. For predictive coding to say something specific about
the existence or character of top-down effects at the personal level, it
would need to say <em>which</em> aspects of that subpersonal information
give rise to <em>which</em> personal-level states (beliefs and
perceptual contents). These assumptions – which connect the subpersonal
level to the personal level – are currently not to be found anywhere
within predictive coding’s computational model. Ideas about these
connections have been proposed, but exactly how subpersonal states of
the computational model map onto personal-level beliefs and perceptual
experiences remains a highly speculative matter.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn15"
class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>
Absent confidence in such assumptions, however, it is simply unclear how
predictive coding’s computational architecture bears, or if it bears at
all, on personal-level top-down effects observed in psychology.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>Second, positing top-down subpersonal information flow inside a
computational model is not a characteristic that is unique to predictive
coding. Almost any plausible computational model of cognition is likely
to claim that information flows both ‘upwards’ (from lower-level sensory
systems to high-level cognitive centres) and ‘downwards’ (from
high-level cognitive centres to lower-level sensory systems). As Ira
Hyman observed in his introduction to the reprinting of Neisser’s
classic 1967 textbook: ‘Cognitive psychology has been and always will be
an interaction of bottom-up and top-down influences’.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn17"
class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>
This could even be said of so-called ‘bottom-up’ computational models,
such as the account of vision proposed by <span class="citation"
data-cites="Marr82">Marr (1982)</span>. Those models might appear to
ignore top-down processes, but this is not because they hold that
top-down influences do not exist in the brain or are unimportant, but
rather because they are not necessary to explain a particular phenomenon
of interest.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a> Indeed, it has been for a long time
standard practice in cognitive science to invoke top-down information
flow to account for endogenous attention, semantic priming, and to
explain how the brain handles ambiguity, noise, and uncertainty in its
sensory input.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a> The mammalian brain contains a huge
number of ‘backward’ cortical connections which suggest that signals
carried from cortical centres to peripheral sensory areas have a
significant computational role in cognitive processing. Even if one were
to ignore these connections, <span class="citation"
data-cites="FirestoneScholl16">Firestone &amp; Scholl (2016)</span>
observe that there are many other causal routes by which high-level
cognitive centres should be expected to systematically affect processing
in low-level sensory systems – the decision to ‘shut one’s eyes’ causes
one’s eyelids to close, which changes low-level sensory inputs,
systematically affecting the contents of states in subpersonal low-level
sensory systems, for example.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn20" class="footnote-ref"
id="fnref20" role="doc-noteref"><sup>20</sup></a> When advocates of
predictive coding suggest that their model has a special relationship
with top-down, expectation-driven effects observed at the personal
level, a challenge they face is to explain why predictive coding’s
specific set of top-down computational pathways is uniquely or best
suited to explain these effects.</p>
<p>To be clear, predictive coding’s computational model is
<em>compatible</em> with personal-level top-down effects in perception
occurring; it is also broadly <em>suggestive</em> that such effects
would occur. What is not clear is that it is <em>better</em> suited to
account for these effects than any number of other models that also
incorporate subpersonal top-down information flow (e.g. other kinds of
recurrent neural networks or classical computational models with loops).
For these reasons, it is not clear how personal-level top-down effects
is distinctively associated with, or selectively confirms, predictive
coding.</p>
<h1 data-number="4" id="minimising-prediction-error"><span
class="header-section-number">4</span> Minimising prediction error</h1>
<p>It is common in contemporary artificial intelligence (AI) to
characterise learning and inference in terms of minimising prediction
error. During learning, an AI system might attempt to change its
parameters to better predict its training data. During inference, an AI
system might search for values of its variables that would result in it
generating predictions that minimise prediction errors – that are as
close to ‘ground truth’ as possible.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn21" class="footnote-ref"
id="fnref21" role="doc-noteref"><sup>21</sup></a> Different AI systems
might differ in the types of data they try to predict, the mathematical
model they use for prediction, or the way they revise parameters of that
model during learning.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a> Prediction error might also be
measured in a number of ways. A common formalisation is mean-squared
error – the average of the squares of the differences between the
predicted values and the true values of the data.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn23"
class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a></p>
<p>The logical space of possible computational systems that aim to
minimise their prediction error is vast. One can get some idea of the
size and diversity of that space by opening up any current textbook on
machine learning or statistics.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn24" class="footnote-ref"
id="fnref24" role="doc-noteref"><sup>24</sup></a> A maximally simple
example of a system that aims to minimise its prediction error would be
one that performs linear regression on its training data. Here,
minimising prediction error reduces to just fitting a straight-line
mathematical model to the training data and using that straight-line
model to make predictions about unseen cases. Learning consists in
finding the value of two parameters (slope and <span
class="math inline">\(y\)</span>-intercept) that would define a straight
line that minimises mean-squared error over the training data. Classical
statistics contains many algorithms for finding those values (e.g., the
ordinary least squares algorithm). Deep neural networks provide more
complicated examples of computational systems that aim to minimise their
prediction error. Here, learning consists in finding the values of not
just two, but millions or billions of parameters. Algorithms like
backpropagation are commonly used to find these values. During
inference, a deep neural network might execute a long sequence of
mathematical operations over many variables in an effort to yield an
output that is as close to the ground truth as possible.</p>
<p>Predictive coding suggests that the brain, like many other
computational systems, aims to minimise a measure of prediction error.
What distinguishes predictive coding from other proposals is that it
makes specific claims about the <em>data</em>, <em>model</em>, and
<em>algorithm</em> used in this task; a distinctive claim is also made
about the <em>role</em> of this instance of prediction error
minimisation within the brain’s wider cognitive economy.</p>
<p>Regarding the <em>data</em>, predictive coding claims that the brain
aims to minimise prediction error concerning incoming <em>sensory
signals</em>. This should be distinguished from other approaches that
claim that the brain aims to minimise prediction error concerning other
forms of data, such as <em>reward signals</em>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn25"
class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>
The mathematical <em>model</em> the brain uses to generate its
predictions is encoded in an abstract hierarchical network containing
prediction and error units linked by weighted connections. This network
is similar to the connectionist networks found in deep learning,
although the behaviour of individual units and the overall topology of
the network differs from those commonly used in deep learning. The
<em>algorithm</em> that adjusts the parameters of the network during
learning is also different. Deep learning tends to use some version of
backpropagation; predictive coding suggests that the brain uses a
Hebbian learning algorithm.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn26" class="footnote-ref"
id="fnref26" role="doc-noteref"><sup>26</sup></a> Finally, a special
<em>role</em> is accorded to prediction error minimisation in cognition.
Predictive coding holds that minimising prediction error over sensory
signals is not just one among many objectives undertaken by the brain,
but its only or fundamental objective.</p>
<p>It is common to find prediction error minimisation occurring inside a
computational model of cognition. What marks out predictive coding as
special is the claim that cognition exclusively involves prediction
error minimisation over a specific set of data, with a specific
mathematical model, and using a specific algorithm for learning and
inference. Evidence for prediction error minimisation occurring in the
brain, although it may be compatible with predictive coding, may also be
compatible with any number of other computational models that also
employ prediction error minimisation.</p>
<h1 data-number="5"
id="cognition-as-a-form-of-probabilistic-inference"><span
class="header-section-number">5</span> Cognition as a form of
probabilistic inference</h1>
<p>Brains receive noisy, incomplete, and sometimes contradictory
information via their sensory organs. They need to weigh this
information rapidly and integrate it with (sometimes conflicting)
background knowledge in order to reach a decision and generate
behaviour. Probabilistic models of cognition provide a broad framework
by which to understand how brains do this. According to these models,
brains do not represent the world in purely categorical way (e.g. ‘the
person facing me is my father’), but instead represent multiple
possibilities (e.g. ‘the person facing me is my father, my uncle, his
cousin, <span class="math inline">\(\ldots\)</span>’) along with some
measure of uncertainty regarding those outcomes.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn27"
class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a>
Computational models typically formalise this by ascribing mathematical
<em>subjective probability distributions</em> to brains. These
probability distributions measure the brain’s degree of confidence in a
range of different possibilities.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn28" class="footnote-ref"
id="fnref28" role="doc-noteref"><sup>28</sup></a> Cognitive processing
is then modelled as a series of operations in which one subjective
probability distribution conditions, or updates, another. The exact
manner in which this happens may vary between different computational
models. In principle, cognitive processing may maintain this
probabilistic character until the brain is forced to plump for a
specific outcome in action (e.g. the agent is required to respond
‘yes’/‘no’ in a forced-choice task).</p>
<p>A particularly influential example of this approach is the
<em>Bayesian brain hypothesis</em>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn29" class="footnote-ref"
id="fnref29" role="doc-noteref"><sup>29</sup></a> On this view, Bayes’
rule, or some approximation to it, is assumed to describe how the brain
combines and updates its subjective probability distributions.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a> Because exact Bayesian inference is
computationally intractable, advocates of the Bayesian brain hypothesis
generally assume that the brain implements some version of approximate
Bayesian inference. Approximate Bayesian inference can be achieved in a
variety of ways, the most popular of which being <em>sampling
algorithms</em> (which use multiple categorical samples to create an
empirical distribution that approximates the true Bayesian posterior)
and <em>variational algorithms</em> (which change the parameters of some
simpler, more computationally tractable distribution in order to try to
find a posterior distribution that is close to the true Bayesian
posterior).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a> Both forms of approximate Bayesian
inference are common in AI and machine learning. Proponents of the
Bayesian brain hypothesis do not agree about whether the brain uses a
sampling method, a variational method, or something else entirely.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn32" class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a></p>
<p>Predictive coding is one example of a probabilistic model of
cognition and an instance of the Bayesian brain hypothesis. Predictive
coding identifies the task the brain faces in cognition as that of
minimising sensory prediction error. If combined with appropriate
simplifying assumptions, this task can be shown to entail approximate
Bayesian inference.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn33" class="footnote-ref" id="fnref33"
role="doc-noteref"><sup>33</sup></a> The numerical values that feature
in predictive coding’s artificial neural network can be interpreted as
parameters of subjective probability distributions (namely, as the means
and variances of Gaussian distributions). Predictive coding’s algorithm
can be interpreted as a particular version of variational Bayesian
inference.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn34" class="footnote-ref" id="fnref34"
role="doc-noteref"><sup>34</sup></a> Predictive coding proposes that
these numerical parameters, and hence the subjective probability
distributions manipulated in cognition, are encoded in the average
firing rates of neural populations of layers in the neocortex, and the
manner in which these subjective probability distributions condition one
another in inference is encoded in the strength of the synaptic
connections between distinct neocortical areas.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn35"
class="footnote-ref" id="fnref35"
role="doc-noteref"><sup>35</sup></a></p>
<p>Someone might endorse the idea that the brain engages in
probabilistic inference, or even the Bayesian brain hypothesis, but
reject some or all of these further assumptions. For example, someone
might not accept that a single probabilistic model underlies every
aspect of cognition, or that the subjective probability distributions in
the brain are always Gaussian, or that the brain uses the specific
version of variational Bayesian inference proposed by predictive coding,
or that the brain’s subjective probability distributions are encoded in
the neocortex.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn36" class="footnote-ref" id="fnref36"
role="doc-noteref"><sup>36</sup></a> Predictive coding is an example of
a probabilistic model of cognition, but there are many possible
alternative probabilistic models. Endorsement of, or evidence for, a
probabilistic approach to cognition cannot straightforwardly be read as
endorsement of, or evidence for, predictive coding as opposed to any
number of other views.</p>
<h1 data-number="6" id="cognition-uses-a-generative-model"><span
class="header-section-number">6</span> Cognition uses a generative
model</h1>
<p>A generative model is a special kind of representation that describes
how observations are produced by unobserved (‘latent’) variables in the
world. If a generative model were supplied with the information that
your best friend enters the room, it might predict which sights, sounds,
smells you would experience. At the highest level of abstraction, you
might conceive of a generative model as a black box that takes, as
input, a hidden state of the world and that yields, as output, the
sensory signals that would be likely to be observed. It is widely
thought that generative models – and in particular, probabilistic
generative models – play an important role in cognition. This is for at
least three reasons.</p>
<p>First, a generative model could help the brain to distinguish between
changes to its sensory data that are <em>self-generated</em> and
<em>externally generated</em>. When our eyes move, our sensory input
changes. How does the brain know which changes are due to movement of
our sensory organs and which are due to movement of external objects in
the environment? <span class="citation" data-cites="Helmholtz67">von
Helmholtz (1867)</span> proposed that our brain makes a copy of its
upcoming motor plans and uses this copy (the ‘efference copy’) to
predict how its plans are likely to affect incoming sensory data. A
generative model (the ‘forward motor model’) predicts the likely sensory
consequences of a planned movement (e.g. how sensory data would be
likely to change if the eyeballs rotate). These predictions are then fed
back to the sensory system and ‘subtracted away’ from incoming sensory
data. This would allow the brain to compensate for changes its own
movement introduces into its sensory data stream.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn37"
class="footnote-ref" id="fnref37"
role="doc-noteref"><sup>37</sup></a></p>
<p>Second, a generative model would help the brain to overcome some of
the inherent latency, noise, and gaps in its sensory data. When you
execute a complex, rapid motion – e.g. a tennis serve – your brain needs
to have accurate, low-latency sensory feedback. It needs to know where
your limbs are, how its motor plan is unfolding, whether any unexpected
resistance is being met, and how external objects (like the tennis ball)
are moving. Due to the limits of the brain’s physical hardware, this
sensory feedback is likely to arrive late, with gaps, and with noise. A
generative model would help the brain to alleviate these problems by
regulating its motor control based, not on actual sensory feedback, but
on expected sensory feedback. When the incoming sensory data do arrive,
the brain could then integrate them into its predictions in a way that
takes into account any background information that it has about bias,
noise, and uncertainty in that sensory signal. <span class="citation"
data-cites="FranklinWolpert11">Franklin &amp; Wolpert (2011)</span>
argue that this would allow the brain to make ‘optimal’ use of its
sensory input during motor control – optimal in the sense that the brain
would make use of all its available information.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn38"
class="footnote-ref" id="fnref38"
role="doc-noteref"><sup>38</sup></a></p>
<p>Third, if a generative model takes a probabilistic form, it could, in
principle be, inverted to produce a <em>discriminative model</em>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn39" class="footnote-ref" id="fnref39"
role="doc-noteref"><sup>39</sup></a> Discriminative models are of
obvious utility in many areas of cognition. A discriminative model tells
the cognitive system, given some sensory signal, which state(s) of the
world are most likely to be responsible for its observations.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn40" class="footnote-ref" id="fnref40"
role="doc-noteref"><sup>40</sup></a> Discriminative models are needed in
visual perception, object categorisation, speech recognition, detection
of causal relations, and social cognition. A discriminative model and a
generative model facilitate inference in opposite directions: whereas a
discriminative model tells the cognitive system how to make the
inferential leap from sensory data to the value of latent unobserved
variables, a generative model tells the cognitive system how to make the
inferential leap from the value of latent variables to sensory
observations. The latter form of inference might not initially appear to
be useful, but if the system applies Bayes’ theorem, a generative model
can be used to infer a discriminative model. Moreover, this may be a
computationally attractive strategy because generative models are often
easier to learn, more compact to represent, and less liable to break
when background conditions change.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn41" class="footnote-ref"
id="fnref41" role="doc-noteref"><sup>41</sup></a> In AI, a common
strategy for tackling a discriminative problem is to first learn a
generative model of the domain and then invert it using Bayes’ theorem.
This strategy is frequently suggested as the way in which the brain
tackles discriminative problems in certain domains of cognition.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn42" class="footnote-ref" id="fnref42"
role="doc-noteref"><sup>42</sup></a></p>
<p>A generative model is a common feature in a modern computational
model of cognition. Its content and structure, the methods by which it
is updated, and how it might be physically implemented in the brain,
might be filled out in many ways, including ways that depart
substantially from those suggested by predictive coding. In the context
of predictive coding, a single probabilistic generative model is claimed
to be employed across all domains of cognition. This generative model is
claimed to have a specific hierarchical structure, content, and to be
implemented in a specific way in the brain.</p>
<p>Someone might accept that generative models play a role in cognition,
but reject these further assumptions. For example, they might hold that
multiple distinct generative models exist in the brain in relative
functional isolation from each other – e.g., there might be a
domain-specific generative model dedicated to motor control.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn43" class="footnote-ref" id="fnref43"
role="doc-noteref"><sup>43</sup></a> They might hold that the brain does
not use a generative model to solve every inference problem – the brain
might sometimes attempt to learn and use a discriminative model of a
domain directly, or employ some other, non-model-based strategy to reach
a decision.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn44" class="footnote-ref" id="fnref44"
role="doc-noteref"><sup>44</sup></a> They might disagree about the
content of the generative model or how the generative model is
physically implemented in the brain.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn45" class="footnote-ref"
id="fnref45" role="doc-noteref"><sup>45</sup></a></p>
<p>Generative models appear in many computational accounts of cognition.
Predictive coding employs the idea, but that idea is not unique to
predictive coding. The proposal that the brain uses a generative model
should not simply be equated with predictive coding and one should not
assume that empirical evidence that favours the hypothesis that the
brain employs a generative model is also evidence that supports
predictive coding’s specific proposal about the character and role of a
generative model in cognition.</p>
<h1 data-number="7" id="conclusion"><span
class="header-section-number">7</span> Conclusion</h1>
<p>The aim of this paper is to separate five influential ideas about
cognition from predictive coding. Many philosophers first encounter
these ideas in the context of predictive coding. However, it is
important to recognise that those ideas exist in a broader intellectual
landscape and they are employed by approaches that have little or
nothing to do with predictive coding. Accepting one or more of these
ideas does not constitute an endorsement of predictive coding.
Similarly, evidence that supports one or more of the ideas should not be
taken as evidence that unambiguously supports predictive coding. If one
wants to understand the distinctive content of predictive coding, or to
evaluate the empirical evidence for it, one needs to disentangle it from
these other ideas.</p>
<p>Of course, there is nothing to stop someone defining the words
‘predictive coding’ to refer to some broad, non-specific synthesis of
these five ideas. On such a deflationary reading, one could say, without
fear of contradiction, that predictive coding is already widely accepted
and empirically confirmed. However, there are good reasons to resist
such a move. Advocates of predictive coding are keen to stress that
their view is both novel and that it faces genuine jeopardy with respect
to future evidence. If these claims are to be taken seriously, one would
need to show (i) that the view departs from plausible rivals; and (ii)
that it is not so anodyne as to be consistent with any likely empirical
evidence. To this end, Clark warns against interpreting predictive
coding as an ‘extremely broad vision’; it should be interpreted as a
‘specific proposal’ <span class="citation" data-cites="Clark15">(Clark
2016 p. 10)</span>. Hohwy observes that there is often an ambiguity
which renders presentations of predictive coding ‘both mainstream and
utterly controversial’ <span class="citation"
data-cites="Hohwy13">(Hohwy 2013 p. 7)</span>. He argues that in order
for it to meaningfully make contact with empirical evidence, it should
be understood as a specific, detailed proposal <span class="citation"
data-cites="Hohwy13">(Hohwy 2013 pp. 7–8)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fn46"
class="footnote-ref" id="fnref46"
role="doc-noteref"><sup>46</sup></a></p>
<p>What is that specific, detailed version of predictive coding? In what
follows, I argue that what distinguishes predictive coding from
contemporary rivals is a combination of three claims, each of which may
be precisified or qualified in various ways. These claims concern how
cognition works at Marr’s <em>computational</em>, <em>algorithmic</em>,
and <em>implementation</em> levels.</p>
<p>It is worth tempering what follows with a cautionary note. As already
mentioned, the specific, detailed content of predictive coding is in no
way a settled matter. Researchers disagree about which features of the
view are essential, whether the model should be applied to all domains
of cognition, whether the computational, algorithmic, and implementation
level claims should be combined, and the exact form each of these claims
should take. Cutting across this disagreement and uncertainty, however,
is a set of ideas that has inspired many researchers: a simple, bold,
and unifying picture of the mind, its abstract computational structure,
and its physical implementation. This somewhat idealised version of
predictive coding will be the focus of the next three papers.</p>
<h1 class="unnumbered" id="acknowledgements">Acknowledgements</h1>
<p>I would like to thank Jonathan Birch, Matteo Colombo, Matt Crosby,
Krzysztof Dolega, Jonny Lee, Edouard Machery, Christian Michel, Nina
Poth, Wolfgang Schwarz, Dan Williams, Wanja Wiese, and Sam Wilkinson for
helpful comments and discussion on earlier drafts of this paper.</p>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-AitchisonLengyel17" class="csl-entry" role="listitem">
Aitchison, L., &amp; Lengyel, M. (2017). <span>‘With or without you:
Predictive coding and <span>B</span>ayesian inference in the
brain’</span>, <em>Current Opinion in Neurobiology</em>, 46: 219–27.
</div>
<div id="ref-Attneave54" class="csl-entry" role="listitem">
Attneave, F. (1954). <span>‘Informational aspects of visual
perception’</span>, <em>Psychological Review</em>, 61: 183–93.
</div>
<div id="ref-Barber12" class="csl-entry" role="listitem">
Barber, D. (2012). <em>Bayesian reasoning and machine learning</em>.
Cambridge: Cambridge University Press.
</div>
<div id="ref-Barlow61a" class="csl-entry" role="listitem">
Barlow, H. B. (1961). <span>‘Possible principles underlying the
transformations of sensory messages’</span>. Rosenblith W. A. (ed.)
<em>Sensory communication</em>, pp. 217–34. MIT Press: Cambridge, MA.
</div>
<div id="ref-Barlow01" class="csl-entry" role="listitem">
Barlow, H. B. (2001). <span>‘Redundancy reduction revisited’</span>,
<em>Network: Computation in Neural Systems</em>, 12: 241–53.
</div>
<div id="ref-BastosUsrey12" class="csl-entry" role="listitem">
Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P.,
&amp; Friston, K. (2012). <span>‘Canonical microcircuits for predictive
coding’</span>, <em>Neuron</em>, 76: 695–711.
</div>
<div id="ref-Bishop06" class="csl-entry" role="listitem">
Bishop, C. M. (2006). <em>Pattern recognition and machine learning</em>.
New York, NY: Springer.
</div>
<div id="ref-Blakemore99" class="csl-entry" role="listitem">
Blakemore, S.-J., Frith, C. D., &amp; Wolpert, D. M. (1999).
<span>‘Spatio-temporal prediction modulates the perception of
self-produced stimuli’</span>, <em>Journal of Cognitive
Neuroscience</em>, 11: 551–9.
</div>
<div id="ref-Bogacz17" class="csl-entry" role="listitem">
Bogacz, R. (2017). <span>‘A tutorial on the free-energy framework for
modelling perception and learning’</span>, <em>Journal of Mathematical
Psychology</em>, 76: 198–211.
</div>
<div id="ref-BowersDavis12" class="csl-entry" role="listitem">
Bowers, J. S., &amp; Davis, C. J. (2012). <span>‘Bayesian just-so
stories in psychology and neuroscience’</span>, <em>Psychological
Bulletin</em>, 128: 389–414.
</div>
<div id="ref-Buhlmann22" class="csl-entry" role="listitem">
Bühlmann, M. (2022). <em><a
href="https://pub.towardsai.net/stable-diffusion-based-image-compresssion-6f1f0a399202">Stable
diffusion based image compression</a></em>.
</div>
<div id="ref-ChaterManning06" class="csl-entry" role="listitem">
Chater, N., &amp; Manning, C. D. (2006). <span>‘Probabilistic models of
language processing and acquisition’</span>, <em>Trends in Cognitive
Sciences</em>, 10: 335–44.
</div>
<div id="ref-ChaterOaksford08" class="csl-entry" role="listitem">
Chater, N., &amp; Oaksford, M. (Eds). (2008). <em>The probabilistic
mind: Prospects for bayesian cognitive science</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-ChaterTenenbaumYuille06" class="csl-entry" role="listitem">
Chater, N., Tenenbaum, J. B., &amp; Yuille, A. (2006).
<span>‘Probabilistic models of cognition: Conceptual
foundations’</span>, <em>Trends in Cognitive Sciences</em>, 10: 287–91.
</div>
<div id="ref-Clark11" class="csl-entry" role="listitem">
Clark, A. (2011). <span>‘<a
href="https://www.edge.org/response-detail/10404">What scientific
concept would improve everybody’s cognitive toolkit?</a>’</span>,
<em>Edge</em>.
</div>
<div id="ref-Clark13" class="csl-entry" role="listitem">
Clark, A. (2013). <span>‘Whatever next? Predictive brains, situated
agents, and the future of cognitive science’</span>, <em>Behavioral and
Brain Sciences</em>, 36: 181–253.
</div>
<div id="ref-Clark15" class="csl-entry" role="listitem">
Clark, A. (2016). <em>Surfing uncertainty: Prediction, action, and the
embodied mind</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Clark19" class="csl-entry" role="listitem">
Clark, A. (2019). <span>‘Consciousness as generative
entanglement’</span>, <em>The Journal of Philosophy</em>, 116: 645–62.
</div>
<div id="ref-Clark23" class="csl-entry" role="listitem">
Clark, A. (2023). <em>The experience machine: How our minds predict and
shape reality</em>. London: Allen Lane.
</div>
<div id="ref-Colombo17" class="csl-entry" role="listitem">
Colombo, M. (2017). <span>‘Review of <span>Andy Clark</span>,
<em><span>S</span>urfing <span>U</span>ncertainty:
<span>P</span>rediction, <span>A</span>ction, and the
<span>E</span>mbodied <span>M</span>ind</em>’</span>, <em>Minds and
Machines</em>, 27: 381–5.
</div>
<div id="ref-ColomboElkin18" class="csl-entry" role="listitem">
Colombo, M., Elkin, L., &amp; Hartmann, S. (2021). <span>‘Being realist
about <span>B</span>ayes, and the predictive processing theory of
mind’</span>, <em>The British Journal for the Philosophy of
Science</em>, 72: 185–220.
</div>
<div id="ref-Danks19" class="csl-entry" role="listitem">
Danks, D. (2019). <span>‘Probabilistic models’</span>. Sprevak M. &amp;
Colombo M. (eds) <em>The routledge handbook of the computational
mind</em>, pp. 149–58. Routledge.
</div>
<div id="ref-deFinetti90" class="csl-entry" role="listitem">
de Finetti, B. (1990). <em>Theory of probability</em>., Vol. 1. New
York, NY: Wiley &amp; Sons.
</div>
<div id="ref-Deneve08" class="csl-entry" role="listitem">
Deneve, S. (2008). <span>‘Bayesian spiking neurons <span>I</span>:
<span>I</span>nference’</span>, <em>Neural Computation</em>, 20: 91–117.
</div>
<div id="ref-Dennett91" class="csl-entry" role="listitem">
Dennett, D. C. (1991). <em>Consciousness explained</em>. Boston, MA:
Little, Brown &amp; Company.
</div>
<div id="ref-DolegaDewhurst20" class="csl-entry" role="listitem">
Dolega, K., &amp; Dewhurst, J. E. (2021). <span>‘Fame in the predictive
brain: A deflationary approach to explaining consciousness in the
prediction error minimization framework’</span>, <em>Synthese</em>, 198:
7781–806.
</div>
<div id="ref-Drayson17" class="csl-entry" role="listitem">
Drayson, Z. (2017). <span>‘Modularity and the predictive mind’</span>.
Metzinger T. &amp; Wiese W. (eds) <em>Philosophy and predictive
processing</em>. MIND Group: 10.15502/9783958573031. DOI: <a
href="https://doi.org/10.15502/9783958573024">10.15502/9783958573024</a>
</div>
<div id="ref-EberhardtDanks11" class="csl-entry" role="listitem">
Eberhardt, F., &amp; Danks, D. (2011). <span>‘Confirmation in the
cognitive sciences: The problematic case of <span>B</span>ayesian
models’</span>, <em>Minds and Machines</em>, 21: 389–410.
</div>
<div id="ref-FirestoneScholl16" class="csl-entry" role="listitem">
Firestone, C., &amp; Scholl, B. J. (2016). <span>‘Cognition does not
affect perception: Evaluating the evidence for <span>“top-down”</span>
effects’</span>, <em>Behavioral and Brain Sciences</em>, 39: E229.
</div>
<div id="ref-FiserBerkes10" class="csl-entry" role="listitem">
Fiser, J., Berkes, P., Orbán, G., &amp; Lengyel, M. (2010).
<span>‘Statistically optimal perception and learning: From behavior to
neural representations’</span>, <em>Trends in Cognitive Sciences</em>,
14: 119–30.
</div>
<div id="ref-Forster08" class="csl-entry" role="listitem">
Forster, M. (2008). <span>‘Prediction’</span>. Psillos S. &amp; Curd M.
(eds) <em>The routledge companion to philosophy of science</em>, pp.
405–13. Routledge: London.
</div>
<div id="ref-FranklinWolpert11" class="csl-entry" role="listitem">
Franklin, D. W., &amp; Wolpert, D. M. (2011). <span>‘Computational
mechanisms of sensorimotor control’</span>, <em>Neuron</em>, 72: 425–42.
</div>
<div id="ref-Friston03" class="csl-entry" role="listitem">
Friston, K. (2003). <span>‘Learning and inference in the brain’</span>,
<em>Neural Networks</em>, 16: 1325–52.
</div>
<div id="ref-Friston05" class="csl-entry" role="listitem">
Friston, K. (2005). <span>‘A theory of cortical responses’</span>,
<em>Philosophical Transactions of the Royal Society of London, Series
B</em>, 360: 815–36.
</div>
<div id="ref-Friston09" class="csl-entry" role="listitem">
Friston, K. (2009). <span>‘The free-energy principle: A rough guide to
the brain?’</span>, <em>Trends in Cognitive Sciences</em>, 13: 293–301.
</div>
<div id="ref-Friston10" class="csl-entry" role="listitem">
Friston, K. (2010). <span>‘The free-energy principle: A unified brain
theory?’</span>, <em>Nature Reviews Neuroscience</em>, 11: 127–38.
</div>
<div id="ref-FristonFortierFriedman18" class="csl-entry"
role="listitem">
Friston, K., Fortier, M., &amp; Friedman, D. A. (2018). <span>‘Of
woodlice and men: A <span>B</span>ayesian account of cognition, life and
consciousness: An interview with <span>K</span>arl
<span>F</span>riston’</span>, <em>ALIUS Bulletin</em>, 2: 17–43.
</div>
<div id="ref-FristonSchwartenbeckFitzGerald13" class="csl-entry"
role="listitem">
Friston, K., Schwartenbeck, P., FitzGerald, T., Moutoussis, M., Behrens,
T., &amp; Dolan, R. J. (2013). <span>‘The anatomy of choice: Active
inference and agency’</span>, <em>Frontiers in Human Neuroscience</em>,
7: 598.
</div>
<div id="ref-GardnerBarlow01" class="csl-entry" role="listitem">
Gardner-Medwin, A. R., &amp; Barlow, H. B. (2001). <span>‘The limits of
counting accuracy in distributed neural representations’</span>,
<em>Neural Computation</em>, 13: 477–504.
</div>
<div id="ref-Gershman19" class="csl-entry" role="listitem">
Gershman, S. J. (2019). <span>‘What does the free energy principle tell
us about the brain?’</span>, <em>Neurons, Behavior, Data Analysis, and
Theory</em>.
</div>
<div id="ref-Gregory97" class="csl-entry" role="listitem">
Gregory, R. L. (1997). <span>‘Knowledge in perception and
illusion’</span>, <em>Philosophical Transactions of the Royal Society of
London, Series B</em>, 352: 1121–8.
</div>
<div id="ref-GriffithsVul12" class="csl-entry" role="listitem">
Griffiths, T. L., Vul, E., &amp; Sanborn, A. N. (2012). <span>‘Bridging
levels of analysis for probabilistic models of cognition’</span>,
<em>Current Directions in Psychological Science</em>, 21: 263–8.
</div>
<div id="ref-Grush04" class="csl-entry" role="listitem">
Grush, R. (2004). <span>‘The emulator theory of representation: Motor
control, imagery, and perception’</span>, <em>Behavioral and Brain
Sciences</em>, 27: 377–442.
</div>
<div id="ref-Hohwy12" class="csl-entry" role="listitem">
Hohwy, J. (2012). <span>‘Attention and conscious perception in the
hypothesis testing brain’</span>, <em>Frontiers in Psychology</em>, 3:
1–14.
</div>
<div id="ref-Hohwy13" class="csl-entry" role="listitem">
Hohwy, J. (2013). <em>The predictive mind</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-Hohwy20" class="csl-entry" role="listitem">
Hohwy, J. (2020). <span>‘New directions in predictive
processing’</span>, <em>Mind and Language</em>, 35: 209–23.
</div>
<div id="ref-HoyerHyvarinen03" class="csl-entry" role="listitem">
Hoyer, P. O, &amp; Hyvärinen, A. (2003). <span>‘Interpreting neural
response variability as <span>M</span>onte <span>C</span>arlo sampling
of the posterior’</span>. Becker S., Thrun S., &amp; Obermayer K. (eds)
<em>Advances in neural information processing systems 15</em>, pp.
277–84. MIT Press: Cambridge, MA.
</div>
<div id="ref-Icard16" class="csl-entry" role="listitem">
Icard, T. (2016). <span>‘Subjective probability as sampling
propensity’</span>, <em>Review of Philosophy and Psychology</em>, 7:
863–903.
</div>
<div id="ref-JiangRao22" class="csl-entry" role="listitem">
Jiang, L. P., &amp; Rao, R. P. N. (2022). <span>‘Predictive coding
theories of cortical function’</span>. Sherman S. M. (ed.) <em>Oxford
research encyclopedia of neuroscience</em>. DOI: <a
href="https://doi.org/10.1093/acrefore/9780190264086.013.328">10.1093/acrefore/9780190264086.013.328</a>
</div>
<div id="ref-KanaiKomuraShipp15" class="csl-entry" role="listitem">
Kanai, R., Komura, Y., Shipp, S., &amp; Friston, K. (2015).
<span>‘Cerebral hierarchies: Predictive processing, precision and the
pulvinar’</span>, <em>Philosophical Transactions of the Royal Society of
London, Series B</em>, 370: 20140169.
</div>
<div id="ref-KellerMrsciFlogel18" class="csl-entry" role="listitem">
Keller, G. B., &amp; Mrsci-Flogel, T. D. (2018). <span>‘Predictive
processing: A canonical cortical computation’</span>, <em>Neuron</em>,
100: 424–35.
</div>
<div id="ref-KirchhoffKiverstein19a" class="csl-entry" role="listitem">
Kirchhoff, M. D., &amp; Kiverstein, J. (2019). <em>Extended
consciousness and predictive processing</em>. Abingdon: Routledge.
</div>
<div id="ref-KnillPouget04" class="csl-entry" role="listitem">
Knill, D. C., &amp; Pouget, A. (2004). <span>‘The <span>B</span>ayesian
brain: The role of uncertainty in neural coding and computation’</span>,
<em>Trends in Neurosciences</em>, 27: 712–9.
</div>
<div id="ref-KokLange15" class="csl-entry" role="listitem">
Kok, P., &amp; Lange, F. P. de. (2015). <span>‘Predictive coding in the
sensory cortex’</span>. Forstmann B. U. &amp; Wagenmakers E.-. J. (eds)
<em>An introduction to model-based cognitive neuroscience</em>, pp.
221–44. Springer: New York, NY.
</div>
<div id="ref-KordingWolpert04" class="csl-entry" role="listitem">
Körding, K. P., &amp; Wolpert, D. M. (2004). <span>‘Bayesian integration
in sensorimotor learning’</span>, <em>Nature</em>, 427: 244–7.
</div>
<div id="ref-KordingWolpert06" class="csl-entry" role="listitem">
Körding, K. P., &amp; Wolpert, D. M. (2006). <span>‘Bayesian decision
theory in sensorimotor control’</span>, <em>Trends in Cognitive
Sciences</em>, 10: 319–26.
</div>
<div id="ref-Kriegeskorte15" class="csl-entry" role="listitem">
Kriegeskorte, N. (2015). <span>‘Deep neural networks: A new framework
for modeling biological vision and brain information processing’</span>,
<em>Annual Review of Vision Science</em>, 1: 417–46.
</div>
<div id="ref-Lakatos78" class="csl-entry" role="listitem">
Lakatos, I. (1978). <em>The methodology of scientific research
programmes: Philosophical papers volume 1</em>. (J. Worrall &amp; G.
Currie, Eds). Cambridge: Cambridge University Press.
</div>
<div id="ref-LangeHeilbronKok18" class="csl-entry" role="listitem">
Lange, F. P. de, Heilbron, M., &amp; Kok, P. (2018). <span>‘How do
expectations shape perception?’</span>, <em>Trends in Cognitive
Sciences</em>, 22: 764–79.
</div>
<div id="ref-LasserreBishop06" class="csl-entry" role="listitem">
Lasserre, J. A., Bishop, C. M., &amp; Minka, T. P. (2006).
<span>‘Principled hybrids of generative and discriminative
models’</span>. <em>Proceedings of the 2006 <span>IEEE</span> computer
society conference on computer vision and pattern recognition</em>, pp.
87–94. IEEE Computer Society: New York, NY.
</div>
<div id="ref-Laudan77" class="csl-entry" role="listitem">
Laudan, L. (1977). <em>Progress and its problems</em>. Berkeley, CA:
University of California Press.
</div>
<div id="ref-Lupyan15" class="csl-entry" role="listitem">
Lupyan, G. (2015). <span>‘Cognitive penetrability of perception in the
age of prediction: Predictive systems are penetrable systems’</span>,
<em>Review of Philosophy and Psychology</em>, 6: 547–69.
</div>
<div id="ref-MacKay03" class="csl-entry" role="listitem">
MacKay, D. J. C. (2003). <em>Information theory, inference, and learning
algorithms</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Macpherson12" class="csl-entry" role="listitem">
Macpherson, F. (2012). <span>‘Cognivite penetration of colour
experience: Rethinking the issue in light of an indirect
mechanism’</span>, <em>Philosophy and Phenomenological Research</em>,
84: 24–62.
</div>
<div id="ref-Macpherson17" class="csl-entry" role="listitem">
Macpherson, F. (2017). <span>‘The relationship between cognitive
penetration and predictive coding’</span>, <em>Consciousness and
Cognition</em>, 47: 6–16.
</div>
<div id="ref-Marr82" class="csl-entry" role="listitem">
Marr, D. (1982). <em>Vision</em>. San Francisco, CA: W. H. Freeman.
</div>
<div id="ref-Matloff17" class="csl-entry" role="listitem">
Matloff, N. (2017). <em>Statistical regression and classification</em>.
Boca Raton, FL: CRC Press.
</div>
<div id="ref-MetzingerWiese17a" class="csl-entry" role="listitem">
Metzinger, T., &amp; Wiese, W. (2017). <span>‘Vanilla <span>PP</span>
for philosophers: <span>A</span> primer on predictive
processing’</span>. Metzinger T. &amp; Wiese W. (eds) <em>Philosophy and
predictive processing</em>. MIND Group: Frankfurt am Main. DOI: <a
href="https://doi.org/10.15502/9783958573024">10.15502/9783958573024</a>
</div>
<div id="ref-MorenoBoteKnillPouget11" class="csl-entry" role="listitem">
Moreno-Bote, R., Knill, D. C., &amp; Pouget, A. (2011). <span>‘Bayesian
sampling in visual perception’</span>, <em>Proceedings of the National
Academy of Sciences</em>, 108: 12491–6.
</div>
<div id="ref-Neisser67" class="csl-entry" role="listitem">
Neisser, U. (2014). <em>Cognitive psychology</em>. Englewood Cliffs, NJ:
Prentice-Hall.
</div>
<div id="ref-NgJordan02" class="csl-entry" role="listitem">
Ng, A. Y., &amp; Jordan, M. I. (2002). <span>‘On discriminative
vs. Generative classifiers: <span>A</span> comparison of logistic
regression and naive <span>B</span>ayes’</span>. Dietterich T. G.,
Becker S., &amp; Ghahramani Z. (eds) <em>Advances in neural information
processing systems 14</em>, pp. 841–8. MIT Press: Cambridge, MA.
</div>
<div id="ref-NivSchoenbaum08" class="csl-entry" role="listitem">
Niv, Y., &amp; Schoenbaum, G. (2008). <span>‘Dialogues on prediction
errors’</span>, <em>Trends in Cognitive Sciences</em>, 12: 265–72.
</div>
<div id="ref-PoeppelBever10" class="csl-entry" role="listitem">
Poeppel, D., &amp; Bever, T. G. (2010). <span>‘Analysis by synthesis: A
(re-)emerging program of research for language and vision’</span>,
<em>Biolinguistics</em>, 4: 174–200.
</div>
<div id="ref-PougetBeck13" class="csl-entry" role="listitem">
Pouget, A., Beck, J. M., Ma, W. J., &amp; Latham, P. E. (2013).
<span>‘Probabilistic brains: Knows and unknowns’</span>, <em>Nature
Neuroscience</em>, 16: 1170–8.
</div>
<div id="ref-Rahnev17" class="csl-entry" role="listitem">
Rahnev, D. (2017). <em>The case against full probability distributions
in perceptual decision making</em>. DOI: <a
href="https://doi.org/10.1101/108944">10.1101/108944</a>
</div>
<div id="ref-RahnevDenison18" class="csl-entry" role="listitem">
Rahnev, D., &amp; Denison, R. N. (2018). <span>‘Suboptimality in
perceptual decision making’</span>, <em>Behavioral and Brain
Sciences</em>, 41: 1–66.
</div>
<div id="ref-RainaShenMcCallum03" class="csl-entry" role="listitem">
Raina, R., Shen, Y., McCallum, A., &amp; Ng, A. Y. (2003).
<span>‘Classification with hybrid generative/discriminative
models’</span>. Thrun S., Saul L. K., &amp; Schölkopf B. (eds)
<em>Advances in neural information processing systems 16</em>, pp.
545–52. MIT Press: Cambridge, MA.
</div>
<div id="ref-Ramsey90" class="csl-entry" role="listitem">
Ramsey, F. P. (1990). <em>Philosophical papers</em>. (D. H. Mellor,
Ed.). Cambridge: Cambridge University Press.
</div>
<div id="ref-Rescorla18" class="csl-entry" role="listitem">
Rescorla, M. (2018). <span>‘Motor computation’</span>. Sprevak M. &amp;
Colombo M. (eds) <em>The routledge handbook of the computational
mind</em>, pp. 424–35. Routledge: London.
</div>
<div id="ref-Rescorla20" class="csl-entry" role="listitem">
Rescorla, M. (2020). <span>‘A realist perspective on
<span>B</span>ayesian cognitive science’</span>. Nes A. &amp; Chan T.
(eds) <em>Inference and consciousness</em>, pp. 40–73. Routledge:
London.
</div>
<div id="ref-RoskiesWood17" class="csl-entry" role="listitem">
Roskies, A. L., &amp; Wood, C. C. (2017). <span>‘Catching the prediction
wave in brain science’</span>, <em>Analysis</em>, 77: 848–57.
</div>
<div id="ref-RussellNorvig10" class="csl-entry" role="listitem">
Russell, S., &amp; Norvig, P. (2010). <em>Artificial intelligence: A
modern approach</em>., 3rd ed. Upper Saddle River, NJ: Pearson.
</div>
<div id="ref-SanbornChater16" class="csl-entry" role="listitem">
Sanborn, A. N., &amp; Chater, N. (2016). <span>‘Bayesian brains without
probabilities’</span>, <em>Trends in Cognitive Sciences</em>, 20:
883–93.
</div>
<div id="ref-SanbornChater17" class="csl-entry" role="listitem">
Sanborn, A. N., &amp; Chater, N. (2017). <span>‘The sampling
brain’</span>, <em>Trends in Cognitive Sciences</em>, 21: 492–3.
</div>
<div id="ref-SchultzDayan97" class="csl-entry" role="listitem">
Schultz, W., Dayan, P., &amp; Montague, P. R. (1997). <span>‘A neural
substrate of prediction and reward’</span>, <em>Science</em>, 275:
1593–9.
</div>
<div id="ref-SchwartenbeckFitzGeraldMathys15" class="csl-entry"
role="listitem">
Schwartenbeck, P., FitzGerald, T., Mathys, C., Dolan, R. J., &amp;
Friston, K. (2015). <span>‘The dopaminergic midbrain encodes the
expected certainty about desired outcomes’</span>, <em>Cerebral
Cortex</em>, 25: 3434–34445.
</div>
<div id="ref-Seth17" class="csl-entry" role="listitem">
Seth, A. K. (2017). <span>‘The cybernetic brain: From interoceptive
inference to sensorimotor contingencies’</span>. Metzinger T. &amp;
Wiese W. (eds) <em>Philosophy and predictive processing</em>. MIND
Group: Frankfurt am Main. DOI: <a
href="https://doi.org/10.15502/9783958570108">10.15502/9783958570108</a>
</div>
<div id="ref-Seth21" class="csl-entry" role="listitem">
Seth, A. K. (2021). <em>Being you: A new science of consciousness</em>.
London: Faber &amp; Faber.
</div>
<div id="ref-SimoncelliOlshausen01" class="csl-entry" role="listitem">
Simoncelli, E. P., &amp; Olshausen, B. A. (2001). <span>‘Natural image
statistics and neural representation’</span>, <em>Annual Review of
Neuroscience</em>, 24: 1193–216.
</div>
<div id="ref-Spratling17" class="csl-entry" role="listitem">
Spratling, M. W. (2017). <span>‘A review of predictive coding
algorithms’</span>, <em>Brain and Cognition</em>, 112: 92–7.
</div>
<div id="ref-Sprevak22" class="csl-entry" role="listitem">
Sprevak, M. (2022). <span>‘Understanding phenomenal consciousness while
keeping it real’</span>, <em>Philosophical Psychology</em>. DOI: <a
href="https://doi.org/10.1080/09515089.2022.2092465">10.1080/09515089.2022.2092465</a>
</div>
<div id="ref-Sprevak20d" class="csl-entry" role="listitem">
Sprevak, M. (forthcoming). <span>‘Predictive coding <span>IV</span>: The
implementation level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20c" class="csl-entry" role="listitem">
Sprevak, M. (forthcoming). <span>‘Predictive coding <span>III</span>:
The algorithmic level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20b" class="csl-entry" role="listitem">
Sprevak, M. (forthcoming). <span>‘Predictive coding <span>II</span>: The
computational level’</span>, <em>TBC</em>.
</div>
<div id="ref-SprevakSmith23" class="csl-entry" role="listitem">
Sprevak, M., &amp; Smith, R. (2023). <span>‘An introduction to
predictive processing models of perception and decision-making’</span>,
<em>Topics in Cognitive Science</em>. DOI: <a
href="https://doi.org/10.1111/tops.12704">10.1111/tops.12704</a>
</div>
<div id="ref-SterlingLaughlin15" class="csl-entry" role="listitem">
Sterling, P., &amp; Laughlin, S. (2015). <em>Principles of neural
design</em>. Cambridge, MA: MIT Press.
</div>
<div id="ref-Stone18" class="csl-entry" role="listitem">
Stone, J. V. (2018). <em>Principles of neural information theory:
Computational neuroscience and metabolic efficiency</em>. Sebtel Press.
</div>
<div id="ref-Strevens08" class="csl-entry" role="listitem">
Strevens, M. (2017). <em><a
href="http://www.strevens.org/bct/BCT.pdf">Notes on
<span>B</span>ayesian confirmation theory</a></em>.
</div>
<div id="ref-TenenbaumKemp11" class="csl-entry" role="listitem">
Tenenbaum, J. B., Kemp, C., Griffiths, T. L., &amp; Goodman, N. D.
(2011). <span>‘How to grow a mind: Statistics, structure, and
abstraction’</span>, <em>Science</em>, 331: 1279–85.
</div>
<div id="ref-TodericiVincent16" class="csl-entry" role="listitem">
Toderici, G., Vincent, D., Johnston, N., Hwang, S. J., Minnen, D., Shor,
J., &amp; Covell, M. (2017). <em>Full resolution image compression with
recurrent neural networks</em>. DOI: <a
href="https://doi.org/10.48550/arXiv.1608.05148">10.48550/arXiv.1608.05148</a>
</div>
<div id="ref-Usevitch01" class="csl-entry" role="listitem">
Usevitch, B. E. (2001). <span>‘A tutorial on modern lossy wavelet image
compression: Foundations of <span>JPEG</span> 2000’</span>, <em>IEEE
Signal Processing Magazine</em>, 18: 22–35.
</div>
<div id="ref-Helmholtz67" class="csl-entry" role="listitem">
von Helmholtz, H. (1867). <em>Handbuch der physiologischen
<span>O</span>ptik</em>. Hamburg und Leipzig: Leopold Voss.
</div>
<div id="ref-WolpertGhahramaniFlanagan01" class="csl-entry"
role="listitem">
Wolpert, D. M., Ghahramani, Z., &amp; Flanagan, J. R. (2001).
<span>‘Perspectives and problems in motor learning’</span>, <em>Trends
in Cognitive Sciences</em>, 5: 487–94.
</div>
<div id="ref-YuilleKersten06" class="csl-entry" role="listitem">
Yuille, A., &amp; Kersten, D. (2006). <span>‘Vision as
<span>B</span>ayesian inference: Analysis by synthesis?’</span>,
<em>Trends in Cognitive Sciences</em>, 10: 301–8.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>For examples of these broad claims, see <span
class="citation" data-cites="Clark13">Clark (2013)</span>; <span
class="citation" data-cites="Clark15">Clark (2016)</span>; <span
class="citation" data-cites="Hohwy13">Hohwy (2013)</span>; <span
class="citation" data-cites="Friston09">Friston (2009)</span>; <span
class="citation" data-cites="Friston10">Friston (2010)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Some authors use ‘predictive coding’ to refer to only
one aspect of the view: for example, to the efficient coding strategy
described in section 2, or to the algorithm described in Section 2 of
<span class="citation" data-cites="Sprevak20c">Sprevak
(forthcoming)</span>. Some authors call the overall research programme
‘predictive processing’, ‘prediction error minimisation’, or ‘free
energy minimisation’. In what follows, I use the term ‘predictive
coding’ to refer to the overall research programme.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>See <span class="citation" data-cites="Marr82">Marr
(1982)</span>, Ch. 1 for a description of these levels.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The term ‘research programme’ is used here to indicate
that the precise details, goals, and conditions of correct application
of a scientific model are often not to be decided in advance and are
liable to change over time. It is not meant to indicate commitment to a
specific philosophical understanding of a scientific research programme
(e.g. that of <span class="citation" data-cites="Lakatos78">Lakatos
(1978)</span> or <span class="citation" data-cites="Laudan77">Laudan
(1977)</span>). In what follows, I use the terms ‘framework’,
‘approach’, ‘view’, ‘account’, ‘theory’, and ‘model’ interchangeably
with ‘research programme’, with alternative uses flagged along the
way.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>To help build that understanding, helpful reviews
include <span class="citation" data-cites="AitchisonLengyel17">Aitchison
&amp; Lengyel (2017)</span>; <span class="citation"
data-cites="Friston03">Friston (2003)</span>; <span class="citation"
data-cites="Friston05">Friston (2005)</span>; <span class="citation"
data-cites="Friston09">Friston (2009)</span>; <span class="citation"
data-cites="Friston10">Friston (2010)</span>; <span class="citation"
data-cites="KanaiKomuraShipp15">Kanai et al. (2015)</span>; <span
class="citation" data-cites="KellerMrsciFlogel18">Keller &amp;
Mrsci-Flogel (2018)</span>. For reviews that focus on the describing the
mathematical and computational framework, see <span class="citation"
data-cites="Bogacz17">Bogacz (2017)</span>; <span class="citation"
data-cites="Gershman19">Gershman (2019)</span>; <span class="citation"
data-cites="JiangRao22">Jiang &amp; Rao (2022)</span>; <span
class="citation" data-cites="Spratling17">Spratling (2017)</span>; <span
class="citation" data-cites="SprevakSmith23">Sprevak &amp; Smith
(2023)</span>. For reviews that focus on the possible neural
implementation, see <span class="citation"
data-cites="BastosUsrey12">Bastos et al. (2012)</span>; <span
class="citation" data-cites="JiangRao22">Jiang &amp; Rao (2022)</span>;
<span class="citation" data-cites="LangeHeilbronKok18">Lange et al.
(2018)</span>; <span class="citation" data-cites="KokLange15">Kok &amp;
Lange (2015)</span>. For reviews that focus on philosophical issues and
possible applications to existing problems in philosophy, see <span
class="citation" data-cites="Clark13">Clark (2013)</span>; <span
class="citation" data-cites="Clark15">Clark (2016)</span>; <span
class="citation" data-cites="FristonFortierFriedman18">Friston et al.
(2018)</span>; <span class="citation" data-cites="Hohwy13">Hohwy
(2013)</span>; <span class="citation" data-cites="Hohwy20">Hohwy
(2020)</span>; <span class="citation"
data-cites="MetzingerWiese17a">Metzinger &amp; Wiese (2017)</span>;
<span class="citation" data-cites="RoskiesWood17">Roskies &amp; Wood
(2017)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>For examples of work that applies predictive coding’s
computational model to explain conscious experience, see <span
class="citation" data-cites="Clark19">Clark (2019)</span>; <span
class="citation" data-cites="Clark23">Clark (2023)</span>; <span
class="citation" data-cites="DolegaDewhurst20">Dolega &amp; Dewhurst
(2021)</span>; <span class="citation" data-cites="Hohwy12">Hohwy
(2012)</span>; <span class="citation"
data-cites="KirchhoffKiverstein19a">Kirchhoff &amp; Kiverstein
(2019)</span>; <span class="citation" data-cites="Seth17">Seth
(2017)</span>; <span class="citation" data-cites="Seth21">Seth
(2021)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>See <span class="citation"
data-cites="SimoncelliOlshausen01">Simoncelli &amp; Olshausen
(2001)</span>; <span class="citation"
data-cites="SterlingLaughlin15">Sterling &amp; Laughlin (2015)</span>;
<span class="citation" data-cites="Stone18">Stone (2018)</span> for
reviews of efficient coding in the sensory system.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Other coding schemes such as wavelet-based codes <span
class="citation" data-cites="Usevitch01">(Usevitch 2001)</span> or deep
neural networks <span class="citation"
data-cites="TodericiVincent16 Buhlmann22">(Bühlmann 2022; Toderici et
al. 2017)</span> would outperform JPEG in these respects. However, these
schemes tend to impose even higher computing burdens than JPEG if one
wishes to decode or transform an image.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>This is an instance of a more general trade-off in
computer science between optimising for time and optimising for space.
Compressing data saves space, but generally has an adverse effect on the
time (number of computing cycles) required to do inference on that data
to accomplish certain tasks. You have experienced this trade-off any
time you waited for a ‘.zip’ archive to uncompress before being able to
work on its contents.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>A related point is that uncompressed data are more
resistant to noise during storage and transmission.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation"
data-cites="GardnerBarlow01">Gardner-Medwin &amp; Barlow (2001)</span>
list examples in which adding redundancy to sensory signals produces
faster and more reliable inference over sensory data.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>For example, <span class="citation"
data-cites="SimoncelliOlshausen01">Simoncelli &amp; Olshausen
(2001)</span> suggest that the nature of the downstream task a cognitive
system faces in a specific context should be considered when measuring
the overall efficiency of a coding scheme, not merely the degree of
compression of the incoming sensory signal (p. 1210).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref12"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>For examples of this kind of reasoning, see <span
class="citation" data-cites="Clark13">Clark (2013)</span>, p. 190; <span
class="citation" data-cites="Lupyan15">Lupyan (2015)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>See characterisations in <span class="citation"
data-cites="Macpherson12">Macpherson (2012)</span>; <span
class="citation" data-cites="FirestoneScholl16">Firestone &amp; Scholl
(2016)</span>. One could also define a ‘top-down effect’ in terms of how
various high-level states in predictive coding’s subpersonal
computational model change the subject’s physically (non-intentionally)
characterised behaviour (e.g. physical button presses by a subject
during a psychophysics experiment). Such a claim <em>would</em>
plausibly fall within the scope of predictive coding’s model, but its
relationship to top-down effects as standardly defined is not obvious.
Thanks to Matteo Colombo for this point.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref14"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>For critical discussion of this point with respect to
<span class="citation" data-cites="Seth21">Seth (2021)</span>’s
proposals about personal-level experience, see <span class="citation"
data-cites="Sprevak22">Sprevak (2022)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>See <span class="citation"
data-cites="Macpherson17">Macpherson (2017)</span>; <span
class="citation" data-cites="Drayson17">Drayson (2017)</span> for
further development of this line of argument. They suggest that
predictive coding’s computational model is compatible with <em>no</em>
top-down effects occurring at the personal level at all.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation" data-cites="Neisser67">Neisser
(2014)</span>, p. xvi.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>For example, <span class="citation"
data-cites="Marr82">Marr (1982)</span>: ‘… top-down information is
sometimes used and necessary … The interpretation of some images
involves more complex factors as well as more straightforward visual
skills. This image [a black-and-white picture of a Dalmatian] devised by
R. C. James may be one example. Such images are not considered here.’
(pp. 100–101).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>See <span class="citation"
data-cites="Gregory97">Gregory (1997)</span>; <span class="citation"
data-cites="PoeppelBever10">Poeppel &amp; Bever (2010)</span>; <span
class="citation" data-cites="YuilleKersten06">Yuille &amp; Kersten
(2006)</span>. <span class="citation"
data-cites="FirestoneScholl16">Firestone &amp; Scholl (2016)</span>
suggest that endogenous attention requires subpersonal top-down
information flow inside a computational model (p. 14).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref19"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><span class="citation" data-cites="Dennett91">Dennett
(1991)</span> argues that these kinds of external ‘virtual wires’, which
loop into the environment, can enable sophisticated forms of top-down
information processing, including those characteristic of rational
thought (pp. 193–199).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>For example, see <span class="citation"
data-cites="Bishop06">Bishop (2006)</span>, pp. 1–12 and <span
class="citation" data-cites="Hohwy13">Hohwy (2013)</span>, pp. 42–46.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>Note that a ‘prediction’ need not be about the future.
A prediction is an estimate concerning something that the system does
not already know. In principle, a prediction might concern what happened
in the past, what is happening in the present, or what will happen in
the future. For a helpful review of the relevant notion of prediction,
see <span class="citation" data-cites="LangeHeilbronKok18">Lange et al.
(2018)</span>, p. 766, Box 2 and <span class="citation"
data-cites="Forster08">Forster (2008)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref22"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>Strictly speaking, AI systems aim to minimise a
<em>cost function</em>, which combines prediction error with other
factors. A common cost function is the prediction error plus the sum of
the squares of the model’s parameters. The latter serves as
regularisation term that penalises more complex models. For discussion,
see <span class="citation" data-cites="RussellNorvig10">Russell &amp;
Norvig (2010)</span>, pp. 709–713.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref23"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>For example, <span class="citation"
data-cites="Bishop06">Bishop (2006)</span>; <span class="citation"
data-cites="MacKay03">MacKay (2003)</span>; <span class="citation"
data-cites="Barber12">Barber (2012)</span>; <span class="citation"
data-cites="Matloff17">Matloff (2017)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref24"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p>There are a wide range of computational models of
learning and decision-making that attribute the goal of minimising
prediction error over reward signals to the brain <span class="citation"
data-cites="SchultzDayan97 NivSchoenbaum08">(Niv &amp; Schoenbaum 2008;
Schultz et al. 1997)</span>. Although these models bear a family
resemblance to predictive coding, advocates of predictive coding are
generally clear that the two approaches are distinct <span
class="citation" data-cites="Friston09">(Friston 2009)</span>. However,
see <span class="citation"
data-cites="FristonSchwartenbeckFitzGerald13">Friston et al.
(2013)</span>; <span class="citation"
data-cites="SchwartenbeckFitzGeraldMathys15">Schwartenbeck et al.
(2015)</span> for an attempt to show that minimising reward prediction
error can be reconceptualised as minimising a measure of expected
free-energy that is also associated with sensory prediction error<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 2.3.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p>For examples, see <span class="citation"
data-cites="ChaterTenenbaumYuille06">Chater et al. (2006)</span>; <span
class="citation" data-cites="Danks19">Danks (2019)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p>The subjective probabilities in question are formally
handled in a similar manner to subjective probabilities inside classical
formulations of Bayesianism – i.e. as degrees of belief or credences of
some reasoning agent <span class="citation"
data-cites="deFinetti90 Ramsey90">(de Finetti 1990; Ramsey 1990)</span>.
However, unlike in traditional treatments, these subjective
probabilities need not be ascribed to the entire agent; they may be
ascribed to subpersonal parts of the agent (e.g. to individual brain
regions, neural populations, or single neurons) <span class="citation"
data-cites="Deneve08 PougetBeck13">(for example, see Deneve 2008; Pouget
et al. 2013)</span>. For discussion of how the concept of subjective
probability should be applied to subpersonal parts of agents, see <span
class="citation" data-cites="Icard16">Icard (2016)</span>; <span
class="citation" data-cites="Rescorla20">Rescorla (2020)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><span class="citation"
data-cites="ChaterOaksford08">Chater &amp; Oaksford (2008)</span>; <span
class="citation" data-cites="KnillPouget04">Knill &amp; Pouget
(2004)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref29" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p>Bayesian updating is not the only option for handling
inference under uncertainty. Plenty of rules and heuristics do not fit
the Bayesian norms but still generate adaptive behaviour <span
class="citation"
data-cites="BowersDavis12 ColomboElkin18 EberhardtDanks11 RahnevDenison18">(Bowers
&amp; Davis 2012; Colombo et al. 2021; Eberhardt &amp; Danks 2011;
Rahnev &amp; Denison 2018)</span>. <span class="citation"
data-cites="Rahnev17">Rahnev (2017)</span> considers the possibility
that brains do not store full probability distributions, but only a few
categorical samples or summary statistics (e.g. variance, skewness,
kurtosis) and use these partial measures to generate adaptive
behaviour.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref30" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p>For an introduction to sampling methods (e.g. Markov
chain Monte Carlo methods or particle filtering), see <span
class="citation" data-cites="Bishop06">Bishop (2006)</span>, Ch. 11. For
an introduction to variational methods, see <span class="citation"
data-cites="Bishop06">Bishop (2006)</span>, Ch. 10.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref31"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p>For exploration of the idea that the brain uses a
sampling method, see <span class="citation"
data-cites="FiserBerkes10">Fiser et al. (2010)</span>; <span
class="citation" data-cites="GriffithsVul12">Griffiths et al.
(2012)</span>; <span class="citation"
data-cites="HoyerHyvarinen03">Hoyer &amp; Hyvärinen (2003)</span>; <span
class="citation" data-cites="MorenoBoteKnillPouget11">Moreno-Bote et al.
(2011)</span>; <span class="citation"
data-cites="SanbornChater16">Sanborn &amp; Chater (2016)</span>; <span
class="citation" data-cites="SanbornChater17">Sanborn &amp; Chater
(2017)</span>. Predictive coding is an example of a view that holds that
the brain uses a variational method for approximate Bayesian
inference.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p><span class="citation" data-cites="Sprevak20b">Sprevak
(forthcoming)</span>, Section 8; <span class="citation"
data-cites="SprevakSmith23">Sprevak &amp; Smith (2023)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p><span class="citation" data-cites="Sprevak20c">Sprevak
(forthcoming)</span>, Section 5.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref34" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p><span class="citation" data-cites="Sprevak20d">Sprevak
(forthcoming)</span>, Section 3.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref35" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p><span class="citation"
data-cites="AitchisonLengyel17">Aitchison &amp; Lengyel (2017)</span>
consider how predictive coding’s proposals might be changed if its
algorithm for variational Bayesian inference were replaced with a
sampling algorithm (pp. 223–224).<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref36"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p><span class="citation"
data-cites="KellerMrsciFlogel18">Keller &amp; Mrsci-Flogel
(2018)</span>, pp. 424–425. <span class="citation"
data-cites="Blakemore99">Blakemore et al. (1999)</span> use a model of
this kind to explain why it is difficult to tickle yourself.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p><span class="citation" data-cites="Grush04">Grush
(2004)</span>; <span class="citation"
data-cites="KordingWolpert04">Körding &amp; Wolpert (2004)</span>; <span
class="citation" data-cites="KordingWolpert06">Körding &amp; Wolpert
(2006)</span>; <span class="citation" data-cites="Rescorla18">Rescorla
(2018)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref38" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p>Bayes’ theorem is <span class="math inline">\(P(Y \mid
X) = P(Y \mid
X)P(Y)/P(X)\)</span>, and follows from standard axioms and definitions
of probability theory. Bayes’ rule (referenced in Section 5) says that
an agent’s subjective probabilities should be updated using Bayesian
conditionalisation, <span class="math inline">\(P_{t+1}(Y) = P_{t}(Y
\mid X)\)</span>; its justification does not follow from the axioms of
probability <span class="citation" data-cites="Strevens08">(Strevens
2017)</span>.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref39" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p>A discriminative model estimates the probability of a
latent variable, <span class="math inline">\(Y\)</span>, given an
observation, <span class="math inline">\(x\)</span>, i.e. <span
class="math inline">\(P(Y \mid X=x)\)</span>. A generative model is
defined either as the likelihood function, i.e. the probability of an
observation, <span class="math inline">\(X\)</span>, given some hidden
state of the world, <span class="math inline">\(y\)</span>, <span
class="math inline">\(P(X \mid Y=y)\)</span>; or, as the full joint
probability distribution, <span class="math inline">\(P(X, Y)\)</span>.
The difference between these rarely matters in practice as the joint
probability distribution equals the product of the likelihood and the
system’s priors over those unobserved states, <span
class="math inline">\(P(X, Y) = P(X \mid Y) P(Y)\)</span>, and both
likelihood and priors need to be known to invert the model under Bayes’
theorem.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref40" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p>The reasons why generative models provide these
advantages are complex and depend partly on the contingent way our world
is structured. For a brief intuitive explanation, see <span
class="citation" data-cites="RussellNorvig10">Russell &amp; Norvig
(2010)</span>, pp. 497, 516–517.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref41" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p>See <span class="citation" data-cites="Bishop06">Bishop
(2006)</span>, Ch. 4 on creating discriminative classifiers using
generative models. See <span class="citation"
data-cites="ChaterManning06">Chater &amp; Manning (2006)</span>; <span
class="citation" data-cites="Kriegeskorte15">Kriegeskorte (2015)</span>;
<span class="citation" data-cites="PoeppelBever10">Poeppel &amp; Bever
(2010)</span>; <span class="citation"
data-cites="TenenbaumKemp11">Tenenbaum et al. (2011)</span>; <span
class="citation" data-cites="YuilleKersten06">Yuille &amp; Kersten
(2006)</span> for various proposals about how the brain uses generative
models to answer discriminative queries in cognition.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref42"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p><span class="citation"
data-cites="WolpertGhahramaniFlanagan01">Wolpert et al. (2001)</span>;
<span class="citation" data-cites="Grush04">Grush (2004)</span> suggest
this. They also suggest that this motor model is not implemented in the
neocortex but in the cerebellum.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref43" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p><span class="citation" data-cites="NgJordan02">Ng &amp;
Jordan (2002)</span> consider conditions under which it is more
efficient to learn a discriminative model of a domain directly than
learn a generative model first and then invert it. <span
class="citation" data-cites="RainaShenMcCallum03">Raina et al.
(2003)</span>; <span class="citation"
data-cites="LasserreBishop06">Lasserre et al. (2006)</span> examine a
range of hybrid discriminative-generative approaches to inference.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref44" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 2.5; <span
class="citation" data-cites="Sprevak20d">Sprevak (forthcoming)</span>,
Section 6.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref45" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p><span class="citation" data-cites="Colombo17">Colombo
(2017)</span> argues that Clark sometimes interprets predictive coding
as a broad vision.<a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#fnref46" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div>

                            </div>
                            
                        </div>

                    </div>

                    <div class="is-col is-33">     
                        <div class="is-hidden-print is-hidden-mobile is-sticky">
                            
                                <h1 style="margin-top: 0px;">Contents</h1>
                                <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#efficient-neural-coding"><span style="visibility: visible;">2</span> &nbsp;  Efficient neural coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#top-down-expectation-driven-effects-in-perception"><span style="visibility: visible;">3</span> &nbsp;  Top-down, expectation-driven effects in perception</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#minimising-prediction-error"><span style="visibility: visible;">4</span> &nbsp;  Minimising prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#cognition-as-a-form-of-probabilistic-inference"><span style="visibility: visible;">5</span> &nbsp;  Cognition as a form of probabilistic inference</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#cognition-uses-a-generative-model"><span style="visibility: visible;">6</span> &nbsp;  Cognition uses a generative model</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-i-introduction-40b2/#conclusion"><span style="visibility: visible;">7</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                            
                            
                            <div style="border-bottom: 0; padding-bottom: 10px; width:80%; margin-left: auto; margin-right: auto;">
                                <img src="https://marksprevak.com/img/pubs/phil-compass.jpg" alt="">
                            </div>
                            
                        </div>
                    </div>
                </div>
            </main>

        <footer class="footer"></footer>

        </div>

        <script src="https://marksprevak.com/kube/js/kube.min.js"></script>
<script>
    $K.init();
</script>


    </body>
</html>
