<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Predictive coding II: The computational level | Mark Sprevak</title>
        <meta name="description" content="">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" href="https://marksprevak.com/kube/css/kube.min.css" />
<link rel="stylesheet" href="https://marksprevak.com/css-customisations/sprevak.css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<title>Mark Sprevak</title>
<base href="https://marksprevak.com/">
<link rel="canonical" href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,700%7CLato:400,700" rel="stylesheet">

    </head>
    <body>
        <div class="page wrapper">

            <header class="header">
                <div class="is-navbar-container" style="padding-bottom: 6px; padding-top: 0px; margin-bottom: 12px; border-bottom: 1px solid; border-color: rgba(0, 0, 0, 0.3);">
    <div class="is-brand">
        <div class="titlebar"><a href="https://marksprevak.com/">Mark&nbsp;Sprevak</a></div>
        
        <a href="#"
                style="color: rgba(0, 0, 0, 0.8); text-decoration: none; border-bottom: none; font-size:18px;"
                class="is-hidden-print nav-toggle is-push-right-mobile is-shown-mobile icon-kube-menu"
                data-kube="toggle"
                data-target="#top-navbar"></a>
    </div>
    <div id="top-navbar" class="is-navbar is-hidden-print is-hidden-mobile">
        <nav class="is-push-right">
            <ul style="text-align: right;">
                
                
                
                
                
                <li  >
                    <a href="https://marksprevak.com/publications/" style="text-decoration: none; border-bottom: none;">Publications</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/talks/" style="text-decoration: none; border-bottom: none;">Talks</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/outreach/" style="text-decoration: none; border-bottom: none;">Outreach</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/cv/" style="text-decoration: none; border-bottom: none;">CV</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/phds/" style="text-decoration: none; border-bottom: none;">PhD study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/mscs/" style="text-decoration: none; border-bottom: none;">MSc study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/teaching/" style="text-decoration: none; border-bottom: none;">Teaching</a>
                </li>
                
                
            </ul>
        </nav>
    </div>
</div>

            </header>

            <main class="main">
                <div class="is-row">

                    <div class="is-col is-67">     

                        <div style="padding-bottom: 30px;">
                            <div style="margin-bottom: 10px;">
                                <h1 class="is-color-black" style="margin-top: 0px; margin-bottom: 0px;">Predictive coding II: The computational level</h1>
                                
                                <p class="is-muted" style="margin-top: 10px;">
                                    
                                        draft  &nbsp;
                                    
                                    
                                </p>
                                <p class="is-small" style="margin-top: 10px;">
                                    <span>Last updated 22 May 2022</span>
                                    
                                </p>
                            </div>
                            <div class="is-hidden-print">
                                
<a href="https://marksprevak.com/pdf/paper/Sprevak--Predictive-Coding-2-Computation.pdf" target="_blank" class="label is-primary is-focus" style="margin-left: 0px; margin-right:5px;">
    <i class="far fa-file-pdf" style="font-size: 12px;"></i>
    &nbsp;PDF
</a>



<a href="http://philsci-archive.pitt.edu/id/eprint/20641" target="_blank" class="label is-tertiary is-focus" style="margin-left: 0; padding-left: 0; margin-right:2px;">
    preprint
</a>



                            </div>
                        </div>

                        <div class="is-hidden-mobile">
                            
                            <div class="article-style" style="margin-left: 30px; margin-right: 30px; margin-bottom: 30px;">
                                <p>What computational problem does the brain face in cognition? This
question defines Marr&#x2019;s computational level of explanation. I argue that
predictive coding departs from other paradigms by suggesting that the
brain faces just one computational problem across all aspects of
cognition: to minimise its long-term precision-weighted sensory
prediction error. In the first half of this paper, I explore what is
normally meant by this claim. There is agreement about its broad shape
and informal character, but providing a precise characterisation is
still an open issue. In the second half of the paper, I turn to the
justification of the claim. I explore three strategies used to defend
it: the case-based defence, the free-energy defence, and the
instrumental-value defence. I argue that each faces challenges.</p>

                            </div>
                            
                        </div>
                        <div class="is-shown-mobile">
                            
                            
                            <div class="is-muted is-smaller is-hidden-print">
                                Abstract:
                            </div>
                            <div class="article-style" style="margin-bottom: 30px;">
                                <p>What computational problem does the brain face in cognition? This
question defines Marr&#x2019;s computational level of explanation. I argue that
predictive coding departs from other paradigms by suggesting that the
brain faces just one computational problem across all aspects of
cognition: to minimise its long-term precision-weighted sensory
prediction error. In the first half of this paper, I explore what is
normally meant by this claim. There is agreement about its broad shape
and informal character, but providing a precise characterisation is
still an open issue. In the second half of the paper, I turn to the
justification of the claim. I explore three strategies used to defend
it: the case-based defence, the free-energy defence, and the
instrumental-value defence. I argue that each faces challenges.</p>

                            </div>
                            
                        </div>

                        <div>
                            
                            <div class="is-shown-mobile">
                                
                                    <h1 style="margin-top: 0px;" id="internal-mds-toc">Contents</h1>
                                    <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#minimising-sensory-prediction-error"><span style="visibility: visible;">2</span> &nbsp;  Minimising sensory prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#formal-and-informal-descriptions"><span style="visibility: visible;">3</span> &nbsp;  Formal and informal descriptions</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#precision-weighting-of-prediction-errors"><span style="visibility: visible;">4</span> &nbsp;  Precision weighting of prediction errors</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#long-term-prediction-error-and-the-dark-room-objection"><span style="visibility: visible;">5</span> &nbsp;  Long-term prediction error and the dark-room objection</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#evidence-for-predictive-coding"><span style="visibility: visible;">6</span> &nbsp;  Evidence for predictive coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-case-based-defence"><span style="visibility: visible;">7</span> &nbsp;  The case-based defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-free-energy-defence"><span style="visibility: visible;">8</span> &nbsp;  The free-energy defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-instrumental-value-defence"><span style="visibility: visible;">9</span> &nbsp;  The instrumental-value defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#conclusion"><span style="visibility: visible;">10</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                                
                                
                            </div>
                            <div class="article-style">
                                <div>
<h1 data-number="1" id="introduction"><span
class="header-section-number">1</span> Introduction</h1>
<p>When we encounter a new computing device, we often try to describe
its computational characteristics in terms of the task it faces: this
shop’s cash register has the task of <em>adding numbers</em>, this
computer programme has the task of <em>sorting names into alphabetical
order</em>, this Excel spreadsheet has the task of <em>calculating
losses</em>. As well as asking a <em>how</em>-question about the device
– How does it work? – we might ask a <em>what</em>-question: What is the
problem the device is trying to solve? A theory at Marr’s computational
level aims to provide an answer to this question. It aims to identify
the <em>computational task</em> that a device faces.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>What is the computational problem faced by the brain? Conventional
approaches in computational cognitive science tend to start from the
assumption that the brain faces many computational problems. Different
aspects of cognition – e.g. perception, motor control, decision making,
language learning – require the brain to respond to different
information-processing challenges. Each challenge has its own
computational nature and is likely to deserve its own Marrian
computational-level description. On such a picture, it makes sense for
computational cognitive science to adopt a <em>divide et impera</em>
strategy to modelling cognition: it should break up human cognition into
multiple constituent computational problems, each of which should be
described in turn.</p>
<p>Predictive coding suggests that this <em>divide et impera</em>
strategy, and the ‘many problems’ assumption on which it is based, is
wrong. During cognition, the brain faces a <em>single</em> computational
problem. At Marr’s computational level, one unified story should be
told. Apparent differences between different challenges encountered in
perception, motor control, decision making, language learning, and so on
mask an underlying unity that all these problems share. They are all
instances of a single overarching problem: to <em>minimise sensory
prediction error</em>.</p>
<p>Sections 2–4 attempt to unpack what is meant by this. Sections 5–8
turn to the claim’s justification. I outline three main strategies an
advocate of predictive coding might draw on to defend it: the
<em>case-based</em> defence (Section 7), the <em>free-energy</em>
defence (Section 8), and the <em>instrumental-value</em> defence
(Section 9).</p>
<h1 data-number="2" id="minimising-sensory-prediction-error"><span
class="header-section-number">2</span> Minimising sensory prediction
error</h1>
<p>What does it mean to say that the brain is trying to minimise its
sensory prediction error? As we will see, there are a variety of ways of
formalising this task in mathematical language. However, an advocate of
predictive coding often starts with an <em>informal</em> description of
the task. Subsequent mathematical descriptions aim to codify this
informal description more precisely and open it up to proposals that it
is tackled by various numerical algorithms. In predictive coding, there
is currently some degree of uncertainty about exactly the right way to
formalise the task of minimising sensory prediction error in
mathematical terms. However, there is broad agreement about the
<em>informal</em> nature of the problem. We will begin with this
informal description.</p>
<p>The task of <em>minimising sensory prediction error</em> may be
informally characterised as follows. Brains have sensory organs and
their sensory organs supply them with a continuous stream of input from
the outside world. Brains also have complicated endogenous physical
structures and activities that determines how they react to that stream
of input. According to predictive coding, the computational task that a
brain faces in cognition is to ensure that these endogenously generated
responses (the brain’s ‘inference’ over its ‘generative model’) cancel
out or suppress the incoming flux of physical signals conveyed by the
sensory organs from the outside world (that it ‘predicts’ the incoming
‘sensory evidence’). The degree to which this happens, or fails to
happen, is measured by the <em>sensory prediction error</em>. This
quantity measures the discrepancy between the contribution of the
brain’s endogenously generated activities and the incoming physical
signals from the world. According to predictive coding, the problem that
the brain faces, in all aspects of cognition, is to minimise this
discrepancy. If the brain were to succeed at doing this then, at the
sensory boundary, two opposing forces – the world’s sensory input
(excitatory/stimulating) and the brain’s endogenously generated
predictions (inhibitory/suppressing) – would exactly cancel out. The
brain’s anticipatory signal would ‘quench’ incoming excitation from the
world. In more colourful and metaphorical language:</p>
<blockquote>
<p>… this is the state that the cortex is trying to achieve: perfect
prediction of the world, like the oriental Nirvana, as Tai-Sing Lee
suggested to me, when nothing surprises you and new stimuli cause the
merest ripple in your consciousness. <span class="citation"
data-cites="Mumford92">(Mumford 1992 p. 247, n. 5)</span></p>
</blockquote>
<p>Predictive coding is a theory is about the subpersonal computational
machinery of cognition, not our conscious personal-level experience, but
the basic idea is correct. The computational task the brain faces is to
avoid being perturbed or surprised by incoming sensory inputs (in the
Shannon sense of ‘surprise’, i.e. unpredicted). The brain’s goal is to
arrange itself and its physical responses to anticipate and cancel
upcoming sensory input. This goal – ‘Nirvana’ in the above quotation –
is unlikely to ever be achieved, or achieved in any sustained way,
because the sensory inputs supplied by the world are too rich and
complex for our brains to always predict them with perfect accuracy.
Nevertheless, <em>trying</em> to predict them is the task the brain
faces in cognition.</p>
<p>Predictive coders suggest that the various computational problems
that the brain faces in perception, learning, motor control, decision
making, and so on, are all instances of minimising sensory prediction
error. Our various cognitive capacities (sensing, planning, and so on),
which have traditionally been viewed as dissociable responses to
distinct problems (faced in perception, motor control, and so on),
should perhaps be reconceived as parts of a seamless, unified response
by the brain to a single problem. This all suggests that we might need
to rethink how we describe and individuate our cognitive capacities, and
potentially blur the boundaries between them. It is in this sense that,
at Marr’s computational level, predictive coding aims to offer a grand,
unified theory of cognition.</p>
<p>It worth stressing that is not novel or unusual to suggest that
minimising sensory prediction error is <em>one</em> of the computational
challenges faced by the brain. Contemporary models often suggest that
early vision involves compression of sensory signals <span
class="citation" data-cites="Sprevak20a">(Sprevak forthcoming sec.
2)</span> and certain inference and learning tasks are often described
as minimising sensory prediction error (ibid., Section 4). What marks
out predictive coding as special in this context is that it says that
minimising sensory prediction error is the brain’s <em>only</em>
computational task. It is not one among many objectives pursued by the
brain, but the only or the fundamental objective. The elevated status of
this one task is the primary feature that differentiates predictive
coding from other approaches.</p>
<h1 data-number="3" id="formal-and-informal-descriptions"><span
class="header-section-number">3</span> Formal and informal
descriptions</h1>
<p>Theories at Marr’s computational level are often precise and
characterised in mathematical language. They are usually <em>formal</em>
and <em>quantitative</em>. Typically, a theory at Marr’s computational
level will ascribe computation of a mathematical function to the brain
as well as offering an explanation of why computing that function would
help the brain solve a problem that is informally characterised. For
example, in his account of vision, Marr ascribed computation of the
mathematical function <span class="math inline">\(\nabla ^2 G \ast
I\)</span> to the brain. Marr related this problem to the informally
characterised task of <em>edge detection</em>: finding the location of
boundaries between objects in the visual field.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
Marr argued that edge detection is an important problem that the brain
faces in early vision and that solving it is a preliminary step to
solving other problems such as object recognition, depth perception, or
binocular fusion. Marr proposed that the informal task of edge detection
could be more precisely described as the task of computing of this
mathematical function.</p>
<p>In Marr’s formal description, <span class="math inline">\(I\)</span>
is a two-dimensional matrix of numerical values. These values quantify
the magnitude of light falling on a two-dimensional array of
photoreceptors on the retina. <span class="math inline">\(G\)</span> is
a Gaussian filter which is convolved (<span
class="math inline">\(\ast\)</span>) with the two-dimensional image
(<span class="math inline">\(I\)</span>) and the Laplacian,
second-derivative operator (<span class="math inline">\(\nabla
^2\)</span>) is applied to the result. Marr argued that if the brain
were to compute the zero-crossings of this function for various sizes of
Gaussian filter, it would identify areas in the retinal image that
correspond to sharp changes in light intensity. These, Marr argued, tend
to coincide with the edges of objects in the visual field. Hence, the
task of computing the zero-crossings of this mathematical function
provides a precise, mathematically codified formalisation of the
(informally characterised) problem of edge detection.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>One way in which this relationship is described is that between a
‘what’ element and a ‘why’ element of a computational-level theory.<a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> The ‘what’ element in a
computation-level theory describes the mathematical function that the
device needs to compute. In the above case, this would be <span
class="math inline">\(\nabla ^2 G \ast I\)</span>. The ‘why’ element
links the task of computing that mathematical function to some
informally characterised information-processing problem. It draws a
connection between the values that feature in the function and physical
quantities and the concrete adaptive problems faced by the embodied
device. In the case above, it involves explaining why computing <span
class="math inline">\(\nabla ^2 G \ast I\)</span> would help an embodied
system solve the problem of detecting edges in the visual field. Marr’s
‘what’ element provides a formal, mathematical characterisation of the
task; the ‘why’ element explains the appropriateness and adequacy of
that mathematical description to the task as informally conceived.<a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>There are many possible ways one might attempt to formalise the task
of minimising sensory prediction error. Predictive coding has not yet
settled on a single canonical formalisation. A simple example of a
formalisation is given in <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 2.1.<a
href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> However, even in more complex
mathematical treatments, it is common to assume a highly simplified or
stripped-down version of the task. For example, it is common to consider
systems with only one or two sensory input channels, to only attempt to
minimise their current prediction errors, or to only consider
predictions from a linear generative model. Such simplifications not
only help to keep the formalisation manageable, they may also serve to
highlight specific features of interest in the intended model.</p>
<p>Nevertheless, some broad generalisations can be made about predictive
coding’s formal task description. All mathematical formalisations tend
to treat the task as a numerical <em>optimisation problem</em>. That
problem is regarded as having two free variables – the <em>generative
model</em> and the <em>prediction values</em>. Those variables are
changed, on different timescales, in order to find the global minimum of
an objective function – the <em>sensory prediction error</em>. In the
simplest case, the generative model is formalised as a two-dimensional
matrix of values. Prediction values are formalised as a vector that,
when combined with a generative model by multiplication, produce another
vector, the <em>sensory prediction</em>. The <em>sensory input</em> is
another vector with the same dimensionality, each of whose components
encode the actual incoming activity of each physical sensory channel.
The <em>sensory prediction error</em> measures how close the sensory
prediction is to the sensory input. It is often treated as the
(weighted) sum or mean of the squares of the difference between the
sensory input vector and the sensory prediction vector. The task the
brain faces is to select prediction values and generative model such
that its prediction errors over sensory inputs are minimised. Describing
the problem in this way allows many existing numerical optimisation
algorithms – including the vast range of algorithms that employ some
form of gradient descent – to be brought to bear as proposals about how
the brain attempts to solve its problem.</p>
<h1 data-number="4" id="precision-weighting-of-prediction-errors"><span
class="header-section-number">4</span> Precision weighting of prediction
errors</h1>
<p>An important element that has not yet been mentioned is that not all
sensory prediction errors are weighted equally in the task of minimising
sensory prediction error. Predictive coding has a third type of
variable, <em>precision weighting</em>, which describes the relative
weight of each sensory prediction error. The brain’s task is thus to
minimise its <em>precision-weighted</em> sensory prediction error.
Errors that have a high degree of precision weighting should be
prioritised during this; errors that have a low precision weighting are
given a lower priority or ignored. Precision weighting describes a
scaling factor or ‘gain’ that is applied to each component of the
sensory prediction error.</p>
<p>Precision weighting is a critically important part of predictive
coding’s task description. It can make certain sensory prediction errors
dominate the optimisation process and others small enough to be
irrelevant. It can exercise this control in very fine-grained, nuanced
ways. Precision weighting can potentially modify the gain on prediction
errors associated with each individual sensory channel independently.
Precision weighting is usually treated as a distribution that determines
which sensory prediction errors are boosted and which are dampened down
at any given moment. The shape of that distribution may be complex and
it may change radically and rapidly over time (e.g. within
milliseconds). Formally, and in the simplest case, precision weighting
is represented as a two-dimensional matrix that is multiplied by the raw
sensory prediction error vector to scale its elements.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn7"
class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Precision weighting plays a number of conceptually distinct
functional roles within predictive coding. First, under a probabilistic
interpretation of predictive coding’s algorithm, it is assumed to be
connected to the brain’s estimation of <em>uncertainty</em> associated
with its sensory predictions. Predictions about which the brain is more
certain have a smaller variance, which is equivalent to them having a
higher precision weighting associated with their corresponding
prediction errors <span class="citation" data-cites="Friston03">(Friston
2003)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> Second, precision weighting is
claimed to be connected to the <em>direction of fit</em> of sensory
predictions. Sensory prediction errors with a high degree of precision
weighting are the ones that will dominate the optimisation process and
on which the brain is more likely to act; they will function as quasi
motor commands (see Section 7). In contrast, prediction errors with a
low degree of precision weighting are less likely to feed into action
and might be used to simulate or imagine actions of the agent or of
other agents without danger of producing an associated motor response
<span class="citation"
data-cites="FristonMattoutKilner11 Clark15 PickeringClark14">(Clark
2016, Ch. 5; Friston et al. 2011; Pickering &amp; Clark 2014)</span>.<a
href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a> Third, precision weighting is
claimed to be connected to the allocation of <em>attention</em>. When
the cognitive system attends to certain features, the components of the
sensory signals associated with those features are the ones for which
the corresponding prediction errors have been assigned a higher
precision weight. When the cognitive system shifts the focus of its
attention, this entails a rebalancing of the distribution of precision
weightings away from those features <span class="citation"
data-cites="FeldmanFriston10">(Feldman &amp; Friston 2010)</span>.<a
href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a> Finally, and most controversially,
precision weighting is sometimes used as a kind of ‘fudge factor’ to
accommodate observations that do not straightforwardly fit into the
prediction-error-minimisation framework. If the brain fails to minimise
a sensory prediction error, then an advocate of predictive coding might
interpret that failure, not as evidence against predictive coding, but
as evidence that the brain has assigned a low precision weighting to
that particular sensory error. If a scientist is allowed to assume any
distribution of precision weightings at any moment in time, almost any
observation can be accommodated under predictive coding’s task
description.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a> Obviously, constraints are needed
on how precision weightings are assigned to a brain. Finding a
sufficient number of empirically motivated constraints on this remains
an open problem for predictive coding.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn12"
class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>The distribution of precision weighting intuitively captures ‘what
matters’ to the brain when it is attempting to minimise its sensory
prediction error. No version of predictive coding can afford to omit
precision weighting: it would simply be implausible to think that every
sensory prediction error matters equally to the brain. However,
introducing precision weighting into predictive coding’s task
description raises a number of puzzles. It plays many roles within
predictive coding’s model and it is not obvious how all those various
roles cohere. It is also not clear which independent, empirically
motivated constraints lie on the assignment of precision weightings
considering its tremendous power to reshape the computational problem
facing the brain.</p>
<h1 data-number="5"
id="long-term-prediction-error-and-the-dark-room-objection"><span
class="header-section-number">5</span> Long-term prediction error and
the dark-room objection</h1>
<p>A second important element of the task description not yet mentioned
is that the objective should be understood as that of minimising
<em>long-term</em> sensory prediction error. That goal might be glossed
in various ways, with expressions such as ‘global’ prediction error
<span class="citation" data-cites="Lupyan15">(Lupyan 2015)</span>,
‘upcoming’ prediction error <span class="citation"
data-cites="Muckli10">(Muckli 2010 p. 137)</span>, ‘long-term average’
of prediction error <span class="citation" data-cites="Hohwy13">(Hohwy
2013 pp. 90, 175, 176)</span>, or ‘long-term average surprise’ <span
class="citation" data-cites="SchwartenbeckFitzGerald13">(Schwartenbeck
et al. 2013)</span>.</p>
<p>The mathematical nature of this long-term objective is, however, not
entirely clear. It is to minimise some form of average of individual
(precision-weighted) sensory prediction errors over time. However, what
type of average, and how far in time that period should extend, is not
clear. It is unknown whether, and to what degree, future prediction
errors should be discounted. It is unknown whether the objective should
be to reduce prediction errors relative to the system’s own expectations
(its subjective probability) of making future sensory prediction errors,
or relative to the objective chances (objective probability) of it
making such errors. It is unknown whether the relevant time period to
minimise errors is of the order of hours, days, years, the entire future
lifespan of the organism, or further to include the lifespans of all its
possible descendants and evolutionary successors. It is unknown how this
average (which weights prediction errors over time) should interact with
precision weighting (which weights the current error signals) –
i.e. whether precision weighting should be understood as having a
prospective component to allow the brain to preferentially discount
certain expected future errors over others. These open questions suggest
that alternative formulations of predictive coding could be developed at
the computational level.</p>
<p>Nevertheless, acceptance that the brain aims to minimise a long-term
measure plays an important role in clarifying and lending plausibility
to predictive coding’s task description. For one thing, it allows one to
understand how predictive coding could respond to the infamous ‘dark
room’ objection. For another, it suggests that predictive coding is
compatible with inferences and behaviour that tend to drive up
short-term sensory prediction error, such as curiosity, exploration, and
novelty seeking.</p>
<p>The dark-room problem is a long-standing objection to predictive
coding.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a> The dark-room problem is to explain
why, if predictive coding’s description at the computational level is
correct, a cognitive agent would not simply seek out the most
predictable possible environment, such as a dark room, and remain inside
for as long as possible. If the goal of cognition is to minimise sensory
prediction errors, why not maximise the chances of achieving this by
staying in a maximally predictable environment?</p>
<p><span class="citation" data-cites="FristonThornton12">Friston et al.
(2012)</span> offered an initial reply to the dark-room problem.<a
href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> Their response focuses on the idea
that our generative model and prediction values are not infinitely
malleable: there are limits to the kinds of predictions we can generate
and to how much our generative model and prediction values can be
revised. These constraints, primarily due to our physical hardware, are
assumed to be immune to change by learning or inference, and are called
‘hyperpriors’. Human hyperpriors bias us towards making certain kinds of
predictions, and not ones that are not particularly suited to life in a
dark room. Although the sensory data inside a dark room might be ‘easy
to predict’ in some disembodied sense, they might be difficult for a
creature <em>like us</em> to predict. If we were a different type of
creature, one that had evolved with different hard-wired biases (maybe a
cave-dwelling creature), we might have no trouble in reliably generating
accurate sensory predictions inside a dark room. However, we are biased
to predict sensory data that come from bright, changeable environments,
and so we are unlikely to minimise our sensory prediction errors inside
a dark room.</p>
<p>This response highlights an important but as yet unmentioned point
about predictive coding’s task description: the problem brain faces is a
<em>constrained</em> optimisation problem. The brain’s objective is to
minimise sensory prediction error by varying a generative model and
prediction values <em>given</em> the constraints imposed by our physical
hardware about how far and how rapidly that generative model and those
prediction values can vary. The literature on predictive coding’s
computational-level proposal tends to be silent about the specific
nature of these physical constraints. However, a crucial part of making
the view plausible is to acknowledge that a range of constraints on the
optimisation problem are implicitly there.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn15"
class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p>
<p><span class="citation" data-cites="FristonThornton12">Friston et al.
(2012)</span>’s reply brings to the fore an important feature of
predictive coding’s computational-level description, but it does not
fully address the concerns that motivated the dark-room problem. For
example, it does not explain why, <em>even relative to a constrained
model</em>, cognitive agents like ourselves still seek out novelty and
surprise. Even when we can predict a situation, we sometimes choose a
more surprising alternative. In other words, cognitive agents like
ourselves sometimes <em>prefer</em> novelty to predictability. How is
that consistent with what predictive coding says at the computational
level?<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>An alternative reply that fares better at addressing this kind of
objection is to emphasise the long-term nature of the brain’s objective.
The world in which we live contains both environments that are easy to
predict and environments and that are hard to predict (for us).
Successfully predicting our sensory inputs only where we can already do
so may not, over the long term, be a good solution to the brain’s
problem. An agent who sequesters itself inside an easy-to-predict
environment leaves itself a hostage to fortune. Unpredictable elements
may intrude on the agent in ways that it has not taken the trouble to
learn how to handle – light might enter the room, a stranger might
enter, food supplies might run out. To guard against future surprises
and an associated rise in sensory prediction error, it may be better –
purely in the terms of the long-term goal of minimising sensory
prediction error – to leave an environment that is easy to predict and
engage in some exploration to learn a more comprehensive model of the
world. Exploring environments that are harder to predict might raise
current sensory prediction errors, but it is a hedge against future,
possibly bigger surprises that an agent who led an entirely sheltered
life would not be able to avoid. There is obviously a balance to strike
here between the cost of exploring (in terms of a rise in current
sensory prediction error), and its potential future pay-off (in terms of
a reduction in long-term sensory prediction error). But that there is a
trade-off between the value of exploration and exploitation is to be
expected on any model of cognition. The important point is that what
predictive coding says at the computational level allows for the
possibility that a cognitive agent may sometimes prefer unpredictable
environments to predictable ones. Curiosity, exploration, and novelty
seeking are consistent with the brain minimising a long-term measure of
sensory prediction error, even if they entail a rise in that error along
the way <span class="citation"
data-cites="SchwartenbeckFitzGerald13">(Schwartenbeck et al.
2013)</span>.</p>
<h1 data-number="6" id="evidence-for-predictive-coding"><span
class="header-section-number">6</span> Evidence for predictive
coding</h1>
<p>Justification for predictive coding’s computational-level claim often
rests on one of three strategies. I call these the <em>case-based</em>
defence, the <em>free-energy</em> defence, and the
<em>instrumental-value</em> defence. The case-based defence considers a
range of cognitive tasks and aims to show that all of these tasks can
and should be described as minimising sensory prediction error. The
free-energy defence shortcuts consideration of individual tasks and
attempts to establish predictive coding’s computational-level general
claim by appeal to Karl Friston’s free-energy principle. The
instrumental-value defence focuses on the utility of predictive coding’s
task description to computational cognitive science and argues that it
provides a desirable set of heuristics to make sense of, and discern
patterns within, the mass of human behavioural and neural responses.</p>
<h1 data-number="7" id="the-case-based-defence"><span
class="header-section-number">7</span> The case-based defence</h1>
<p>The case-based defence is an abductive argument. It attempts to show
that a number of tasks facing the brain – for example, during
perception, decision-making, planning, motor control – can and should be
thought of as instances of the single task of minimising sensory
prediction error. Some of those tasks may already have
computational-level descriptions associated with them based on rival or
more traditional computational research programmes. The job of
predictive coding is to show that these can and should be stated as
instances of minimising sensory prediction error. Behavioural and neural
responses that might previously have been categorised as attempts by the
brain to compute some domain-specific mathematical function should be
redescribed in the manner predictive coding suggests.</p>
<p>Any case-based argument for predictive coding faces an obvious
epistemic hurdle. Predictive coding makes a universal claim –
<em>every</em> problem the brain encounters in cognition is to minimise
sensory prediction error. Showing that this holds in a limited number of
cases (e.g. in aspects of early vision) does not entail that it holds in
other, perhaps as yet unconsidered cases (e.g. language learning). No
amount of success in applying predictive coding’s task description to
limited domains of cognition demonstrates that in <em>every</em> case
the problem the brain faces is minimisation of sensory prediction error.
Nevertheless, science is rife with universal generalisations made on the
back of observations about a limited number of cases. The
non-demonstrative nature of such arguments is not in principle an
objection to using them. However, there are clearly more and less
effective ways of making such an abductive argument work.</p>
<p>One plausible strategy is to focus on a <em>diverse</em> range of
cases – what one might hope is a <em>representative</em> sample of
cases. Early work on predictive coding focused on sensory compression in
the early visual system <span class="citation"
data-cites="RaoBallard99 SrinivasanLaughlinDubs82 Atick92">(Atick 1992;
Rao &amp; Ballard 1999; Srinivasan et al. 1982)</span>. Ideally,
predictive coding should seek support for its wider claim by showing
that other kinds of behavioural and neural response fall under
predictive coding’s task description. If it can be shown that many
behavioural and neural phenomena that have no obvious connection to each
other, or to early vision, can and should fall under predictive coding’s
task description, then that would lend credence to the idea that not
just in some cases, but in every case, the problem the brain faces is
sensory prediction error minimisation. Example of such ‘non-obvious’
applications of predictive coding include music perception <span
class="citation" data-cites="KoelschVuustFriston19">(Koelsch et al.
2019)</span>; formation of emotions and judgements about bodily
ownership <span class="citation" data-cites="Seth13">(Seth 2013)</span>;
binocular rivalry <span class="citation"
data-cites="HohwyRoepstorff08">(Hohwy et al. 2008)</span>; formation of
judgements about the nature of the self <span class="citation"
data-cites="HohwyMichael17">(Hohwy &amp; Michael 2017)</span>; and the
perceptual, doxastic, and motor characteristics of schizophrenia and
autism <span class="citation"
data-cites="FletcherFrith09 CorlettFletcher14 PellicanoBurr12 FristonStephanMontague14">(Corlett
&amp; Fletcher 2014; Fletcher &amp; Frith 2009; Friston et al. 2014;
Pellicano &amp; Burr 2012)</span>.</p>
<p>It is worth noting that, with respect to each individual case, a
case-based argument requires one to meet two separate challenges. The
first challenge is to show that the case in question <em>can</em> be
described as an instance of sensory-prediction-error minimisation. The
second is to show that it <em>should</em> be described this way. The
first challenge requires one to show that predictive coding’s
computational-level description is <em>consistent</em> with the
behavioural or neural data associated with that case. The second is to
show that cognitive psychology should <em>prefer</em> predictive
coding’s computational-level description of that data to rival or more
traditional accounts. There should be some net <em>benefit</em> to
adopting predictive coding’s computational-level treatment of that
instance of cognition – e.g. in terms of increased predictive accuracy,
increased explanatory power, or some other epistemic virtue.</p>
<p>Predictive coding’s flagship example of a ‘non-obvious’ application
of its computational-level description is <em>motor control</em>.<a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a> Traditional computational
approaches to cognition tend to treat perception and motor control as
entirely separate problems. In perception, the task facing the brain is
to use its sensory data and background knowledge to build an accurate
(or an instrumentally adequate) model of the world. In motor control,
the task facing the brain is to use that model, along with some set of
goals or intentions, to output a sequence of motor commands that would
direct muscle actuators towards accomplishing those goals or intentions.
Of course, motor control might partly rely on solving the perceptual
problem. Motor control problems often require an agent to first build an
accurate perceptual model of the world. Rapid and complex motor control
might also require online regulation by sensory predictions from a
forward model <span class="citation"
data-cites="FranklinWolpert11">(Franklin &amp; Wolpert 2011)</span>.
However, even if the problems of motor control and perception have some
degree of overlap, they remain distinct problems: the task of perception
is to create an accurate model of the world; the task of motor control
is to use that model to generate motor commands to fulfil goals.</p>
<p>According to predictive coding, perception and motor control are
instances of the same problem, namely, that of minimising sensory
prediction error. In perception, the brain minimises sensory prediction
error by varying its generative model and prediction values to
anticipate upcoming sensory input. In motor control, the brain minimises
its sensory prediction error by varying its bodily position and the
external world (via muscle actuators) to change its incoming sensory
stream to make its internally generated sensory predictions more likely
to be true. In both cases, the objective is the same – to minimise
sensory prediction error. The difference lies in the method the
cognitive system uses to try to achieve it. Advocates of predictive
coding call the first method ‘passive’ inference and the second ‘active’
inference. Passive and active inference (perception and motor control)
are claimed to be complementary strategies employed by the brain to
address what is fundamentally the same problem. According to predictive
coding, the task of reaching for a glass of water should be
reconceptualised as the brain making the prediction that the hand is
already holding the glass of water (along with all its sensory
consequences), and then solving its problem – minimising its sensory
prediction error – by varying its limbs and the glass to make this false
sensory prediction true.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn18" class="footnote-ref"
id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<p>Even if perceptual tasks and motor tasks <em>can</em> both be
described as instances of sensory prediction error minimisation, it
remains a further question whether they <em>should</em> be described
this way. The justification for this second step is often not obvious.
The benefits of predictive coding’s proposed task description are not
straightforward to calculate and they need to be estimated relative to a
wide range of epistemic standards, interests, and goals in computational
cognitive science. Different researchers may, with good reason, take
different views about the value of the benefits on offer.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn19"
class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>
As we will see shortly, those benefits are also often presented as
conditional on accepting other elements of predictive coding’s research
programme (e.g. the universal scope of its claim, or elements of its
proposals at the algorithmic or implementation levels).</p>
<p>To illustrate how these questions about the benefits of predictive
coding’s approach might be addressed, we will switch to a simpler case:
the early visual system. Two main strategies have been used to defend
predictive coding’s computational-level description in this context: (i)
appeal to what it can explain and predict relative to more traditional
computational approaches; (ii) appeal to broader theoretical virtues
offered by the view (e.g. its simplicity, elegance, and unifying
power).</p>
<p>The first set of considerations surround predictive coding’s ability
to predict and explain behavioural or neural responses that are
generally regarded as puzzling or anomalous on other views. Traditional
computational-level characterisations of the early sensory system
suggest that its computational task is to function as a Gabor filter
bank on retinal images and thereby extract ecologically salient stimulus
features such as orientation, spatial frequency, colour, direction of
motion, and disparity <span class="citation"
data-cites="CarandiniDemb05">(Carandini et al. 2005)</span>. In formal
terms, the computational task of the early visual system is to convolve
a matrix of retinal data with a variety of Gabor filters to, e.g., pick
out lines in the visual field of various orientation and spatial
frequency. However, many responses of neurons observed in the early
visual system do not fit that description <span class="citation"
data-cites="OlshausenField05">(Olshausen &amp; Field 2005)</span>. These
so-called ‘non-classical’ effects count as anomalies relative to the
visual system’s claimed objective. One such ‘non-classical’ effect is
<em>end-stopping</em>: some V1 neurons give a strong response to a line
at a particular orientation in the visual field, but that response is
reduced or eliminated if the line extends outside the neuron’s receptive
field. End-stopping is inconsistent with a simple Gabor-filter
description of their computational role: a classical Gabor filter should
continue to fire regardless of whether a line extends outside its
receptive field. End-stopping is categorised as anomalous under
traditional computational-level descriptions of the early visual
system.</p>
<p>Predictive coding suggests that the computational task faced by the
early visual system is not to perform Gabor filtering, but to contribute
to minimising the brain’s sensory prediction error. Under predictive
coding’s task description, the behaviour of the relevant neurons within
V1 may be reinterpreted as signalling the difference between the current
sensory input and the brain’s sensory prediction (based on its
statistically-informed expectations regarding likely visual input). In
our environment, the statistical norm is for lines in our visual field
to extend beyond the tiny regions covered by the receptive fields of
individual neurons. Lines that violate this expectation are unusual and,
everything being equal, should be expected to generate prediction
errors. The behaviour of V1 cells when end-stopping may be reinterpreted
as signalling such sensory prediction errors <span class="citation"
data-cites="RaoBallard99 KokLange15">(Kok &amp; Lange 2015 p. 232; Rao
&amp; Ballard 1999)</span>. End-stopping, not accommodated by
traditional computational-level descriptions, can potentially be
accommodated under predictive coding’s computational-level
description.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn20" class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a></p>
<p>A second set of motivations for preferring predictive coding’s
computational-level description surround its general theoretical virtues
such as its simplicity, scope, and unifying power with respect to other
approaches. Arguably, even if predictive coding were to do no better
than any other model at accommodating various behavioural/neural
effects, these general theoretical virtues might still lead one to
favour the view. As observed in Section 1, traditional
computational-level approaches to cognition tend to adopt a <em>divide
et impera</em> approach and assume that the brain is facing multiple
computational problems. On such a view, the brain is treated as an
inherently multifunctional device, not a device tuned to solve just one
problem.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn21" class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a> A description of human cognition at
Marr’s computational level would be expected to consist in a patchwork
of disjoint theories describing each computational problem the brain
faces. Stepping back from that patchwork, there need be no overarching
pattern or unity. Each domain of cognition – perception, motor control,
decision making, language learning – is likely to merit its own
computation-level account. Predictive coding, in contrast, provides a
complete, unified, and relatively simple description of the
computational task the brain faces in all aspects of cognition. That, by
itself, would appear to be a mark in its favour. All else being equal it
is rational to prefer a simple, unifying theory (where available) over
less unified alternatives:</p>
<blockquote>
<p>It is the first time that we have had a theory of this strength,
breadth and depth in cognitive neuroscience … I take that property as a
sure sign that this is a very important theory … Most other models,
including mine, are just models of one small aspect of the brain, very
limited in their scope. This one falls much closer to a grand theory.
<span class="citation" data-cites="Huang08">(Stanislas Dehaene quoted in
Huang 2008)</span></p>
</blockquote>
<p>A unified computational-level theory also promises to reveal
something profound about the metaphysical nature of cognition. It tells
us that cognition is not a motley, a jumble of distinct phenomena; it
can be characterised in terms of a single computational problem.
Predictive coding identifies what the various, seemingly distinct and
unrelated domains of human cognition – perception, motor control,
decision making, language learning – have in common. Moreover, it
appears to explain <em>why</em> they each count as instances of
cognition. It potentially provides us with a criterion to judge whether
new and perhaps controversial instances of cognition are genuinely
cognitive.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a> It suggests that cognition is a
unified and relatively simple functional kind. If a theory uncovers
principles like this – that unify and simplify what otherwise appears to
be a complicated and disordered domain – then, all else equal, that is
reason to favour it. Knowledge about the essence of things and the
patterns into which they enter is surely what science aspires to.</p>
<h1 data-number="8" id="the-free-energy-defence"><span
class="header-section-number">8</span> The free-energy defence</h1>
<p>Pursuit of the case-based defence of predictive coding is likely to
be long and fraught. It requires engaging with the details of many
specific cognitive tasks and showing that their distinctive effects – of
which there may be many – are captured or recaptured on predictive
coding’s task description. A case-based defence has no obvious stopping
point. A defender of predictive coding faces a potentially endless
sequence of battles: there will always be more tasks, more behavioural
and neural effects to consider. It is not obvious when enough cases – or
a diverse enough selection of cases – will have been considered to
justify the conclusion that not just <em>some</em> tasks, but
<em>every</em> task faced by the brain, is sensory prediction error
minimisation. The free-energy defence aims to shortcut all this. It
attempts to establish predictive coding’s computational-level claim in
one fell swoop by appealing to general properties shared by all
cognitive (or living) systems. <span class="citation"
data-cites="Friston10">Friston (2010)</span> presents a defence of
predictive coding along these lines based on his ‘free energy’
formulation of predictive coding. Friston proposes that the task faced
by the brain is that of <em>minimising free energy</em>. Minimising free
energy can be shown, under appropriate further assumptions, to be
equivalent to the task of minimising sensory prediction error.</p>
<p>Free energy is a mathematical quantity that appears inside classical
thermodynamics, statistical mechanics, and information theory. Friston’s
claim is that there is a relationship between two distinct applications
of the mathematical abstraction of free energy: <em>variational</em>
free energy and, what I will call, <em>homoeostatic</em> free energy.<a
href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a> Variational free energy is an
information-theoretic quantity predicated of agents who engage in
probabilistic inference. If a probabilistic reasoner minimises their
variational free energy, this can be shown to be equivalent to them
approximating Bayesian inference <span class="citation"
data-cites="Sprevak20e">(see Sprevak forthcoming sec. 1)</span>. Under
further assumptions, minimising sensory prediction error can also be
shown to be equivalent to minimising variational free energy <span
class="citation" data-cites="Sprevak20e">(see Sprevak forthcoming sec.
2)</span>. ‘Homoeostatic’ free energy applies the same formal construct
to a different set of properties. Unlike variational free energy, it is
not (or at least, not directly) associated with the subjective
probabilities that feature in probabilistic or Bayesian inference.
Rather, it is associated with the objective probability of the
macroscopic physical state the agent is in given its physical
environmental conditions. Minimising homoeostatic free energy is
associated with the agent’s survival within a narrow band of macroscopic
physical state types (‘being alive’). According to Friston, these two
types of free energy – homoeostatic free energy and variational free
energy – are connected. Agents who minimise their homoeostatic free
energy – who survive and maintain homeostasis – also minimise their
variational free energy (and hence, given certain assumptions, minimise
their sensory prediction error).</p>
<p>Friston is clear that neither variational nor homoeostatic free
energy is the same as thermodynamic free energy. Thermodynamic free
energy measures the useful mechanical work that can be extracted from a
physical system. It is usually defined in terms of that system’s ability
to exert macroscopic mechanical forces on its surroundings – its energy
that is ‘free’ to perform mechanical work. This is normally formalised
as a difference between the physical system’s internal energy and its
thermodynamic entropy (its internal energy that is ‘useless’ for work).
Having a reserve of thermodynamic free energy is generally a good thing
for a cognitive or living creature: a surplus of thermodynamic free
energy is a prerequisite for it to be able to move or act in the world.
<em>Minimising</em> thermodynamic free energy would make little sense as
a rule for cognition or survival. Friston is explicit that his principle
– that all cognitive/living systems aim to minimise their
homoeostatic/variational free energy – is not meant to be somehow a
consequence of, or a principle about, thermodynamic free energy. He
justifies his free-energy principle not on thermodynamic grounds, but on
what he calls ‘selectionist’ grounds: all cognitive/living creatures
strive to minimise their homoeostatic free energy because if they did
not, they would tend to die off and hence be less likely to reproduce or
to be observed by us.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn24" class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a> Friston suggests that the only
connection between thermodynamic free energy and his notion of free
energy is their shared mathematical form.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn25"
class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a></p>
<p>In outline, the logic of the free-energy defence of predictive coding
is as follows. Its starting point is the observation that all cognitive
(and living) creatures face the problem of surviving and maintaining
homeostasis. That task, according to Friston, can be formalised as the
problem of minimising a particular free-energy measure (what I have
called homoeostatic free energy). Friston claims that minimising
homoeostatic free energy entails that the creature also minimises a
second free-energy measure associated with the creature’s subjective
probabilistic guesses (variational free energy). Minimising variational
free energy, given certain further assumptions <span class="citation"
data-cites="Sprevak20e">(detailed in Sprevak forthcoming sec. 2)</span>,
entails that the creature minimises its sensory prediction error. Hence,
cognitive and living creatures, because they face the problem of
survival and maintaining homeostasis, face the problem of minimising
sensory prediction error.</p>
<p>There is much to unpack here.</p>
<p>First, the argument relies on a tight connection between homoeostatic
and variational free energy. However, the nature of, and justification
for, that connection is not obvious. Homoeostatic free energy pertains
to how well the creature maintains its physical state within the narrow
band associated with survival and homeostasis in the face of actual and
possible perturbations from a changing physical environment. Living
creatures change their microscopic physical state all the time. When
they do so, they risk undergoing a fatal phase transition in their
macroscopic physical state. When living systems resist this tendency –
when they survive and maintain homeostasis – they minimise their
homoeostatic free energy. Minimising homoeostatic free energy involves
the creature trying to arrange its macroscopic state so as to avoid
being overly changed by likely environmental physical transitions <span
class="citation"
data-cites="FristonKilner06 FristonStephan07 Friston13">(Friston et al.
2006; Friston 2013; Friston &amp; Stephan 2007)</span>. In contrast,
variational free energy is predicated of an agent’s subjective
probability distributions. It measures how far the agent’s probabilistic
guesses depart from the optimal guesses of a perfect Bayesian observer
armed with the same evidence.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn26" class="footnote-ref"
id="fnref26" role="doc-noteref"><sup>26</sup></a> According to Friston’s
formulation, the brain’s task is to minimise variational free energy and
so approximate an ideal Bayesian reasoner in inference. Minimising
variational free energy makes the sensory data stream less surprising
(in the Shannon sense), and therefore tends to drive down the agent’s
sensory prediction error <span class="citation"
data-cites="Sprevak20e">(granted certain additional assumptions, see
Sprevak forthcoming sec. 2)</span>.</p>
<p>Homoeostatic free energy and variational free energy have certain
features in common. They are both information-theoretic quantities and
they are both measured over probability distributions. However, they are
not the same. Homoeostatic free energy is measured over the
<em>objective</em> probability distributions of macroscopic physical
states that could occur; variational free energy is measured over the
<em>subjective</em> probability distributions entertained by an agent
about what could occur. Homoeostatic free energy is defined over the
chances of various possible (fatal) physical states of the agent
occurring in response to environmental changes; variational free energy
is defined over the subjective probabilistic guesses the agent might
make. The respective probability distributions might involve different
sets of events, the distributions might have different shapes, and they
each involve different types of probability (subjective and objective).
There might, for various reasons, be a correlation between the two types
of free energy, but it is not obvious that minimising one entails
minimising the other.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn27" class="footnote-ref" id="fnref27"
role="doc-noteref"><sup>27</sup></a></p>
<p>To see this more clearly, consider the tight relationship already
mentioned between minimising variational free energy and Bayesian
inference. An agent who minimises its variational free energy <em>ipso
facto</em> approximates an ideal Bayesian reasoner. In many
circumstances, a Bayesian agent would be well placed to survive and
maintain homeostasis. But the precise nature of the connection between
<em>being Bayesian</em> and <em>maximising one’s chances of physical
survival and homeostasis</em> is far from obvious. A non-Bayesian agent
might live in a ‘irrationality friendly’ environment that maintains its
homeostasis and physical integrity, even if it does not update its
subjective probability distributions that represent its environment
according to Bayesian norms. Conversely, an ideal Bayesian reasoner
might live in a ‘rationality hostile’ physical environment that changes
so rapidly and dramatically that it fails to survive or maintain
homoeostasis, even if it updates its subjective probability
distributions quickly and accurately according to Bayesian norms.
Bayesian reasoning is plausibly related to survival, but it is not
obvious in what sense it would guarantee it. Currently, the exact nature
of the relationship between Friston’s two measures of free energy –
homoeostatic and variational – is unclear and the subject of ongoing
analysis.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn28" class="footnote-ref" id="fnref28"
role="doc-noteref"><sup>28</sup></a></p>
<p>At least two other aspects of the free-energy defence invite further
scrutiny.</p>
<p>First, the predictive coding research programme aims to defend a
universal claim: <em>every</em> task that the brain faces can and should
be described as minimisation of sensory prediction error.
Survival/homoeostasis is clearly one task faced by the brain, and an
important one. If the internal logic of the free-energy defence is
correct, then because the brain faces that task it also faces the task
of minimising sensory prediction error. But it is not obvious how this
reasoning is meant to generalise. Plausibly, our brains face other
challenges that may be unrelated, or even in tension with, our long-term
survival or homoeostasis – e.g. problems of mate selection, fulfilment
of social roles, or arbitrary challenges set in the classroom or wider
social environments. It is not clear how the free-energy defence is
intended to handle these cases. The free-energy defence appeals to a
formal connection between survival/homoeostasis and minimising sensory
prediction error, but it is largely silent about how problems that do
not (or do not obviously) improve the chances of our long-term
survival/homoeostasis are meant to be related to minimising sensory
predictive error. Even if the internal logic of the free-energy defence
is correct, it is unclear how it supports the claim that every aspect of
cognition is sensory prediction error minimisation.</p>
<p>Second, recall that the case-based defence required one to show not
only that every problem faced by the brain in cognition <em>can</em> be
described as sensory prediction error minimisation, but also that it
<em>should</em> be described that way. The free-energy defence appears
to only speak to the first issue. It attempts to establish a formal
relationship between the task of survival/homoeostasis and the task of
minimising sensory prediction error. However, even if such a connection
were to exist, it would say nothing about the merits of one task
description over the other. In order to address that issue, one would
need to go beyond a purely formal equivalence between the task
descriptions and consider the <em>value</em> of predictive coding’s
proposed description with respect to the wider standards, interests, and
goals in cognitive neuroscience. <em>Why</em> should we describe the
task facing the brain as sensory prediction error minimisation, even if,
as the free-energy defence suggests, we could? That part of the argument
remains to be made and it is likely to depend, at least in part, on an
examination of the benefits offered by predictive coding’s
computational-level description to specific cases of interest to
cognitive neuroscience. This suggests that the free-energy defence may
not be able to entirely shortcut the exigencies of the case-by-case
defence.</p>
<h1 data-number="9" id="the-instrumental-value-defence"><span
class="header-section-number">9</span> The instrumental-value
defence</h1>
<!-- It has recently been suggested that the merits of the PP framework should be evaluated on the basis of its fruitfulness, as opposed to its explanatory or unificatory merits. In particular, Litwin and Mi􏰧lkowski (2020) argue that -->
<!-- Among PP proponents, we may distinguish ‘neats’–who posit that all cog- nition arises from the imperative to minimize informational uncertainty in hierarchical PP architectures–from ‘scruffies,’ who perceive PP as a frame- work or even a toolbox. This toolbox could be a common stock of algorithmic specifications and concepts that find their precise empirical meanings in indi- vidual models (Clark, 2013). If PP is a toolbox, then its main virtue lies in its fruitfulness in displaying commonalities across phenomena. We actually sympathize with the scruffies: PP might be a useful theory even if it is not -->
<!-- 17necessarily unifying to a high degree. -->
<p>The instrumental-value defence has a different character from the
previous two. This third strategy for defending predictive coding helps
to explain an otherwise puzzling phenomenon: the widespread adoption of
predictive coding’s computational-level claim in cognitive neuroscience
despite what we have seen as the view’s current relatively slender
epistemic support. According to the instrumental-value defence,
predictive coding should be interpreted, not as a passive claim that
awaits confirmation, but as a <em>discovery heuristic</em> – an
assumption that researchers may adopt in order to help organise data,
guide experimental design and interpretation, and formulate further,
more specific hypotheses for testing. Predictive coding’s
computational-level claim provides a novel way to systematise
behavioural and neural data. It constrains the way one might group
behavioural and brain responses into psychologically relevant,
computationally-defined capacities, and the kinds of experimental and
control conditions one might design. Furthermore, if one understands
predictive coding as a package that includes proposals at Marr’s
algorithmic and implementation levels, it provides a rich set of
heuristics to guide and inspire claims about the formal methods and
neural mechanisms that underlie those computational capacities. The
focus in the previous two sections was on whether predictive coding gets
the computational-level description of the brain <em>right</em> or
<em>wrong</em> (or whether it does better than alternatives). But one
might equally well ask the question of how one should come up with a
computational-level description <em>at all</em>. Scientific work here
can potentially benefit from what predictive coding says, even if
uncertainty remains about the view’s ultimate epistemic standing.</p>
<p>It is worth stressing that individuating the mass of human
behavioural and neural responses into discrete, well-defined
computational capacities is hard. Cognitive neuroscientists do not have
an agreed methodology to do this. Formulating a computational-level
description of the brain usually requires adopting some broad
theoretical orientation about the overall purpose of the brain’s
activity. It is not obvious where an empirically minded researcher
should look to for inspiration or guidance here. Traditionally, folk
psychology has provided one possible source of inspiration. Someone
might, for example, start by assuming that the brain is trying to use
roughly ‘belief’-like states and ‘desire’-like states to produce
outcomes that satisfy what it represents as desired. Bringing this
general framework to bear on empirical data might motivate a researcher
to formulate more specific hypotheses about particular kinds of
belief-like and desire-like states inside the brain, the relationships
between them, the processes that transform them, and how sensory and
behavioural responses update those beliefs and fulfil those desires.<a
href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a></p>
<p><span class="citation" data-cites="Machery18">Machery
(forthcoming)</span> describes an alternative source of inspiration that
might lead a researcher in a different direction to a set of more
specific, testable hypotheses about the computational tasks the brain
faces and its underlying computational capacities, states, and
mechanisms. He argues that one feature of evolutionary psychology is
that, irrespective of its other epistemic properties, it provides a
potentially valuable set of discovery heuristics. Some of these speak
directly to the problem of coming up with hypotheses at Marr’s
computational level. For example, the ‘forward-looking’ heuristic
suggests that our computational capacities may be identified by looking
at the problems that were encountered by our ancestors that regularly
bore on their fitness.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a> Hypotheses about the computational
capacities that our brains have today can be inferred from the problems
faced by our evolutionary ancestors <span class="citation"
data-cites="CosmidesTooby89">(Cosmides &amp; Tooby 1989)</span>.
Hypotheses about our computational capacities arrived at in this fashion
of course need to be empirically confirmed. But even in advance of
securing epistemic support, it may make sense to accept a framework like
evolutionary psychology (or folk psychology) <em>pro tem</em> as a
discovery heuristic, in order to make the problem of task description
tractable at all.</p>
<p>Predictive coding could potentially play a similar role for cognitive
neuroscience. It suggests that neural and behavioural responses should
be organised around the central notion that those responses are all
attempts by the brain to minimise long-term, precision-weighted sensory
prediction error. Even if the evidential basis for that claim is slight,
it may still function as a useful discovery heuristic to guide design of
experiments, measurement, and as a means of generating more specific,
testable proposals about physical responses.</p>
<p>For example, <span class="citation"
data-cites="FletcherFrith09">Fletcher &amp; Frith (2009)</span>,
inspired by predictive coding’s computational-level claim, hypothesise
that a range of positive symptoms of schizophrenia – including
hallucinations, delusions, abnormal saliences in perception,
disturbances in low-level motor functioning – should be categorised as
instances of a single, unitary dysfunction in the computational ability
to minimise precision-weighted sensory prediction error. They go on to
propose that this dysfunction is unwritten by both a single
computational mechanism and a single physical basis, again prompted by
predictive coding’s claims at those levels.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn31"
class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a>
Such work suggests novel experimental designs that might attempt to
dissociate the relevant factors in schizophrenia, probe how they might
be quantitatively affected by manipulating sensory prediction errors,
and explore analogues of schizophrenia in healthy subjects with designs
that induce similar effects on their sensory prediction errors.<a
href="#fn32" class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a> <span class="citation"
data-cites="CorlettFletcher14">Corlett &amp; Fletcher (2014)</span>
describe how predictive coding could function as a discovery heuristic
for clinicians to find new therapeutic interventions for patients
(including pharmacological treatments). The idea that the brain aims to
minimise its sensory prediction error might function as the starting
point for any number of theoretical, experimental, and therapeutic
developments.</p>
<p>In contrast to both the case-based defence and the free-energy
defence, the focus here is not primarily on truth, but on predictive
coding’s utility. The relevant kind of utility should be understood as
broader than merely a concern with achieving a narrow instrumental
outcome. Cognitive neuroscience needs to make assumptions regarding the
overall purpose of brain activity in order to make any sense of that
activity at all. Those assumptions need to come from somewhere. It is
reasonable to assume that any candidate source of these assumptions
should be understood to be uncertain and exploratory. Predictive coding
provides one among many possible sources (and one distinct from folk
psychology or evolutionary psychology). Its sheer novelty and boldness
is undoubtedly an attraction. It allows us to see familiar behavioural
and neural responses in a new light and group them together in different
ways from previous research programmes.</p>
<p>It should be clear that using predictive coding in this way – as a
heuristic to guide discovery rather than as a claim that passively
awaits confirmation – does not somehow magically confer justification on
the view. Merely believing something to be true does not make it so.
Justification for predictive coding only accrues if it can predict and
explain better than alternative theoretical approaches.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn33"
class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a>
The instrumental-value defence does not reduce the need to gather
conventional empirical evidence to confirm predictive coding. However,
it does explain why someone might be rational to accept what predictive
coding says now, even in advance of such evidence being obtained.</p>
<!-- It explains why predictive coding might be adopted in cognitive -->
<!-- neuroscience as a working hypothesis despite its truth -->
<!-- remaining in question.  -->
<h1 data-number="10" id="conclusion"><span
class="header-section-number">10</span> Conclusion</h1>
<p>In its boldest form, predictive coding proposes that the only
computational problem that the brain faces is to minimise its long-term,
prediction-weighted sensory prediction error. It is natural to wonder
what would happen if one were to qualify this claim.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn34"
class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a>
Perhaps predictive coding describes some, but not all, problems the
brain faces. One might imagine a variety of ways in which the scope of
predictive coding’s ambition at the computational level might be reigned
in. At the more modest end would be the relatively anodyne claim that in
early vision one thing the brain tries to do is minimise its sensory
prediction errors. At the more speculative end would be the
revolutionary claim that this is the only problem that the brain tries
to solve. Advocates of predictive coding might wish to allow for the
possibility that their view will fall between these two extremes. It is
worth noting however, that to the extent to which the scope of the view
is restricted, its unifying power is also compromised. If predictive
coding is to fulfil its original promise of offering a grand unifying
theory, the research programme should aim to deliver as broad and
comprehensive a theory of brain function as possible.</p>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-AitchisonLengyel17" class="csl-entry"
role="doc-biblioentry">
Aitchison, L., &amp; Lengyel, M. (2017). <span>‘With or without you:
Predictive coding and <span>B</span>ayesian inference in the
brain’</span>, <em>Current Opinion in Neurobiology</em>, 46: 219–27.
</div>
<div id="ref-AlinkSchwiedrzi10" class="csl-entry"
role="doc-biblioentry">
Alink, A., Schwiedrzik, C. M., Kohler, A., Singer, W., &amp; Muckli, L.
(2010). <span>‘Stimulus predictability reduces responses in primary
visual cortex’</span>, <em>Journal of Neuroscience</em>, 30: 2960–6.
</div>
<div id="ref-Allen17" class="csl-entry" role="doc-biblioentry">
Allen, C. (2017). <span>‘On (not) defining cognition’</span>,
<em>Synthese</em>, 194: 4233–49.
</div>
<div id="ref-Atick92" class="csl-entry" role="doc-biblioentry">
Atick, J. J. (1992). <span>‘Could information theory provide an
ecological theory of sensory processing?’</span>, <em>Network:
Computation in Neural Systems</em>, 3: 213–51.
</div>
<div id="ref-BayneBrainardByrne19" class="csl-entry"
role="doc-biblioentry">
Bayne, T., Brainard, D., Byrne, R. W., Chittka, L., Clayton, N., Heyes,
C., Mather, J., et al. (2019). <span>‘What is cognition?’</span>,
<em>Current Biology</em>, 29: R603–22.
</div>
<div id="ref-Bogacz17" class="csl-entry" role="doc-biblioentry">
Bogacz, R. (2017). <span>‘A tutorial on the free-energy framework for
modelling perception and learning’</span>, <em>Journal of Mathematical
Psychology</em>, 76: 198–211.
</div>
<div id="ref-BruinebergKiversteinRietveld18" class="csl-entry"
role="doc-biblioentry">
Bruineberg, J., Kiverstein, J., &amp; Rietveld, E. (2018). <span>‘The
anticipating brain is not a scientist: The free-energy principle from an
ecological-enactive perspective’</span>, <em>Synthese</em>, 195:
2417–44.
</div>
<div id="ref-CarandiniDemb05" class="csl-entry" role="doc-biblioentry">
Carandini, M., Demb, J. B., Mante, V., Tolhurst, D. J., Dan, Y.,
Olshausen, B. A., Gallant, J. L., et al. (2005). <span>‘Do we know what
the early visual system does?’</span>, <em>Journal of Neuroscience</em>,
25: 10577–97.
</div>
<div id="ref-CarandiniHeeger12" class="csl-entry"
role="doc-biblioentry">
Carandini, M., &amp; Heeger, D. J. (2012). <span>‘Normalization as a
canonical neural computation’</span>, <em>Nature Reviews
Neuroscience</em>, 13: 51–62.
</div>
<div id="ref-Carruthers06" class="csl-entry" role="doc-biblioentry">
Carruthers, P. (2006). <em>The architecture of the mind</em>. Oxford:
Oxford University Press.
</div>
<div id="ref-Clark13a" class="csl-entry" role="doc-biblioentry">
Clark, A. (2013a). <span>‘The many faces of precision (replies to
commentaries on <span>“<span>W</span>hatever next? <span>N</span>eural
prediction, situated agents, and the future of cognitive
science”</span>)’</span>, <em>Frontiers in Psychology</em>, 4: 270.
</div>
<div id="ref-Clark13" class="csl-entry" role="doc-biblioentry">
——. (2013b). <span>‘Whatever next? Predictive brains, situated agents,
and the future of cognitive science’</span>, <em>Behavioral and Brain
Sciences</em>, 36: 181–253.
</div>
<div id="ref-Clark15" class="csl-entry" role="doc-biblioentry">
——. (2016). <em>Surfing uncertainty: Prediction, action, and the
embodied mind</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Clark17" class="csl-entry" role="doc-biblioentry">
——. (2017). <span>‘How to knit your own <span>M</span>arkov
blanket’</span>. Metzinger T. &amp; Wiese W. (eds) <em>Philosophy and
predictive processing</em>. MIND Group: Frankfurt am Main. DOI: <a
href="https://doi.org/10.15502/9783958573031">10.15502/9783958573031</a>
</div>
<div id="ref-ColomboWright18" class="csl-entry" role="doc-biblioentry">
Colombo, M., &amp; Wright, C. (2021). <span>‘First principles in the
life sciences: The free-energy principle, organicism, and
mechanism’</span>, <em>Synthese</em>, 198: S3463–88.
</div>
<div id="ref-CorlettFletcher14" class="csl-entry"
role="doc-biblioentry">
Corlett, P. R., &amp; Fletcher, P. C. (2014). <span>‘Computational
psychiatry: A <span>R</span>osetta <span>S</span>tone linking the brain
to mental illness’</span>, <em>The Lancet Psychiatry</em>, 1: 399–402.
</div>
<div id="ref-CorlettFrith09" class="csl-entry" role="doc-biblioentry">
Corlett, P. R., Frith, C. D., &amp; Fletcher, P. C. (2009). <span>‘From
drugs to deprivation: A <span>B</span>ayesian framework for
understanding models of psychosis’</span>, <em>Psychopharmacology</em>,
206: 515–30.
</div>
<div id="ref-CosmidesTooby89" class="csl-entry" role="doc-biblioentry">
Cosmides, L., &amp; Tooby, J. (1989). <span>‘Evolutionary psychology and
the generation of culture, part <span>II</span>: <span>C</span>ase
study: <span>A</span> computational theory of social exchange’</span>,
<em>Ethology and Sociobiology</em>, 10: 51–97.
</div>
<div id="ref-FeldmanFriston10" class="csl-entry" role="doc-biblioentry">
Feldman, H., &amp; Friston, K. (2010). <span>‘Attention, uncertainty,
and free-energy’</span>, <em>Frontiers in Human Neuroscience</em>, 4:
1–23.
</div>
<div id="ref-FletcherFrith09" class="csl-entry" role="doc-biblioentry">
Fletcher, P. C., &amp; Frith, C. D. (2009). <span>‘Perceiving is
believing: A <span>B</span>ayesian approach to explaining the positive
symptoms of schizophrenia’</span>, <em>Nature Reviews Neuroscience</em>,
10: 48–58.
</div>
<div id="ref-FranklinWolpert11" class="csl-entry"
role="doc-biblioentry">
Franklin, D. W., &amp; Wolpert, D. M. (2011). <span>‘Computational
mechanisms of sensorimotor control’</span>, <em>Neuron</em>, 72: 425–42.
</div>
<div id="ref-Friston03" class="csl-entry" role="doc-biblioentry">
Friston, K. (2003). <span>‘Learning and inference in the brain’</span>,
<em>Neural Networks</em>, 16: 1325–52.
</div>
<div id="ref-Friston05" class="csl-entry" role="doc-biblioentry">
——. (2005). <span>‘A theory of cortical responses’</span>,
<em>Philosophical Transactions of the Royal Society of London, Series
B</em>, 360: 815–36.
</div>
<div id="ref-Friston09" class="csl-entry" role="doc-biblioentry">
——. (2009). <span>‘The free-energy principle: A rough guide to the
brain?’</span>, <em>Trends in Cognitive Sciences</em>, 13: 293–301.
</div>
<div id="ref-Friston10" class="csl-entry" role="doc-biblioentry">
——. (2010). <span>‘The free-energy principle: A unified brain
theory?’</span>, <em>Nature Reviews Neuroscience</em>, 11: 127–38.
</div>
<div id="ref-Friston11" class="csl-entry" role="doc-biblioentry">
——. (2011). <span>‘What is optimal about motor control?’</span>,
<em>Neuron</em>, 72: 488–98.
</div>
<div id="ref-Friston13" class="csl-entry" role="doc-biblioentry">
——. (2013). <span>‘Life as we know it’</span>, <em>Journal of the Royal
Society Interface</em>, 10: 20130475.
</div>
<div id="ref-FristonDaunizeau10" class="csl-entry"
role="doc-biblioentry">
Friston, K., Daunizeau, J., Kilner, J., &amp; Kiebel, S. J. (2010).
<span>‘Action and behavior: A free-energy formulation’</span>,
<em>Biological Cybernetics</em>, 102: 227–60.
</div>
<div id="ref-FristonKilner06" class="csl-entry" role="doc-biblioentry">
Friston, K., Kilner, J., &amp; Harrison, L. (2006). <span>‘A free energy
principle for the brain’</span>, <em>Journal of Physiology (Paris)</em>,
100: 70–87.
</div>
<div id="ref-FristonMattoutKilner11" class="csl-entry"
role="doc-biblioentry">
Friston, K., Mattout, J., &amp; Kilner, J. (2011). <span>‘Action
understanding and active inference’</span>, <em>Biological
Cybernetics</em>, 104: 137–60.
</div>
<div id="ref-FristonStephan07" class="csl-entry" role="doc-biblioentry">
Friston, K., &amp; Stephan, K. E. (2007). <span>‘Free-energy and the
brain’</span>, <em>Synthese</em>, 159: 417–58.
</div>
<div id="ref-FristonStephanMontague14" class="csl-entry"
role="doc-biblioentry">
Friston, K., Stephan, K. E., Montague, P. R., &amp; Dolan, R. J. (2014).
<span>‘Computational psychiatry: The brain as a phantastic
organ’</span>, <em>The Lancet Psychiatry</em>, 1: 148–58.
</div>
<div id="ref-FristonThornton12" class="csl-entry"
role="doc-biblioentry">
Friston, K., Thornton, C., &amp; Clark, A. (2012). <span>‘Free-energy
minimization and the dark-room problem’</span>, <em>Frontiers in
Psychology</em>, 3: 1–7.
</div>
<div id="ref-Hohwy13" class="csl-entry" role="doc-biblioentry">
Hohwy, J. (2013). <em>The predictive mind</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-HohwyMichael17" class="csl-entry" role="doc-biblioentry">
Hohwy, J., &amp; Michael, J. (2017). <span>‘Why should any body have a
self?’</span> Vignemont F. de &amp; Alsmith A. (eds) <em>The body and
the self, revisited</em>, pp. 363–92. MIT Press: Cambridge, MA.
</div>
<div id="ref-HohwyRoepstorff08" class="csl-entry"
role="doc-biblioentry">
Hohwy, J., Roepstorff, A., &amp; Friston, K. (2008). <span>‘Predictive
coding explains binocular rivalry: An epistemological review’</span>,
<em>Cognition</em>, 108: 687–701.
</div>
<div id="ref-HosoyaBaccus05" class="csl-entry" role="doc-biblioentry">
Hosoya, T., Baccus, S. A., &amp; Meister, M. (2005). <span>‘Dynamic
predictive coding by the retina’</span>, <em>Nature</em>, 436: 71–7.
</div>
<div id="ref-Huang08" class="csl-entry" role="doc-biblioentry">
Huang, G. T. (2008). <span>‘Is this a unified theory of the
brain?’</span>, <em>New Scientist</em>, 2658: 30–3.
</div>
<div id="ref-JeheeBallard09" class="csl-entry" role="doc-biblioentry">
Jehee, J. F. M., &amp; Ballard, D. H. (2009). <span>‘Predictive feedback
can account for biphasic responses in the lateral geniculate
nucleus’</span>, <em><span>PLoS</span> Computational Biology</em>, 5:
e1000373.
</div>
<div id="ref-KirchhoffKiverstein19" class="csl-entry"
role="doc-biblioentry">
Kirchhoff, M. D., &amp; Kiverstein, J. (2021). <span>‘How to determine
the boundaries of the mind: A <span>M</span>arkov blanket
proposal’</span>, <em>Synthese</em>, 198: 4791–810.
</div>
<div id="ref-KoelschVuustFriston19" class="csl-entry"
role="doc-biblioentry">
Koelsch, S., Vuust, P., &amp; Friston, K. (2019). <span>‘Predictive
processes and the peculiar case of music’</span>, <em>Trends in
Cognitive Sciences</em>, 23: 63–77.
</div>
<div id="ref-KokJeheeLange12" class="csl-entry" role="doc-biblioentry">
Kok, P., Jehee, J. F. M., &amp; Lange, F. P. de. (2012). <span>‘Less is
more: Expectation sharpens representations in the primary visual
cortex’</span>, <em>Neuron</em>, 75: 265–70.
</div>
<div id="ref-KokLange15" class="csl-entry" role="doc-biblioentry">
Kok, P., &amp; Lange, F. P. de. (2015). <span>‘Predictive coding in the
sensory cortex’</span>. Forstmann B. U. &amp; Wagenmakers E.-. J. (eds)
<em>An introduction to model-based cognitive neuroscience</em>, pp.
221–44. Springer: New York, NY.
</div>
<div id="ref-Kording07" class="csl-entry" role="doc-biblioentry">
Kording, K. (2007). <span>‘Decision theory: What <span>“should”</span>
the nervous system do?’</span>, <em>Science</em>, 318: 606–10.
</div>
<div id="ref-Lupyan15" class="csl-entry" role="doc-biblioentry">
Lupyan, G. (2015). <span>‘Cognitive penetrability of perception in the
age of prediction: Predictive systems are penetrable systems’</span>,
<em>Review of Philosophy and Psychology</em>, 6: 547–69.
</div>
<div id="ref-Machery18" class="csl-entry" role="doc-biblioentry">
Machery, E. (forthcoming). <span>‘Discovery and confirmation in
evolutionary psychology’</span>. Prinz J. (ed.) <em>The oxford handbook
of philosophy of psychology</em>. Oxford University Press.
</div>
<div id="ref-Marr82" class="csl-entry" role="doc-biblioentry">
Marr, D. (1982). <em>Vision</em>. San Francisco, CA: W. H. Freeman.
</div>
<div id="ref-MillerClark18" class="csl-entry" role="doc-biblioentry">
Miller, M., &amp; Clark, A. (2018). <span>‘Happily entangled:
Prediction, emotion, and the embodied mind’</span>, <em>Synthese</em>,
195: 2559–75.
</div>
<div id="ref-Muckli10" class="csl-entry" role="doc-biblioentry">
Muckli, L. (2010). <span>‘What are we missing here? Brain imaging
evidence for higher cognitive functions in primary visual cortex
<span>V</span>1’</span>, <em>International Journal of Imaging Systems
and Technology</em>, 20: 131–9.
</div>
<div id="ref-Mumford92" class="csl-entry" role="doc-biblioentry">
Mumford, D. (1992). <span>‘On the computational architecture of the
neocortex. <span>II</span> <span>T</span>he role of cortico-cortico
loops’</span>, <em>Biological Cybernetics</em>, 66: 241–51.
</div>
<div id="ref-MurrayKersten02" class="csl-entry" role="doc-biblioentry">
Murray, S. O., Kersten, D., Olshausen, B. A., Schrater, P., &amp; Woods,
D. L. (2002). <span>‘Shape perception reduces activity in human primary
visual cortex’</span>, <em>Proceedings of the National Academy of
Sciences</em>, 99: 15164–9.
</div>
<div id="ref-OlshausenField05" class="csl-entry" role="doc-biblioentry">
Olshausen, B. A., &amp; Field, D. J. (2005). <span>‘How close are we to
understanding <span>V</span>1?’</span>, <em>Neural Computation</em>, 17:
1665–99.
</div>
<div id="ref-PellicanoBurr12" class="csl-entry" role="doc-biblioentry">
Pellicano, E., &amp; Burr, D. (2012). <span>‘When the world becomes
<span>“too real”</span>: A <span>B</span>ayesian explanation of autistic
perception’</span>, <em>Trends in Cognitive Sciences</em>, 16: 504–10.
</div>
<div id="ref-PickeringClark14" class="csl-entry" role="doc-biblioentry">
Pickering, M. J., &amp; Clark, A. (2014). <span>‘Getting ahead:
<span>F</span>orward models and their place in cognitive
architecture’</span>, <em>Trends in Cognitive Sciences</em>, 18: 451–6.
</div>
<div id="ref-RamsteadKirchhoffConstant21" class="csl-entry"
role="doc-biblioentry">
Ramstead, M. J. D., Kirchhoff, M. D., Constant, A., &amp; Friston, K.
(2021). <span>‘Multiscale integration: Beyond internalism and
externalism’</span>, <em>Synthese</em>, 198: S41–70.
</div>
<div id="ref-RaoBallard99" class="csl-entry" role="doc-biblioentry">
Rao, R. P. N., &amp; Ballard, D. H. (1999). <span>‘Predictive coding in
the visual cortex: A functional interpretation of some extra-classical
receptive-field effects’</span>, <em>Nature Neuroscience</em>, 2: 79–87.
</div>
<div id="ref-RaoSejnowski02" class="csl-entry" role="doc-biblioentry">
Rao, R. P. N., &amp; Sejnowski, T. J. (2002). <span>‘Predictive coding,
cortical feedback, and spike-timing dependent plasticity’</span>. Rao R.
P. N., Olshausen B. A., &amp; Lewicki M. S. (eds) <em>Probablistic
models of the brain: Perception and neural function</em>, pp. 297–315.
MIT Press: Cambridge, MA.
</div>
<div id="ref-SchwartenbeckFitzGerald13" class="csl-entry"
role="doc-biblioentry">
Schwartenbeck, P., FitzGerald, T., Dolan, R. J., &amp; Friston, K.
(2013). <span>‘Exploration, novelty, surprise, and free energy
minimization’</span>, <em>Frontiers in Psychology</em>, 4: 1–5.
</div>
<div id="ref-SchwarzSimoncelli01" class="csl-entry"
role="doc-biblioentry">
Schwarz, O., &amp; Simoncelli, E. P. (2001). <span>‘Natural signal
statistics and sensory gain control’</span>, <em>Nature
Neuroscience</em>, 4: 819–25.
</div>
<div id="ref-Seth13" class="csl-entry" role="doc-biblioentry">
Seth, A. K. (2013). <span>‘Interoceptive inference, emotion, and the
embodied self’</span>, <em>Trends in Cognitive Sciences</em>, 17:
565–73.
</div>
<div id="ref-ShadmehrKrakauer08" class="csl-entry"
role="doc-biblioentry">
Shadmehr, R., &amp; Krakauer, J. W. (2008). <span>‘A computational
neuroanatomy for motor control’</span>, <em>Experimental Brain
Research</em>, 185: 359–81.
</div>
<div id="ref-Shagrir10a" class="csl-entry" role="doc-biblioentry">
Shagrir, O. (2010). <span>‘Marr on computational-level theories’</span>,
<em>Philosophy of Science</em>, 77: 477–500.
</div>
<div id="ref-ShagrirBechtel13" class="csl-entry" role="doc-biblioentry">
Shagrir, O., &amp; Bechtel, W. (2017). <span>‘Marr’s computational level
and delineating phenomena’</span>. Kaplan D. (ed.) <em>Integrating
psychology and neuroscience: Prospects and problems</em>, pp. 190–214.
Oxford University Press: Oxford.
</div>
<div id="ref-Spratling10" class="csl-entry" role="doc-biblioentry">
Spratling, M. W. (2010). <span>‘Predictive coding as a model of response
properties in cortical area <span>V</span>1’</span>, <em>Journal of
Neuroscience</em>, 30: 3531–43.
</div>
<div id="ref-Spratling17" class="csl-entry" role="doc-biblioentry">
——. (2017). <span>‘A review of predictive coding algorithms’</span>,
<em>Brain and Cognition</em>, 112: 92–7.
</div>
<div id="ref-Sprevak18b" class="csl-entry" role="doc-biblioentry">
Sprevak, M. (2020). <span>‘Two kinds of information processing in
cognition’</span>, <em>Review of Philosophy and Psychology</em>, 11:
591–611.
</div>
<div id="ref-Sprevak20e" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding: appendix’</span>,
<em>TBC</em>.
</div>
<div id="ref-Sprevak20d" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>IV</span>: The
implementation level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20c" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>III</span>: The
algorithmic level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20a" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>I</span>:
introduction’</span>, <em>TBC</em>.
</div>
<div id="ref-SrinivasanLaughlinDubs82" class="csl-entry"
role="doc-biblioentry">
Srinivasan, M. V., Laughlin, S. B., &amp; Dubs, A. (1982).
<span>‘Predictive coding: A fresh view of inhibition in the
retina’</span>, <em>Proceedings of the Royal Society, Series B</em>,
216: 427–59.
</div>
<div id="ref-Wiese17" class="csl-entry" role="doc-biblioentry">
Wiese, W. (2017). <span>‘Action is enabled by systematic
misrepresentation’</span>, <em>Erkenntnis</em>, 82: 1233–52.
</div>
</div>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Marr’s use of the term
‘computational’ here is not meant to imply that his other levels of
description are not computational. His usage of the term derives from
mathematical logic, where a ‘computational’ theory denotes relationships
between tasks that are blind to differences in algorithms or physical
implementation (as in the identification of relations of computational
equivalence).<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation"
data-cites="Marr82">Marr (1982)</span>, pp. 68–74. The full story about
the informal task is complex, and ‘edges’ should be understood to
include not only the boundaries of objects, but also regions of the
visual field where there are changes in reflectance, illumination,
depth, or surface orientation.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Marr thought that this computation
was accomplished by the action of retinal ganglion cells: ‘Take the
retina. I have argued that from a computational point of view, it
signals <span class="math inline">\(\nabla ^2 G \ast I\)</span> (the X
channels) and its time derivative <span
class="math inline">\(\partial/\partial t (\nabla ^2 G \ast I)\)</span>
(the Y channels). From a computational point of view, this is a precise
specification of what the retina does.’ <span class="citation"
data-cites="Marr82">(Marr 1982 p. 337)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>See <span class="citation"
data-cites="Marr82">Marr (1982)</span>, p. 22.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>See <span class="citation"
data-cites="ShagrirBechtel13">Shagrir &amp; Bechtel (2017)</span>; <span
class="citation" data-cites="Shagrir10a">Shagrir (2010)</span> for a
helpful explanation of the ‘what’ and ‘why’ at Marr’s computational
level.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>A range of other formalisations can
be found in <span class="citation" data-cites="Bogacz17">Bogacz
(2017)</span>; <span class="citation" data-cites="Friston03">Friston
(2003)</span>; 1330–1339; <span class="citation"
data-cites="Friston05">Friston (2005)</span>, pp. 819–821; <span
class="citation" data-cites="Friston09">Friston (2009)</span>, p. 296;
<span class="citation" data-cites="Spratling17">Spratling (2017)</span>,
pp. 92–93.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 2.4.<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 5.<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 6.1.<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20d">Sprevak (forthcoming)</span>, Section 5.<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13a">Clark (2013a)</span> for examples of how precision
weighting can explain a range of otherwise puzzling cases for the view
(e.g. habit-based action and behaviour during model-free learning). See
<span class="citation" data-cites="MillerClark18">Miller &amp; Clark
(2018)</span>, p. 2568 for their response to the objection that
precision weighting functions as a ‘magic modulator’ that allows
predictive coding to accommodate every possible behaviour.<a
href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>For further discussion of this
problem, see <span class="citation" data-cites="Sprevak20d">Sprevak
(forthcoming)</span>, Section 8.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13">Clark (2013b)</span>, p. 193 for a statement of the
problem.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>See also <span class="citation"
data-cites="Hohwy13">Hohwy (2013)</span>, pp. 87, 185; <span
class="citation" data-cites="Clark15">Clark (2016)</span>,
pp. 265–268;<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>We will see some constraints flow
from what predictive coding says at the algorithmic level and
implementation level <span class="citation"
data-cites="Sprevak20c Sprevak20d">(Sprevak forthcoming sec. 2.5;
forthcoming sec. 7)</span>. However, as will become clear, what
predictive coding says at those levels is by no means a complete account
of the relevant constraints faced by the brain in inference or
learning.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref15" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>See also <span class="citation"
data-cites="Clark15">Clark (2016)</span>, pp. 265–266<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>See <span class="citation"
data-cites="Friston10">Friston (2010)</span>, pp. 133–134; <span
class="citation" data-cites="FristonDaunizeau10">Friston et al.
(2010)</span>; <span class="citation" data-cites="Clark15">Clark
(2016)</span>, Section 4.5; <span class="citation"
data-cites="Hohwy13">Hohwy (2013)</span>, Ch. 4.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>As well proposing a unified account
of the problem facing the brain in perception and motor control,
predictive coding also suggests that the algorithms that govern
perceptual and motor processing have a great deal in common <span
class="citation" data-cites="Sprevak20c">(see Sprevak forthcoming sec.
6.1)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>For the benefits of predictive
coding’s task description of motor control see <span class="citation"
data-cites="Friston11">Friston (2011)</span>, <span class="citation"
data-cites="FristonDaunizeau10">Friston et al. (2010)</span>; <span
class="citation" data-cites="Wiese17">Wiese (2017)</span>, <span
class="citation" data-cites="PickeringClark14">Pickering &amp; Clark
(2014)</span>. For benefits of alternative approaches, see <span
class="citation" data-cites="Kording07">Kording (2007)</span>; <span
class="citation" data-cites="ShadmehrKrakauer08">Shadmehr &amp; Krakauer
(2008)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref19" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>For other examples of non-classical
effects in the early visual system that appear to be accommodated by
predictive coding, see <span class="citation"
data-cites="JeheeBallard09">Jehee &amp; Ballard (2009)</span>; <span
class="citation" data-cites="KokJeheeLange12">Kok et al. (2012)</span>;
<span class="citation" data-cites="HosoyaBaccus05">Hosoya et al.
(2005)</span>; <span class="citation" data-cites="RaoSejnowski02">Rao
&amp; Sejnowski (2002)</span>; <span class="citation"
data-cites="Muckli10">Muckli (2010)</span>; <span class="citation"
data-cites="KokLange15">Kok &amp; Lange (2015)</span>; <span
class="citation" data-cites="Spratling10">Spratling (2010)</span>; <span
class="citation" data-cites="AlinkSchwiedrzi10">Alink et al.
(2010)</span>; <span class="citation"
data-cites="MurrayKersten02">Murray et al. (2002)</span>. For
alternative computational-level accounts of these non-classical effects
(e.g. in terms of divisive normalisation), see <span class="citation"
data-cites="AitchisonLengyel17">Aitchison &amp; Lengyel (2017)</span>,
p. 224; <span class="citation" data-cites="CarandiniHeeger12">Carandini
&amp; Heeger (2012)</span>; <span class="citation"
data-cites="SchwarzSimoncelli01">Schwarz &amp; Simoncelli
(2001)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>For example, see <span
class="citation" data-cites="Allen17">Allen (2017)</span>; <span
class="citation" data-cites="Carruthers06">Carruthers (2006)</span>;
<span class="citation" data-cites="BayneBrainardByrne19">Bayne et al.
(2019)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref21" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>For predictive coding as a potential
‘mark of cognitive’, see <span class="citation"
data-cites="Clark17">Clark (2017)</span>; <span class="citation"
data-cites="KirchhoffKiverstein19">Kirchhoff &amp; Kiverstein
(2021)</span>; <span class="citation"
data-cites="RamsteadKirchhoffConstant21">Ramstead et al.
(2021)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref22" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>Friston does not use these terms. He
refers to both as ‘variational’ free energy.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref23"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p><span class="citation"
data-cites="FristonStephan07">Friston &amp; Stephan (2007)</span>,
pp. 419–420, 451; <span class="citation"
data-cites="FristonKilner06">Friston et al. (2006)</span>, p. 85<a
href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p>See <span class="citation"
data-cites="FristonStephan07">Friston &amp; Stephan (2007)</span>,
p. 419.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref25" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20e">Sprevak (forthcoming)</span>, Section 1 for the
connection between variational free energy and Bayesian inference.<a
href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p>For further discussion of this
point, see <span class="citation" data-cites="Sprevak18b">Sprevak
(2020)</span>, pp. 602–604.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref27" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn28" role="doc-endnote"><p>For discussion of this point, see
<span class="citation"
data-cites="BruinebergKiversteinRietveld18">Bruineberg et al.
(2018)</span>; <span class="citation"
data-cites="ColomboWright18">Colombo &amp; Wright (2021)</span>; <span
class="citation" data-cites="Sprevak18b">Sprevak (2020)</span>.<a
href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29" role="doc-endnote"><p>See <span class="citation"
data-cites="Machery18">Machery (forthcoming)</span>, Section 1.1.<a
href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30" role="doc-endnote"><p>ibid.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref30"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31" role="doc-endnote"><p>ibid., pp. 53–55; <span
class="citation" data-cites="CorlettFrith09">Corlett et al.
(2009)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref31" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn32" role="doc-endnote"><p>For example, see <span
class="citation" data-cites="FletcherFrith09">Fletcher &amp; Frith
(2009)</span>, p. 55–56.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33" role="doc-endnote"><p>See <span class="citation"
data-cites="Machery18">Machery (forthcoming)</span>, Section 3.2 for a
similar point regarding evolutionary psychology.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref33"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13">Clark (2013b)</span>, pp. 200–201.<a
href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div>

                            </div>
                            
                        </div>

                    </div>

                    <div class="is-col is-33">     
                        <div class="is-hidden-print is-hidden-mobile is-sticky">
                            
                                <h1 style="margin-top: 0px;">Contents</h1>
                                <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#minimising-sensory-prediction-error"><span style="visibility: visible;">2</span> &nbsp;  Minimising sensory prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#formal-and-informal-descriptions"><span style="visibility: visible;">3</span> &nbsp;  Formal and informal descriptions</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#precision-weighting-of-prediction-errors"><span style="visibility: visible;">4</span> &nbsp;  Precision weighting of prediction errors</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#long-term-prediction-error-and-the-dark-room-objection"><span style="visibility: visible;">5</span> &nbsp;  Long-term prediction error and the dark-room objection</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#evidence-for-predictive-coding"><span style="visibility: visible;">6</span> &nbsp;  Evidence for predictive coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-case-based-defence"><span style="visibility: visible;">7</span> &nbsp;  The case-based defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-free-energy-defence"><span style="visibility: visible;">8</span> &nbsp;  The free-energy defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-instrumental-value-defence"><span style="visibility: visible;">9</span> &nbsp;  The instrumental-value defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#conclusion"><span style="visibility: visible;">10</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                            
                            
                        </div>
                    </div>
                </div>
            </main>

        <footer class="footer"></footer>

        </div>

        <script src="https://marksprevak.com/kube/js/kube.min.js"></script>
<script>
    $K.init();
</script>


    </body>
</html>
