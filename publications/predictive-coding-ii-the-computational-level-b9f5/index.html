<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Predictive coding II: The computational level | Mark Sprevak</title>
        <meta name="description" content="">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" href="https://marksprevak.com/kube/css/kube.min.css" />
<link rel="stylesheet" href="https://marksprevak.com/css-customisations/sprevak.css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<title>Mark Sprevak</title>
<base href="https://marksprevak.com/">
<link rel="canonical" href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,700%7CLato:400,700" rel="stylesheet">

    </head>
    <body>
        <div class="page wrapper">

            <header class="header">
                <div class="is-navbar-container" style="padding-bottom: 6px; padding-top: 0px; margin-bottom: 12px; border-bottom: 1px solid; border-color: rgba(0, 0, 0, 0.3);">
    <div class="is-brand">
        <div class="titlebar"><a href="https://marksprevak.com/">Mark&nbsp;Sprevak</a></div>
        
        <a href="#"
                style="color: rgba(0, 0, 0, 0.8); text-decoration: none; border-bottom: none; font-size:18px;"
                class="is-hidden-print nav-toggle is-push-right-mobile is-shown-mobile icon-kube-menu"
                data-kube="toggle"
                data-target="#top-navbar"></a>
    </div>
    <div id="top-navbar" class="is-navbar is-hidden-print is-hidden-mobile">
        <nav class="is-push-right">
            <ul style="text-align: right;">
                
                
                
                
                
                <li  >
                    <a href="https://marksprevak.com/publications/" style="text-decoration: none; border-bottom: none;">Publications</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/talks/" style="text-decoration: none; border-bottom: none;">Talks</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/outreach/" style="text-decoration: none; border-bottom: none;">Outreach</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/cv/" style="text-decoration: none; border-bottom: none;">CV</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/phds/" style="text-decoration: none; border-bottom: none;">PhD study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/mscs/" style="text-decoration: none; border-bottom: none;">MSc study</a>
                </li>
                
                
                
                <li  >
                    <a href="https://marksprevak.com/teaching/" style="text-decoration: none; border-bottom: none;">Teaching</a>
                </li>
                
                
            </ul>
        </nav>
    </div>
</div>

            </header>

            <main class="main">
                <div class="is-row">

                    <div class="is-col is-67">     

                        <div style="padding-bottom: 30px;">
                            <div style="margin-bottom: 10px;">
                                <h1 class="is-color-black" style="margin-top: 0px; margin-bottom: 0px;">Predictive coding II: The computational level</h1>
                                
                                <p class="is-muted" style="margin-top: 10px;">
                                    
                                        draft  &nbsp;
                                    
                                    
                                </p>
                                <p class="is-small" style="margin-top: 10px;">
                                    <span>Last updated 19 October 2021</span>
                                    
                                </p>
                            </div>
                            <div class="is-hidden-print">
                                
<a href="https://marksprevak.com/pdf/paper/Sprevak--Predictive-Coding-2-Computation.pdf" target="_blank" class="label is-primary is-focus" style="margin-left: 0px; margin-right:5px;">
    <i class="far fa-file-pdf" style="font-size: 12px;"></i>
    &nbsp;PDF
</a>



<a href="http://philsci-archive.pitt.edu/id/eprint/19366" target="_blank" class="label is-tertiary is-focus" style="margin-left: 0; padding-left: 0; margin-right:2px;">
    preprint
</a>



                            </div>
                        </div>

                        <div class="is-hidden-mobile">
                            
                        </div>
                        <div class="is-shown-mobile">
                            
                            
                            <div class="is-muted is-smaller is-hidden-print">
                                Abstract:
                            </div>
                            <div class="article-style" style="margin-bottom: 30px;">
                                
                            </div>
                            
                        </div>

                        <div>
                            
                            <div class="is-shown-mobile">
                                
                                    <h1 style="margin-top: 0px;" id="internal-mds-toc">Contents</h1>
                                    <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#minimising-sensory-prediction-error"><span style="visibility: visible;">2</span> &nbsp;  Minimising sensory prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#formal-and-informal-descriptions"><span style="visibility: visible;">3</span> &nbsp;  Formal and informal descriptions</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#precision-weighting-of-prediction-errors"><span style="visibility: visible;">4</span> &nbsp;  Precision weighting of prediction errors</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#long-term-prediction-error-and-the-dark-room-objection"><span style="visibility: visible;">5</span> &nbsp;  Long-term prediction error and the dark-room objection</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#evidence-for-predictive-coding"><span style="visibility: visible;">6</span> &nbsp;  Evidence for predictive coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-case-based-defence"><span style="visibility: visible;">7</span> &nbsp;  The case-based defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-free-energy-defence"><span style="visibility: visible;">8</span> &nbsp;  The free-energy defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-instrumental-value-defence"><span style="visibility: visible;">9</span> &nbsp;  The instrumental-value defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#conclusion"><span style="visibility: visible;">10</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                                
                                
                            </div>
                            <div class="article-style">
                                <div>
<h1 data-number="1" id="introduction"><span
class="header-section-number">1</span> Introduction</h1>
<p>When we encounter a new computing device, we often try to describe
its computational characteristics in terms of the task it faces: this
shop’s cash register has the task of <em>adding numbers</em>, this
computer programme has the task of <em>sorting names into alphabetical
order</em>, this Excel spreadsheet has the task of <em>calculating
expected losses</em>. As well as asking a <em>how</em>-question about
the device – How does it work? – we might ask a <em>what</em>-question:
What is the problem it is trying to solve? What is the nature of the
task the device faces? A theory at Marr’s computational level aims to
provide an answer to this question. It aims to identify the
<em>computational problem</em> that the device faces.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>What is the computational problem faced by the brain? Conventional
approaches in cognitive science tend to start from the assumption that
the brain faces <em>many</em> different computational problems.
Different aspects of human cognition – e.g. perception, motor control,
decision making, language learning – require our brains to respond to
different types of computational challenge. Each is likely to have its
own unique computational nature and it is likely to deserve its own
Marrian computational-level description. On such a picture, it makes
sense for cognitive science to tackle human cognition using a <em>divide
et impera</em> approach: it should break up human cognition into its
multiple computational problems, each of which could be described in
turn.</p>
<p>Predictive coding suggests that this strategy, and the ‘many
problems’ assumption on which it is based, is wrong. The brain faces a
<em>single</em> type of computational challenge when engaged in
cognition. At Marr’s computational level, a single, unified story should
be told about the nature of that challenge. Apparent differences between
different problems that the brain confronts in perception, motor
control, decision making, language learning, and so on mask an
underlying unity that all these problems share. They are all instances
of a single overarching computational task: to <em>minimise sensory
prediction error</em>.</p>
<p>Sections 2–4 attempt to unpack this claim in more detail. Sections
5–8 turn to the evidence for the claim. I outline three main strategies
that an advocate of predictive coding might draw on to defend the claim:
the <em>case-based</em> defence (Section 7), the <em>free-energy</em>
defence (Section 8), and the <em>instrumental-value</em> defence
(Section 9).</p>
<h1 data-number="2" id="minimising-sensory-prediction-error"><span
class="header-section-number">2</span> Minimising sensory prediction
error</h1>
<p>What does it mean to say that the brain faces the problem of
minimising sensory prediction error? As we will see, there are a variety
of ways of formalising this task in mathematical language. However, an
advocate of predictive coding often starts with an <em>informal</em>
description of the task. Subsequent mathematical descriptions aim to
codify this informal description more precisely and open it up to
proposals that it is tackled by various numerical algorithms. Currently,
there is some degree of uncertainty and disagreement among advocates of
predictive coding about exactly the right way to formalise the task in
mathematical terms. However, there is broad agreement about the
<em>informal</em> nature of the problem. We will begin with this
informal description.</p>
<p>The task of <em>minimising sensory prediction error</em> may be
informally characterised as follows. Brains have sensory organs and
those sensory organs supply them with a continuous stream of input from
the outside world. Brains also have complicated endogenous physical
structures and occurrent activities that determine how they react to
that stream of input. According to predictive coding, the computational
task that a brain faces in cognition is to ensure that these
endogenously generated responses (the brain’s ‘inference’ over its
‘generative model’) cancel out or suppress the incoming flux of physical
signals conveyed by the sensory organs from the outside world (that it
‘predicts’ the incoming ‘sensory evidence’). The degree to which this
happens, or fails to happen, is measured by the <em>sensory prediction
error</em>. This quantity is the discrepancy between the contribution of
the brain’s endogenously generated activities and the incoming physical
signals from the world. The problem that the brain faces – in all
aspects of cognition according to predictive coding – is to minimise the
difference between those two elements. If the brain were to succeed at
doing this then, at the sensory boundary, two opposing forces – the
world’s sensory input (described as excitatory/stimulating) and the
brain’s endogenously generated predictions (described as
inhibitory/suppressing) – would exactly cancel out. The brain’s
anticipatory activity would ‘quench’ the incoming excitation from the
world. In more colourful and metaphorical language:</p>
<blockquote>
<p>… this is the state that the cortex is trying to achieve: perfect
prediction of the world, like the oriental Nirvana, as Tai-Sing Lee
suggested to me, when nothing surprises you and new stimuli cause the
merest ripple in your consciousness. <span class="citation"
data-cites="Mumford92">(Mumford 1992 p. 247, n. 5)</span></p>
</blockquote>
<p>Predictive coding should be understood in this context as a theory
about the subpersonal machinery of cognition, not of our personal-level
conscious experience, but the basic idea described above is correct. The
computational task of the brain is to avoid being perturbed or
‘surprised’ by incoming sensory inputs (in the Shannon
information-theoretic sense of ‘surprise’, <em>viz</em>. unpredicted).
The brain’s objective is to arrange itself and its physical responses so
as to anticipate and thereby cancel out its upcoming sensory input. This
objective – ‘Nirvana’ in the above quotation – is unlikely to ever be
achieved, or to be achieved in any sustained way, because the flux of
sensory input from the world is too rich and complicated for our brains
to be guaranteed to predict it with perfect accuracy. Nevertheless,
<em>trying</em> to predict it is the task the brain faces in
cognition.</p>
<p>Predictive coders suggest that the various computational problems
that the brain faces in perception, learning, motor control, decision
making, and so on, are all instances of this single problem of
minimising sensory prediction error. Our various cognitive capacities
(sensing, planning, and so on), which have traditionally been viewed as
individual solutions to distinct problems (faced in perception, motor
control, and so on), should be viewed as parts of a seamless, unified
response by the brain to a single problem. This suggests that we might
need to rethink how we describe and individuate our cognitive
capacities, and potentially blur the boundaries between them. It is in
this sense that, at Marr’s computational level, predictive coding aims
to offer a grand, unified theory of cognition.</p>
<p>It is worth stressing that it is not novel or unusual to say that
<em>one</em> of the computational challenges faced by the brain is to
minimise sensory prediction error. It is common for contemporary models
in cognitive neuroscience to suggest that the brain engages in sensory
compression <span class="citation" data-cites="Sprevak20a">(Sprevak
forthcoming sec. 2)</span> and to describe certain inference and
learning tasks (particularly, in perception) as minimising sensory
prediction error (ibid., Section 4). What marks predictive coding out as
special in this context is that it says that minimising sensory
prediction error is the brain’s <em>only</em> task.</p>
<h1 data-number="3" id="formal-and-informal-descriptions"><span
class="header-section-number">3</span> Formal and informal
descriptions</h1>
<p>Theories at Marr’s computational level are often precise and
characterised in mathematical language. They are usually both
<em>formal</em> and <em>quantitative</em>. Typically, a theory at Marr’s
computational level will ascribe the task of computing a specific
mathematical function to the brain as well as offering an explanation of
why computing that function would help the brain solve the problem as
informally characterised. For example, in his account of vision Marr,
ascribed computation of the mathematical function <span
class="math inline">\(\nabla ^2 G \ast I\)</span> to the brain. Marr
related this abstract function to the informally characterised task of
<em>edge detection</em>: finding the location of boundaries between
objects in the visual field.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a> Marr argued that the
problem of edge detection (informally characterised) is likely to be an
important task that the brain faces in early vision and that it is a
precursor to solving other problems such as object recognition, depth
perception, or binocular fusion. Marr proposed that the computational
problem the brain undertakes when it attempts to do edge detection could
be characterised as the task of computing of this mathematical
function.</p>
<p>In Marr’s formal description, <span class="math inline">\(I\)</span>
is a two-dimensional matrix of numbers. These numbers encode the
magnitude of light falling on a two-dimensional array of photoreceptors
on the retina. <span class="math inline">\(G\)</span> is a Gaussian
filter which is convolved (<span class="math inline">\(\ast\)</span>)
with the two-dimensional image (<span class="math inline">\(I\)</span>)
and the Laplacian, second-derivative operator (<span
class="math inline">\(\nabla ^2\)</span>) is applied to the result. Marr
argued that if the brain were to compute the zero-crossings of the <span
class="math inline">\(\nabla ^2 G \ast I\)</span> function for various
sizes of Gaussian filter, it could identify areas in the retinal image
that correspond to sharp changes in light intensity. These, Marr argued,
typically correspond in our world to the edges of objects in the visual
field. Hence, if the brain attempts to solve the task of computing the
zero-crossings of the <span class="math inline">\(\nabla ^2 G \ast
I\)</span> function it will thereby attempt to solve the (informally
characterised) problem of edge detection.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>One way in which the relationship between the formal and informal
elements of a computational-level theory has been described is in terms
of the ‘what’ and the ‘why’.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a> The ‘what’ element of a
computation-level theory describes the formal mathematical function that
the device needs to compute. In the above case, this would be <span
class="math inline">\(\nabla ^2 G \ast I\)</span>. The ‘why’ links the
task of computing that abstract mathematical function to some concrete
informally characterised information-processing problem. It explains the
connection between the abstract numerical values that feature in that
function and the physical quantities and the adaptive problems faced by
the embodied device. In the case above, it involves explaining why
computing the zero-crossings of <span class="math inline">\(\nabla ^2 G
\ast I\)</span> would help solve the problem of edge detection as
informally characterised. The ‘what’ element of a computational-level
theory provides a formal, mathematical characterisation of the problem.
The ‘why’ element explains the appropriateness and adequacy of that
mathematical description to the problem facing the brain as informally
conceived.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>The predictive coding community has not yet settled on a single
canonical way to mathematically formalise the task facing the brain. As
we will see shortly, there are many decisions to make about how to
mathematically describe minimising sensory prediction error. An
extremely simple example of a formalisation is given in <span
class="citation" data-cites="Sprevak20c">Sprevak (forthcoming)</span>,
Section 2.1.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> However even in more sophisticated
mathematical treatments, it is common to assume a massively simplified,
stripped-down version of the task. For example, it is common to consider
agents that only have one or two sensory input channels, that only
minimise their current prediction errors, or that make predictions using
a linear generative model. These simplifications help to keep the
formalisation manageable and also serve to highlight specific features
of interest in the intended model.</p>
<p>That said, certain general aspects of the mathematical formalisation
are widely agreed. All the mathematical formalisations tend to agree
that the problem facing the brain is a numerical <em>optimisation
problem</em>. This optimisation problem is regarded as having two free
variables – the <em>generative model</em> and the <em>prediction
values</em>. These collections of quantities are varied, over different
timescales, in order to minimise some objective function – <em>sensory
prediction error</em>. The generative model is typically encoded by a
two-dimensional matrix of numbers. Prediction values are typically
encoded by a vector of numbers that, when combined with the generative
model via multiplication, produce another vector, the <em>sensory
prediction</em>. <em>Sensory input</em> is another vector of numbers,
with the same dimensionality, whose components encode the actual
incoming activity for each physical sensory channel. <em>Sensory
prediction error</em> is a scalar quantity that measures how ‘close’ the
prediction vector is to the sensory input vector. It is often treated as
the (weighted) sum or the (weighted) mean of the squares of the
difference between the components of the sensory input vector and the
sensory prediction vector. The task the brain faces in cognition is to
find a set of prediction values and a generative model such that
prediction errors over sensory inputs are minimised. Characterising the
problem in this way allows many existing numerical optimisation
algorithms – including the huge range of algorithms that attempt to
optimise by gradient descent – to be brought to bear as proposals
regarding how the brain attempts to solve its problem.</p>
<h1 data-number="4" id="precision-weighting-of-prediction-errors"><span
class="header-section-number">4</span> Precision weighting of prediction
errors</h1>
<p>Not all sensory prediction errors matter equally to the brain in its
task of minimising sensory prediction error. Predictive coding
introduces an additional free variable that has not yet been mentioned,
<em>precision weighting</em>, which describes the relative weight of
each sensory prediction error with respect to the others. The brain’s
task is to minimise its <em>precision-weighted</em> sensory prediction
error. Errors with a high degree of precision weighting should be
prioritised in the optimisation task. Errors with a low degree of
precision weighting should be given a lower priority or discounted.
Intuitively, precision weighting encodes ‘what matters’ to the brain
when it is minimising sensory prediction error. Effectively, precision
weighting provides a ‘gain’ that scales each component of the sensory
prediction error.</p>
<p>Precision weighting plays a critically important role in predictive
coding’s computational-level description. It can make certain sensory
prediction errors dominate in the optimisation problem and others small
enough to be ignored. It can also exercise this control in extremely
fine-grained, nuanced ways. Potentially, it can change the gain on each
individual sensory channel independently. Precision weighting is often
described as a ‘distribution’ that determines which sensory prediction
errors are boosted and which are damped down. The overall shape of that
distribution may be complex and it may change radically and rapidly over
time (e.g. on a millisecond timescale). In mathematical terms, precision
weighting is usually represented by a two-dimensional matrix of numbers
that is multiplied by the sensory prediction error vector to scale its
elements.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>Precision weighting plays a number of conceptually distinct roles
within predictive coding.</p>
<p>First, it is assumed to encode the brain’s estimation of
<em>uncertainty</em> associated with its sensory predictions.
Predictions about which the brain is less certain have a larger
variance, which is equivalent to their having a smaller precision
weighting assigned to their corresponding prediction errors. Precision
weighting in this context is often called the ‘inverse of variance’
<span class="citation" data-cites="Friston03">(Friston 2003)</span>.<a
href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a></p>
<p>Second, precision weighting is claimed to determine the <em>direction
of fit</em> of the brain’s sensory predictions. Sensory prediction
errors that have a high degree of precision weighting intuitively
‘matter more’ to the brain and so are more likely to drive action, and
hence function more like motor commands than predictions (see Section
7). Prediction errors with a low associated precision weighting may not
‘matter enough’ meet the threshold to drive motor responses and so may
play a purely epistemic role for the brain <span class="citation"
data-cites="FristonMattoutKilner11 Clark15 PickeringClark14">(Clark
2016, Ch. 5; Friston et al. 2011; Pickering &amp; Clark 2014)</span>.<a
href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></p>
<p>Third, precision weighting is claimed to be related to
<em>attention</em>. When the brain attends to certain features, the
sensory signals associated with those features are the ones for which
the corresponding prediction errors have been assigned a higher weight.
When the brain shifts its attention, this involves a rebalancing in the
distribution of precision weights away from those features. The boost
that precision weighting applies to sensory prediction errors is claimed
to provide a novel account or explanation of attention <span
class="citation" data-cites="FeldmanFriston10">(Feldman &amp; Friston
2010)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<p>Finally, precision weighting sometimes appears to be used as a kind
of ‘fudge factor’ to accommodate behavioural and neural data that do not
straightforwardly fit into the prediction-error-minimisation framework.
If the brain fails to minimise a sensory prediction error, an advocate
of predictive coding might explain this, not as evidence against
predictive coding, but as evidence that the brain assigns a low
precision weighting to that particular sensory prediction error. If one
is permitted to assume an appropriate distribution of precision
weightings at each moment in time, then almost any observation can be
accommodated under predictive coding’s task description.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn11"
class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>
Clearly, some constraints are needed on how a distribution of precision
weightings are assigned to the brain. A number of constraints do arise
from assumptions made at the algorithmic and implementation levels <span
class="citation" data-cites="Sprevak20c Sprevak20d">(Sprevak forthcoming
sec. 2.4; forthcoming sec. 5)</span>. However, finding a sufficient
number of empirically motivated constraints on the assignment of
precision weights remains an open problem for predictive coding.<a
href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>No version of predictive coding can afford to omit precision
weighting from its computational-level account. It would simply not be
credible to claim that there is no difference in the weighting of
different sensory prediction errors. However, the introduction of
precision weighting into the optimisation problem raises a number of
puzzles. It plays many, seemingly distinct functional roles within
predictive coding’s model and it is not obvious how all of these roles
cohere. It is also not clear where independent constraints lie on the
assignment of precision weights given its tremendous power to reshape
the computational task facing the brain.</p>
<h1 data-number="5"
id="long-term-prediction-error-and-the-dark-room-objection"><span
class="header-section-number">5</span> Long-term prediction error and
the dark-room objection</h1>
<p>A second important way in which predictive coding’s
computational-level description should be qualified is that the brain’s
objective is not to minimise its <em>current</em> sensory prediction
error but to minimise some <em>long-term</em> aggregate measure
regarding sensory prediction error. This temporally extended version of
the optimisation problem may be described in various ways: by talking
about the brain needing to minimise ‘global’ prediction error <span
class="citation" data-cites="Lupyan15">(Lupyan 2015)</span>, ‘upcoming’
prediction error <span class="citation" data-cites="Muckli10">(Muckli
2010 p. 137)</span>, ‘long-term average’ of prediction error <span
class="citation" data-cites="Hohwy13">(Hohwy 2013 pp. 90, 175,
176)</span>, or ‘long-term average surprise’ <span class="citation"
data-cites="SchwartenbeckFitzGerald13">(Schwartenbeck et al.
2013)</span>.</p>
<p>Hard questions remain in the predictive coding literature about the
exact nature of the long-term objective and how it should be
mathematically formalised. It is assumed that it is some sort of average
of precision-weighted sensory prediction error taken over time. But what
sort of average, how far into the future it should extend, and what type
of temporal discounting should be applied, is not clear. In the case of
the brain, it is unclear whether the relevant extended period is of the
order of hours, days, years, the expected future lifespan of the agent,
or long enough to include the lives of possible descendants and
evolutionary successors. It is unknown whether the optimisation problem
should be understood as reducing prediction errors relative to the
agent’s <em>own</em> expectations (its subjective probability) of making
future sensory prediction errors, or relative to the objective
<em>chances</em> (objective probability) of it making such errors. Also
unclear is how any long-term error measure (which would be a weighted
sum of sensory prediction errors over time) should be understood as
interacting with precision weighting (which is a weighted sum of current
sensory prediction errors) – i.e. whether precision weighting should be
understood as having a prospective component to allow the brain to
preferentially discount some expected future errors over others. The
possibility of different views on how to answer these questions suggests
that different versions of predictive coding could be developed at the
computational level.</p>
<p>Shared by all views, however, is agreement that we should rule out
any interpretation of predictive coding that says the brain aims only to
minimise its <em>current</em> sensory prediction error. This initial
move plays a significant role in lending plausibility to predictive
coding’s task description. For one thing, it allows advocates of
predictive coding to respond to the infamous ‘dark room’ objection. It
also suggests a way in which predictive coding is compatible with
inferences and behaviour that tend to drive up current sensory
prediction errors, such as curiosity, exploration, and novelty seeking.
Both points are worth reviewing as they are the focus of many criticisms
of predictive coding.</p>
<p>The ‘dark room’ problem is a long-standing objection to predictive
coding. The problem is to explain why, if predictive coding’s
computational-level description is true, we do not always seek out the
most predictable possible environment (e.g. a dark room), and remain
inside for as long as possible. If the brain’s objective is to minimise
its sensory prediction error, why not make that task as easy as possible
by staying inside a maximally predictable sensory environment?<a
href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
<p><span class="citation" data-cites="FristonThornton12">Friston et al.
(2012)</span> offered an initial influential reply to the dark-room
problem.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> Their response focused on the idea
that both our generative model and prediction values, as implemented in
our neural hardware, are physically constrained. There are limits to the
kinds of sensory predictions that our brains can generate and to how
much our generative model and prediction values can be changed. These
constraints, which are assumed not to be open to revision by learning or
inference, are called ‘hyperpriors’. Our hyperpriors bias us towards
making certain types of sensory predictions, and ones that are not
particularly suited to life in a dark room. Consequently, although the
sensory data we might receive inside a dark room might be ‘easy to
predict’ in some absolute sense, due to the biases introduced by our
hyperpriors that sensory data stream might be difficult for creatures
like us to predict. If we were a different different type of creature,
one with different hard-wired biases (maybe a cave-dwelling creature),
we might have no trouble in generating accurate predictions inside a
dark room. However, humans are strongly biased to predict sensory data
from non-dark-room environments, and so we are unlikely to minimise our
sensory prediction errors inside a dark room.</p>
<p>This response highlights an important feature of predictive coding’s
task description: the task facing the brain is a <em>constrained</em>
optimisation problem. The brain’s goal is to minimise its sensory
prediction error by varying its generative model and prediction values
<em>given</em> the many and varied constraints imposed by our physical
hardware about how far and how rapidly those components can change. The
brain’s goal is to minimise its sensory prediction errors relative to
those externally imposed constraints. Although predictive coding’s
computational-level proposals tend to be silent about the specific
nature of those physical constraints, a crucial part of making the view
plausible is to acknowledge that a range of constraints are implicitly
there.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p>
<p>Although <span class="citation"
data-cites="FristonThornton12">Friston et al. (2012)</span>’s reply
brings to the fore an important feature of predictive coding’s
computational-level description, it does not fully address the dark-room
objection. For example, it does not explain why, <em>even relative to a
constrained model</em>, cognitive agents like ourselves still often seek
out novelty and surprise. Even when we <em>can</em> accurately predict
our sensory stream in a situation, we sometimes choose a more surprising
alternative. In other words, agents like ourselves sometimes prefer
novelty and surprise to maximal sensory predictability. How is that
consistent with what predictive coding says at the computational
level?<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>An alternative reply, which fares better at dealing with this kind of
objection, is to emphasise the long-term and prospective character of
the brain’s goal. The world in which we live contains environments that
are relatively easier for us to predict and environments that are harder
for us to predict. Successfully predicting our sensory inputs by
choosing to exclusively inhabit environments that are easier to predict
may not be a good solution to the brain’s long-term problem. An agent
who sequesters itself inside an easy-to-predict environment leaves
itself hostage to fortune. Unpredictable elements may intrude on the
agent in ways that it has not previously taken the trouble to learn how
to handle – lighting conditions may change, a stranger might enter, food
supplies might run out. To guard against future surprises, and perhaps a
precipitous rise in sensory prediction error, it may be better – in the
terms of meeting the goal of minimising long-term sensory prediction
error – to choose to leave an easy-to-predict environment and engage in
some exploration to learn a more comprehensive model of the world.
Exploring harder-to-predict environments might raise sensory prediction
error in the short term, but that rise is a hedge against future,
possible bigger surprises to which an agent who leads an entirely
sheltered life would be vulnerable. There is obviously a balance to
strike between the cost of exploring (in terms of an expected rise in
current sensory prediction error), and its potential future pay-off (in
terms of an expected fall in long-term sensory prediction error). But
that there is a trade-off between the value of exploration and
exploitation is to be expected on any model of cognition. The important
point is that what predictive coding says at the computational level at
least allows for the possibility that a cognitive agent may sometimes
prefer unpredictable environments to predictable ones. Curiosity,
exploration, and novelty seeking are consistent with the brain aiming to
minimise long-term sensory prediction error, even if they entail
short-term rises in sensory prediction error along the way <span
class="citation" data-cites="SchwartenbeckFitzGerald13">(Schwartenbeck
et al. 2013)</span>.</p>
<h1 data-number="6" id="evidence-for-predictive-coding"><span
class="header-section-number">6</span> Evidence for predictive
coding</h1>
<p>Justification for predictive coding’s computational-level claim often
rests on one of three strategies. I call these strategies the
<em>case-based</em> defence, the <em>free-energy</em> defence, and the
<em>instrumental-value</em> defence. The case-based defence considers a
range of cognitive tasks and aims to show that all of these tasks can
and should be described as minimising sensory prediction error. The
free-energy defence shortcuts consideration of individual tasks and
attempts to establish predictive coding’s computational-level claim in
one fell swoop by appeal to Karl Friston’s ‘free-energy’ principle. The
instrumental-value defence focuses on the utility of predictive coding
to computational cognitive science and argues that it provides a
desirable set of heuristics to make sense of, and discern patterns
within, the mass of human behavioural and neural responses.</p>
<h1 data-number="7" id="the-case-based-defence"><span
class="header-section-number">7</span> The case-based defence</h1>
<p>The case-based defence attempts to show that a range of tasks facing
the brain – for example, various problems it encounters during
perception, decision-making, planning, motor control – can and should be
thought of as minimising sensory prediction error. Some of these tasks
may, on the basis of rival research programmes in cognitive science,
already have computational-level descriptions associated with them. The
job of predictive coding is to show that these tasks are better
conceptualised as instances of minimising sensory prediction error.
Behavioural and neural responses that might previously have been
explained as attempts by the brain to compute some domain-specific
function should be redescribed in the manner predictive coding
suggests.</p>
<p>The case-based defence is an abductive argument for predictive
coding’s computational-level description. It attempts to justify its
computational-level account based on its successful application to a
number of specific cases. Any such defence of predictive coding faces an
obvious epistemic hurdle. In its strongest form, predictive coding makes
a universal claim: <em>every</em> problem the brain encounters in
cognition is to minimise sensory prediction error. Showing that a
limited number of cases can and should be described as minimising
sensory prediction error does not entail that other, perhaps as yet
unconsidered, cases should be described in the same way. No amount of
success in applying predictive coding’s task description to specific
domains of cognition entails that in <em>every</em> domain the problem
the brain faces is minimisation of sensory prediction error.
Nevertheless, non-demonstrative evidence still has probative value, and
in science it is common to gain evidence for grand theories by
considering their application to specific cases.</p>
<p>There are clearly more and less effective ways of making this sort of
argument for predictive coding work. One plausible strategy is to focus
on a <em>diverse</em> range of cases. One might hope that the cases
considered form a <em>representative</em> sample of problems the brain
faces in cognition.</p>
<p>Early work on predictive coding focused almost entirely on the early
visual system <span class="citation"
data-cites="RaoBallard99 SrinivasanLaughlinDubs82 Atick92">(Atick 1992;
Rao &amp; Ballard 1999; Srinivasan et al. 1982)</span>. Ideally,
predictive coding should seek to gain empirical support by showing that
it applies to other kinds of task. If it can be shown that many, diverse
aspects of cognition – ones that have no obvious connection either to
each other or to the early visual system – can and should fall under
predictive coding’s task description, then that would lend credibility
to the idea that not just in some cases, but in every case, the problem
the brain faces is that of sensory prediction error minimisation.
Example of such ‘non-obvious’ applications of predictive coding’s task
description include music perception <span class="citation"
data-cites="KoelschVuustFriston19">(Koelsch et al. 2019)</span>;
formation of emotions and judgements about bodily ownership <span
class="citation" data-cites="Seth13">(Seth 2013)</span>; binocular
rivalry <span class="citation" data-cites="HohwyRoepstorff08">(Hohwy et
al. 2008)</span>; formation of judgements about the nature of the self
<span class="citation" data-cites="HohwyMichael17">(Hohwy &amp; Michael
2017)</span>; and the perceptual, doxastic, and motor characteristics of
schizophrenia and autism <span class="citation"
data-cites="FletcherFrith09 CorlettFletcher14 PellicanoBurr12 FristonStephanMontague14">(Corlett
&amp; Fletcher 2014; Fletcher &amp; Frith 2009; Friston et al. 2014;
Pellicano &amp; Burr 2012)</span>.</p>
<p>Predictive coding’s flagship example of a ‘non-obvious’ application
of its computational-level description is <em>motor control</em>.<a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a> The majority of rival computational
approaches to cognition treat motor control and perception as entirely
separate problems that lie at opposite ends of cognitive processing. In
perception, the brain’s task is to use its sensory data to build and
update an accurate (or instrumentally adequate) model of the world. In
motor control, its task is to use that model, along with some set of
goals or intentions, to output a sequence of motor commands that would
direct muscle actuators towards accomplishing those goals or intentions.
The two problems are of course not independent: perception requires
motor control to move the eyes and motor control requires the perceptual
model to be regularly updated. However, irrespective of any threads
running between the two problems inside a cognitive agent, they remain
distinct problems. The computational problem facing the brain in
perception is to create an accurate model of the world. The
computational problem facing the brain in motor control is to use that
model to generate motor commands to fulfil goals.</p>
<p>According to predictive coding, perception and motor control are
instances of the same problem, namely, that of minimising sensory
prediction error. In perception, the brain minimises sensory prediction
error by varying its generative model and prediction values. In motor
control, the brain minimises its sensory prediction error by varying its
bodily position and the external world (via muscle actuators) to change
its incoming sensory stream to make its sensory predictions more
accurate. In both cases, the problem facing the brain is the same – to
minimise sensory prediction error. The difference lies in the method the
brain uses to try to achieve it. Advocates of predictive coding call the
first type of method ‘passive’ inference and the second ‘active’
inference. At Marr’s algorithmic level, they claim that active and
passive inference work together during cognitive processing to solve the
task. At Marr’s computational level, they claim that the ‘motor’ problem
of reaching for a glass of water should be redescribed, not as a classic
inverse kinematics problem of the brain inferring a set of motor
commands that would accomplish its goal, but as the brain predicting
that the hand is already holding the glass of water (along with all its
sensory and particularly proprioceptive consequences), and then it
attempting to minimise its sensory prediction error by varying its limbs
and the glass to make this false sensory prediction true.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn18"
class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a></p>
<p>It is worth noting that, for each individual case, a case-based
argument requires predictive coding to meet two separate challenges. The
first challenge is to show that the case in question <em>can</em> be
described as an instance of sensory-prediction-error minimisation. The
second is to show that it <em>should</em> be described this way. The
first challenge requires one to show that predictive coding’s
computational-level description is <em>consistent</em> with whatever
data is associated with that case. The second challenge is to show that
one should <em>prefer</em> predictive coding’s computational-level
description of that data to rival or traditional accounts. There should
be some net benefit to adopting predictive coding’s computational-level
treatment of that instance of cognition – e.g. in terms of increased
predictive accuracy, increased explanatory power, or some other
theoretical virtue. The kinds of justification given for this second
point are often complicated and contentious. The benefits of predictive
coding’s task description are not straightforward to calculate and need
to be measured relative to a broad range of epistemic standards,
interests, and goals. The claimed benefits are often also conditional on
buying into other elements of predictive coding’s research programme
(e.g. its prospective application to all of cognition, or elements of
its proposals at the algorithmic and implementation levels). Different
researchers may take different views about the worth of any potential
benefits on offer.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a></p>
<!-- Even if, as mooted above, perceptual tasks and motor control -->
<!-- tasks *can* both be described as instances of sensory -->
<!-- prediction error minimisation, it is a further question whether -->
<!-- they *should* be described this way.  -->
<!-- It is one thing to show that, say, a motor control task *can* both be -->
<!-- described as an instance of sensory prediction error minimisation.  It -->
<!-- is another thing to show that it *should* be described this way. -->
<p>To illustrate how these questions about preferability might be
addressed, we will switch back to the case of the early visual system.
In that case, two main strategies have been used to justify predictive
coding’s computational-level description: (i) its predictive and
explanatory benefits over other computational approaches; (ii) the
broader theoretical virtues offered by the view (e.g. simplicity,
elegance, and unifying power).</p>
<p>The first set of considerations surround predictive coding’s ability
to predict and explain behavioural or neural responses that are not
predicted or explained on other views. Traditional computational-level
descriptions of the early sensory system tend to suggest that its
computational task is to function as a Gabor filter bank on retinal
images to extract features such as orientation, spatial frequency,
colour, direction of motion, and disparity <span class="citation"
data-cites="CarandiniDemb05">(Carandini et al. 2005)</span>. For
example, the task of some neurons in V1 is to convolve a matrix of
retinal data with a range of Gabor filters to pick out lines in the
visual field of various orientations and spatial frequencies. However,
observations about what the brain does do not always fit with that
computational-level description. These so-called ‘non-classical’ effects
count as anomalies relative to the early visual system’s claimed
objective. One such non-classical effect is <em>end-stopping</em> <span
class="citation" data-cites="OlshausenField05">(Olshausen &amp; Field
2005)</span>. Some neurons in V1 give a strong response to a line at a
particular orientation in the visual field, but this response is reduced
or eliminated if the line extends outside that neuron’s receptive field.
This does not fit with a classical Gabor-filter description of their
computational task. A Gabor filter should continue to fire regardless of
whether a line extends outside its receptive field or not.</p>
<p>Predictive coding suggests that the computational task faced by the
early visual system is not to perform Gabor filtering, but to minimise
sensory prediction error. Under this task description, end-stopping may
be reinterpreted as signalling the difference between the current
sensory input and the brain’s sensory prediction (based on its
statistically-informed expectations regarding visual input). In our
environment, the statistical norm is for lines in the visual field to
extend beyond the tiny regions covered by individual receptive fields.
Lines that violate this norm are uncommon and, everything being equal,
should be expected to be the source of sensory prediction errors. The
unexplained behaviour of V1 cells when end-stopping may be reinterpreted
as positively signalling such sensory prediction errors <span
class="citation" data-cites="RaoBallard99 KokLange15">(Kok &amp; Lange
2015 p. 232; Rao &amp; Ballard 1999)</span>. For the more common stimuli
(long lines extending outside individual receptive fields), the V1
neurons tend to be quiet, but for the rarer stimuli (short lines that
fall inside individual receptive fields), the neurons tend to be more
active, singingly something new or surprising. End-stopping, not
accommodated by traditional computational-level descriptions, can
potentially be accommodated under predictive coding’s
computational-level description.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn20" class="footnote-ref"
id="fnref20" role="doc-noteref"><sup>20</sup></a></p>
<p>A second and entirely distinct set of motivations used to justify
predictive coding’s task description are based around the view’s alleged
broader theoretical virtues, such as its relative simplicity, scope, and
unifying power with respect to other computational-level approaches.
Arguably, even if predictive coding were to do no better than
alternative computational-level approaches in terms of explaining
anomalous behaviour/neural effects, these general theoretical virtues
may still give one a reason to favour the view over alternatives.
Traditional computational-level approaches tend to adopt a <em>divide et
impera</em> approach to cognition and assume that the brain is facing
multiple computational problems. A complete description of human
cognition at Marr’s computational level is expected to consist in a
patchwork of theories covering distinct tasks the brain faces. Each
domain of cognition – perception, motor control, decision making,
language learning – is likely to merit its own computation-level
account. This disaggregation of computational-level theories reflects
the assumption that the brain is a device that is optimised to solve a
motley of problems, rather than a device tuned to solve just one
problem. Stepping back from these various computational-level theories,
there need be no overarching pattern or unity regarding what the brain
is aiming to do.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn21" class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a> Predictive coding, in contrast,
claims to provide a unified, complete, and relatively simple description
of the computational problem the brain faces in cognition. If the view
can be shown to be as empirically adequate (or at least, no worse than
alternatives), then uncovering this unity at the computational level
would, by itself, be a mark in its favour. All else being equal, it is
rational to prefer grand, simple, unifying theories (where available)
over less unified alternatives.</p>
<blockquote>
<p>It is the first time that we have had a theory of this strength,
breadth and depth in cognitive neuroscience … I take that property as a
sure sign that this is a very important theory … Most other models,
including mine, are just models of one small aspect of the brain, very
limited in their scope. This one falls much closer to a grand theory.
<span class="citation" data-cites="Huang08">(Stanislas Dehaene quoted in
Huang 2008)</span></p>
</blockquote>
<p>A unified computational-level theory of cognition promises to reveal
something profound about the fundamental nature of cognition. It tells
us that cognition is not a motley, a jumble of distinct phenomena, but a
response to a single computational problem. Predictive coding identifies
what seemingly unrelated domains of human cognition – e.g. perception,
motor control, decision making, language learning – have in common. It
potentially explains why each counts as an instance of cognition. It
provides us with an account of cognition that enables us to judge
whether new and perhaps unexpected or previously unconsidered phenomena
are genuinely cognitive.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn22" class="footnote-ref"
id="fnref22" role="doc-noteref"><sup>22</sup></a> Understood as a
metaphysical claim, predictive coding suggests that cognition is
essentially a unified and simple functional kind. In a manner that is
not even attempted by an open-ended and disaggregated set of
computational theories, it attempts to provide information about what
cognition is. If a theory can uncover fundamental, universal principles
while remaining consistent with empirical data – if it unifies and
simplifies an otherwise disordered domain – then, all else being equal,
that is a reason to favour it over non-unified alternatives. Knowledge
about the essence of things and general patterns into which they enter
is surely what science aspires to.</p>
<h1 data-number="8" id="the-free-energy-defence"><span
class="header-section-number">8</span> The free-energy defence</h1>
<p>A case-based defence of predictive coding is likely to be a long,
hard slog and may ultimately not convince someone who is sceptical of
the view. It requires engaging with the empirical details of many
different individual tasks and showing that their distinctive effects –
of which there are many – are adequately captured or recaptured on
predictive coding’s task description. There is no obvious stopping point
to this: it is not obvious when enough cases – or a diverse enough array
of cases – would have been considered to warrant the conclusion that not
just <em>some</em> tasks, but <em>every</em> task faced by the brain is
sensory prediction error minimisation. The free-energy defence aims to
shortcut all this. It tries to establish predictive coding’s
computational-level claim in a single step by appeal to properties
necessarily shared by all cognitive (or living) systems. <span
class="citation" data-cites="Friston10">Friston (2010)</span> presents a
defence of predictive coding along these lines based on his ‘free
energy’ formulation of predictive coding. According to Friston, the task
faced by the brain is that of <em>minimising free energy</em>.
Minimising free energy can be shown, if appropriate further assumptions
are made, to be equivalent to the task of minimising sensory prediction
error.</p>
<p>Free energy is a mathematical quantity that appears in classical
thermodynamics, statistical mechanics, and information theory. Friston’s
central claim is that there is a relationship between two distinct
applications of the mathematical abstraction of free energy:
<em>variational</em> free energy and what I will call
<em>homoeostatic</em> free energy.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn23" class="footnote-ref"
id="fnref23" role="doc-noteref"><sup>23</sup></a> Variational free
energy is an information-theoretic quantity predicated of agents who
engage in probabilistic inference. If a probabilistic reasoner minimises
their variational free energy, then this can be shown to be equivalent
to them approximating Bayesian inference <span class="citation"
data-cites="Sprevak20e">(see Sprevak forthcoming sec. 1)</span>. Granted
a number of further assumptions, minimising variational free energy can
also be shown to entail minimising sensory prediction error <span
class="citation" data-cites="Sprevak20e">(see Sprevak forthcoming sec.
2)</span>. ‘Homoeostatic’ free energy is a distinct quantity which
applies the same abstract free-energy formalism to an entirely distinct
set of properties. Unlike variational free energy, it is not (or at
least, not directly) associated with the subjective probabilities that
feature in an agent’s probabilistic inferences. Rather, it is associated
with the objective probability of the macroscopic physical state that
the agent is in given its physical environmental conditions. Minimising
homoeostatic free energy is associated with the agent’s survival within
a narrow band of macroscopic physical states. According to Friston,
these two kinds of free energy – homoeostatic free energy and
variational free energy – are interlinked. Agents who minimise their
homoeostatic free energy – i.e. who survive and maintain homeostasis and
thereby maintain their macroscopic physical state in response to likely
environmental perturbations – also minimise their variational free
energy (and hence, given certain assumptions, minimise their sensory
prediction error).</p>
<p>Friston is clear that neither free-energy measure should be
identified with <em>thermodynamic</em> free energy. Thermodynamic free
energy measures the useful mechanical work that can be obtained from a
physical system. It is usually defined in terms of that system’s ability
to exert macroscopic mechanical forces on its surroundings – its energy
that is ‘free’ to perform mechanical work. This is normally formalised
as a difference between the physical system’s internal energy and its
thermodynamic entropy (internal energy that is ‘useless’ for work).
Having a reserve of thermodynamic free energy is generally a useful
thing for any cognitive or living creature: an excess of thermodynamic
free energy allows a creature to be able to move or act in a non-random
way in the world. <em>Minimising</em> thermodynamic free energy would
make little or no sense as a survival strategy or as a way to maintain a
creature’s homoeostatic function. Friston is clear that his free-energy
principle – that all cognitive/living systems aim to minimise their
homoeostatic/variational free energy – is not meant to be somehow a
consequence of thermodynamics or a principle about thermodynamic
free-energy. He justifies his free-energy principle not on thermodynamic
grounds, but on what he calls ‘selectionist’ grounds: all
cognitive/living creatures strive to minimise their homoeostatic free
energy because if they did not, they would tend to die off and hence be
less likely to reproduce or to be observed by us.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn24"
class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>
Friston suggests that the only connection between thermodynamic free
energy and his two notions of free energy is their shared mathematical
form.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn25" class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a></p>
<p>In outline, the logic of Friston’s free-energy defence of predictive
coding is as follows. Its starting point is the observation that all
cognitive (and living) creatures face the problem of surviving and
maintaining homeostasis. That task, according to Friston, can be
formally redescribed as the task of minimising a free-energy measure
(what I have called homoeostatic free energy). Friston claims that
minimising this free-energy measure entails that the creature also
minimises a second free-energy measure associated with the creature’s
subjective probabilistic guesses (variational free energy). Minimising
variational free energy, given certain further assumptions <span
class="citation" data-cites="Sprevak20e">(detailed in Sprevak
forthcoming sec. 2)</span>, entails that the creature also minimises its
sensory prediction error. Hence, cognitive and living creatures, because
they face the problem of survival and maintaining homeostasis, face the
problem of minimising sensory prediction error.</p>
<p>There is much to unpack here.</p>
<p>First, the argument relies on a presumed connection between
homoeostatic and variational free energy. However, the justification for
that connection is not obvious. Homoeostatic free energy pertains to how
well the creature maintains its physical state within the narrow band
associated with survival and homeostasis in the face of actual and
possible perturbations from a changing physical environment. Living
creatures change their microscopic physical state all the time. When
they do so, they risk undergoing a fatal phase transition in their
macroscopic physical state. When living systems resist this tendency –
when they survive and maintain homeostasis despite these perturbations –
they minimise their homoeostatic free energy. Minimising homoeostatic
free energy involves the creature trying to arrange its macroscopic
states so as to avoid being overly changed by likely environmental
physical transitions. A physical system that minimises its homoeostatic
free energy strives to maintain its macroscopic physical state in
balance with likely environmental changes <span class="citation"
data-cites="FristonKilner06 FristonStephan07 Friston13">(Friston et al.
2006; Friston 2013; Friston &amp; Stephan 2007)</span>. In contrast,
variational free energy is an information-theoretic quantity predicated
of an agent’s subjective probability distributions. It measures how far
the agent’s probabilistic guesses depart from the optimal guesses of a
perfect Bayesian observer armed with the same evidence.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn26"
class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>
According to Friston’s formulation, the brain’s task is to minimise this
variational free-energy quantity and so approximate an ideal Bayesian
reasoner in inference. Minimising variational free energy makes the
sensory data stream unsurprising (in the Shannon sense), and thereby
tends to minimise the agent’s sensory prediction error <span
class="citation" data-cites="Sprevak20e">(given certain assumptions
outlined in Sprevak forthcoming sec. 2)</span>.</p>
<p>Homoeostatic free energy and variational free energy have at least
two features in common: they are both information-theoretic quantities
and they both attach to probability distributions. However, they are not
the same quantity. Homoeostatic free energy is measured over the
<em>objective</em> probability distributions of macroscopic physical
states that could occur. Variational free energy is measured over the
<em>subjective</em> probability distributions entertained by an agent
about what could occur. Variational free energy attaches to the guesses
of the agent; homoeostatic free energy attaches to chances of various
possible (fatal) physical states of the agent occurring in response to
environmental changes. The respective probability distributions might
involve entirely different events, their distributions might take
entirely different shapes, and they each involve materially different
types of probability (subjective and objective). There might, for
various reasons, be a correlation between the two types of free energy,
but it is not obvious that minimising free energy for one probability
distribution entails minimising free energy for the other.<a
href="#fn27" class="footnote-ref" id="fnref27"
role="doc-noteref"><sup>27</sup></a></p>
<p>To see this point more clearly, consider the analytic relationship
already mentioned between variational free energy and Bayesian
inference. An agent who minimises its variational free energy
approximates an ideal Bayesian reasoner. A Bayesian agent is arguably
well placed to survive and maintain homeostasis. But the precise nature
of the connection between <em>being perfectly Bayesian in one’s
reasoning</em> and <em>maximising one’s chances of physical survival and
homeostasis</em> is far from obvious. A non-Bayesian agent might live in
a ‘irrationality friendly’ environment that supports its homeostasis and
physical integrity, even if the agent does not update its subjective
probability distributions which represent that environment according to
Bayesian norms. Conversely, an ideal Bayesian reasoner might live in a
‘rationality unfriendly’ physical environment that changes so rapidly
and dramatically that the agent fails to survive or maintain
homoeostasis even if it updates its subjective probability distributions
quickly and represents the environment accurately according to the
Bayesian norms. It is plausible that there is some connection between
following Bayesian norms in one’s reasoning and one’s ultimate chances
of survival, but it is not obvious that being Bayesian entails
maximising one’s chances of survival. Currently, the exact nature of the
relationship between Friston’s two types of free energy – homoeostatic
and variational – is unclear and the subject of ongoing analysis.<a
href="#fn28" class="footnote-ref" id="fnref28"
role="doc-noteref"><sup>28</sup></a></p>
<p>At least two other aspects of the free-energy defence of predictive
coding warrant further scrutiny.</p>
<p>First, ideally the predictive coding research programme aims to
defend a universal claim: <em>every</em> task that the brain faces can
and should be described as minimisation of sensory prediction error.
Survival/homoeostasis is one task faced by the brain – and obviously an
important one. If the internal logic of the free-energy defence is
correct, then because the brain faces this task it also faces the task
of minimising sensory prediction error. But it is not clear how this
argumentative strategy is meant to generalise: why someone might think
that survival/homoeostasis is the <em>only</em> problem faced by the
brain. Plausibly, a human brain faces other challenges that may be
unrelated, or even in anticorrelation with, maximising the agent’s
chances of survival or homoeostasis – e.g. problems of mate selection,
fulfilment of social roles, or arbitrary challenges set in the classroom
or other social environments. It is not clear how the free-energy
defence is meant to handle these cases. The free-energy defence appeals
to a claimed connection between survival/homoeostasis and minimising
sensory prediction error, but it is largely silent about how problems
that do not, or do not obviously, contribute to survival/homoeostasis
are meant to be related to sensory predictive error. Even if the
internal logic of the free-energy defence is sound, it is unclear how it
supports a general conclusion that every aspect of cognition is sensory
prediction error minimisation.</p>
<!-- Even if some -->
<!-- task facing the brain *can* be described as an instance of sensory -->
<!-- prediction error minimisation, it is a further question whether it -->
<!-- *should* be described this way. -->
<p>Second, recall that a defender of predictive coding needs to meet two
separate challenges at the computational level: (i) show that every
problem faced by the brain in cognition <em>can</em> be redescribed as
sensory prediction error minimisation; and (ii) show also that it
<em>should</em> be redescribed that way. The free-energy defence appears
only to speak to the first issue. It claims to establish a connection
between the task of survival/homoeostasis and the task of minimising
sensory prediction error. However, even if such a connection exists, it
would say nothing about the relative merits of one task description over
the other. In order to address that second issue, one would need to go
beyond the equivalences between task descriptions conjectured by the
free-energy defence and consider the <em>value</em> of predictive
coding’s proposed computational-level description with respect to the
broader epistemic and pragmatic standards, interests, and goals in
cognitive neuroscience. <em>Why</em> should we describe the task facing
the brain as sensory prediction error minimisation, even if, as the
free-energy defence suggests, we can? That part of the argument remains
to be made, and doing so is likely to depend, at least partly, on an
examination of concrete benefits offered by predictive coding’s proposed
computational-level description to specific cases of interest to
cognitive neuroscience. This suggests that the free-energy defence may
not be able to entirely shortcut the exigencies of the case-by-case
defence.</p>
<h1 data-number="9" id="the-instrumental-value-defence"><span
class="header-section-number">9</span> The instrumental-value
defence</h1>
<p>The instrumental-value defence has a different character from the
previous two. In contrast to both the case-based defence and the
free-energy defence, its focus is not primarily on the truth of
predictive coding’s claim, but on its <em>utility</em>. According to the
instrumental-value defence, predictive coding should be interpreted not
as a passive claim that awaits confirmation, but as a <em>way of
thinking</em> – an assumption that researchers might adopt in order to
help organise data, guide experimental design and interpretation, and
formulate further, more specific hypotheses for testing. Predictive
coding’s computational-level description provides a novel way to
systematise behavioural and neural responses, it brings particular
patterns to the fore that may be quantified, and it guides how one might
group responses under the heading of the exercise of psychologically
meaningful, computationally defined capacities. Furthermore, if one
understands what it proposes as part of a wider package that includes
ideas at Marr’s algorithmic and implementation levels, then it also
provides a set of heuristics to guide and inspire claims about the
computational processes and neural mechanisms that underlie those
computational capacities. The focus of the previous two sections was on
whether predictive coding gets the computational-level description of
the brain <em>right</em> or <em>wrong</em> (or whether it fares better
than alternative proposals). However, one might well ask the prior
question of <em>how to formulate</em> a set of hypotheses about this at
all. Scientific work can potentially benefit from what predictive coding
says here, even if uncertainty remains about the view’s ultimate
truth.</p>
<p>The totality of possible brain and environmental data associated with
cognition is utterly titanic and has little obvious or uncontroversial
structure. How should one go about approaching it to say which discrete
computational problems the brain faces? There is no purely mechanical
method or algorithm to do this. The raw behavioural and neural data do
not wear a computational interpretation on their sleeve. To even get
started on this problem, cognitive neuroscientists need something like a
<em>discovery heuristic</em>. A discovery heuristic provides a broad
theoretical orientation or clue about the overall purpose of the brain’s
activity and behaviour. That assumption may or may not ultimately prove
to be correct. But regardless of its epistemic standing, it may be
useful to accept <em>pro tem</em> as a working hypothesis in order to
develop a range of more specific and testable hypotheses. A discovery
heuristic provides a toehold from which to make sense of an otherwise
baffling array of data. Such toeholds may be useful even in advance of
one knowing whether where they lead will be entirely justified by
empirical evidence.</p>
<!-- Such assumptions may be useful even in advance of one knowing -->
<!-- whether what it says is entirely true.  -->
<!-- provides a set of hypotheses about the overall purpose of the -->
<!-- brain's activity and behaviour.  However, it is not obvious where a -->
<!-- researcher should look to for discovery heuristics. -->
<p>Folk psychological ideas about the brain often function as a possible
discovery heuristic in cognitive science. On such a view, one might
start by assuming that the brain is trying to combine something like
‘belief’-like and ‘desire’-like states in a process that roughly
resembles inference. Bringing this idea to bear on empirical data might
motivate a researcher to conjecture specific belief-like and desire-like
states inside the brain, hypothesise possible relationships between
them, the processes that transform them, and how sensory and behavioural
responses might update those beliefs and fulfil those desires. The idea
that the brain is a means–end reasoner may not ultimately prove to be
successful, but they do provide a source of more specific hypotheses
about the brain’s computational function.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn29"
class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a>
<span class="citation" data-cites="Machery18">Machery
(forthcoming)</span> argues that evolutionary psychology is another
source of discovery heuristics. that might lead a researcher towards
more specific hypotheses about the computational tasks the brain faces
and its underlying computational capacities, states, and mechanisms. He
argues that irrespective of evolutionary psychology’s truth value or
current confirmation, it provides a useful set of discovery heuristics.
One of those heuristics – the ‘forward-looking’ heuristic – suggests
that computational problems that our brains aim to solve should be
identified by looking at the information-processing problems encountered
by our ancient ancestors that bore on their fitness.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn30"
class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a>
One source of hypotheses about the computational capacities that our
brains have today is the set of problems that shaped its evolution <span
class="citation" data-cites="CosmidesTooby89">(Cosmides &amp; Tooby
1989)</span>.</p>
<p>Predictive coding might play a similar methodological role as a
discovery heuristic in cognitive neuroscience. It suggests that neural
and behavioural responses should be organised around the central idea
that the brain is aiming to minimise its long-term, precision-weighted
sensory prediction error. That idea can be precisified in many different
ways, but even in its most general form it may still function as a
useful assumption to guide design of experiments, measurement, and
generate more specific, testable proposals about physical responses.
Hypotheses that derive from folk psychology, evolutionary psychology, or
predictive coding of course need to be empirically confirmed. The key
point is that even in advance of securing such empirical support, it may
make sense to accept them in order to make the problem of formulating a
task description tractable at all. This also helps to explain an
otherwise puzzling phenomenon: the widespread adoption of predictive
coding in certain areas of the cognitive neuroscience literature despite
the view’s current relatively thin empirical support.</p>
<!-- Cognitive neuroscientists need to make assumptions regarding -->
<!-- the overall purpose of neural functioning in order to make -->
<!-- any sense of activity in the brain and behaviour.  Those -->
<!-- assumptions need to come from somewhere.  It is reasonable that -->
<!-- any candidate source for those ideas should be understood to -->
<!-- be uncertain and exploratory; predictive coding provides one -->
<!-- among many possible approaches (distinct from folk psychology -->
<!-- or evolutionary psychology).  Its sheer novelty -- predictive -->
<!-- coding's ability to depart from traditional categorisations of -->
<!-- behaviour and neural response -- is undoubtedly an attraction.  -->
<!-- It allows us to see familiar behavioural and neural responses -->
<!-- in a new light and group them together in different ways from -->
<!-- previous research programmes.  The central idea that generated -->
<!-- these hypotheses may ultimately prove to be mistaken, but that -->
<!-- possibility should not disbar it from being used to guide -->
<!-- current thinking or practice.  -->
<p>There are many examples of scientists embracing predictive coding’s
task description in a way that seems puzzling based purely on its
empirical support. For example, <span class="citation"
data-cites="FletcherFrith09">Fletcher &amp; Frith (2009)</span>,
inspired by predictive coding’s computational-level orientation,
hypothesise that a range of positive symptoms of schizophrenia –
including hallucinations, delusions, abnormal saliences in perception,
disturbances in low-level motor functioning – are all instances of a
single, unified dysfunction to minimise (precision-weighted) sensory
prediction error. They propose that this dysfunction is unwritten by a
single computational mechanism and physical basis, again prompted by
predictive coding’s claims at the algorithmic and implementation
levels.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a> Adopting predictive coding as a
working hypothesis suggests novel experimental designs that might
attempt to dissociate these factors, probe how they might be
quantitatively affected by manipulating sensory prediction errors, and
explore analogues of schizophrenia in healthy subjects by looking at
regimes that have similar effects on sensory prediction errors.<a
href="#fn32" class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a> <span class="citation"
data-cites="CorlettFletcher14">Corlett &amp; Fletcher (2014)</span>
argue that predictive coding could function as a discovery heuristic for
clinicians to find and trial new therapeutic interventions for patients
(including pharmacological treatments). The idea that the brain aims to
minimise sensory prediction error might function as the starting point
for any number of concrete theoretical, experimental, and therapeutic
developments.</p>
<p>Using predictive coding in this way – as a heuristic to facilitate
discovery in science rather than a claim that passively awaits
confirmation – does not somehow magically confer extra justification on
the view. Believing that something is true does not thereby make it
true, no matter how instrumentally useful it is. The gold standard for
justification of predictive coding is if it can predict and explain
empirical results better than alternative theoretical approaches.<a
href="#fn33" class="footnote-ref" id="fnref33"
role="doc-noteref"><sup>33</sup></a> The instrumental-value defence does
not somehow reduce the need to gather empirical evidence to confirm
predictive coding. However, it does explain why someone might be willing
to accept what predictive coding says even in advance of such evidence
being obtained.</p>
<!-- It explains why predictive coding might be adopted in cognitive -->
<!-- neuroscience as a working hypothesis despite its truth -->
<!-- remaining in question.  -->
<h1 data-number="10" id="conclusion"><span
class="header-section-number">10</span> Conclusion</h1>
<p>Predictive coding proposes that the computational problem that the
brain always faces in cognition is to minimise its long-term,
prediction-weighted sensory prediction error. This paper has reviewed
three strategies to defend this claim (Sections 7, 8, 9). These three
defences should not be viewed as mutually exclusive, but as potentially
complementary methods for justifying predictive coding.</p>
<p>In its boldest form, predictive coding proposes that its
computational-level description applies to all aspects of cognition. It
is natural to wonder what would happen if one were to trim the scope of
predictive coding’s claim here.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fn34" class="footnote-ref"
id="fnref34" role="doc-noteref"><sup>34</sup></a> Perhaps it describes
<em>some</em> of the problems that the brain faces, but not all. One
might imagine a variety of ways in which its computational-level claim
might be reigned in. At one extreme would be the largely uncontroversial
but by no means novel claim that <em>one</em> of the problems the brain
faces is to try to minimise sensory prediction error. At the other
extreme is the controversial and largely unsupported claim that trying
to minimising sensory prediction error is the brain’s <em>only</em>
problem in cognition. An advocate of predictive coding might wish to
adopt a qualified version of the view that falls at any number of points
between these two extremes. However, to the extent to which they move
towards the first extreme, both the novelty and unifying power of the
predictive coding framework is compromised. The predictive coding
research programme, if it is to fulfil its original promise, should aim
to offer as broad and comprehensive an account of cognition as
possible.</p>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-AguileraMillidgeTschantz22" class="csl-entry"
role="doc-biblioentry">
Aguilera, M., Millidge, B., Tschantz, A., &amp; Buckley, C. L. (2022).
<span>‘How particular is the physics of the free energy
principle?’</span>, <em>Physics of Life Reviews</em>, 40: 24–50.
</div>
<div id="ref-AitchisonLengyel17" class="csl-entry"
role="doc-biblioentry">
Aitchison, L., &amp; Lengyel, M. (2017). <span>‘With or without you:
Predictive coding and <span>B</span>ayesian inference in the
brain’</span>, <em>Current Opinion in Neurobiology</em>, 46: 219–27.
</div>
<div id="ref-AlinkSchwiedrzi10" class="csl-entry"
role="doc-biblioentry">
Alink, A., Schwiedrzik, C. M., Kohler, A., Singer, W., &amp; Muckli, L.
(2010). <span>‘Stimulus predictability reduces responses in primary
visual cortex’</span>, <em>Journal of Neuroscience</em>, 30: 2960–6.
</div>
<div id="ref-Allen17" class="csl-entry" role="doc-biblioentry">
Allen, C. (2017). <span>‘On (not) defining cognition’</span>,
<em>Synthese</em>, 194: 4233–49.
</div>
<div id="ref-Atick92" class="csl-entry" role="doc-biblioentry">
Atick, J. J. (1992). <span>‘Could information theory provide an
ecological theory of sensory processing?’</span>, <em>Network:
Computation in Neural Systems</em>, 3: 213–51.
</div>
<div id="ref-BayneBrainardByrne19" class="csl-entry"
role="doc-biblioentry">
Bayne, T., Brainard, D., Byrne, R. W., Chittka, L., Clayton, N., Heyes,
C., Mather, J., et al. (2019). <span>‘What is cognition?’</span>,
<em>Current Biology</em>, 29: R603–22.
</div>
<div id="ref-BiehlPollockKanai21" class="csl-entry"
role="doc-biblioentry">
Biehl, M., Pollock, F. A., &amp; Kanai, R. (2021). <span>‘A technical
critique of some parts of the free energy principle’</span>,
<em>Entropy</em>, 23: 293.
</div>
<div id="ref-Bogacz17" class="csl-entry" role="doc-biblioentry">
Bogacz, R. (2017). <span>‘A tutorial on the free-energy framework for
modelling perception and learning’</span>, <em>Journal of Mathematical
Psychology</em>, 76/198–211.
</div>
<div id="ref-BruinebergKiversteinRietveld18" class="csl-entry"
role="doc-biblioentry">
Bruineberg, J., Kiverstein, J., &amp; Rietveld, E. (2018). <span>‘The
anticipating brain is not a scientist: The free-energy principle from an
ecological-enactive perspective’</span>, <em>Synthese</em>, 195:
2417–44.
</div>
<div id="ref-CarandiniDemb05" class="csl-entry" role="doc-biblioentry">
Carandini, M., Demb, J. B., Mante, V., Tolhurst, D. J., Dan, Y.,
Olshausen, B. A., Gallant, J. L., et al. (2005). <span>‘Do we know what
the early visual system does?’</span>, <em>Journal of Neuroscience</em>,
25: 10577–97.
</div>
<div id="ref-CarandiniHeeger12" class="csl-entry"
role="doc-biblioentry">
Carandini, M., &amp; Heeger, D. J. (2012). <span>‘Normalization as a
canonical neural computation’</span>, <em>Nature Reviews
Neuroscience</em>, 13: 51–62.
</div>
<div id="ref-Clark13a" class="csl-entry" role="doc-biblioentry">
Clark, A. (2013a). <span>‘The many faces of precision (replies to
commentaries on <span>“<span>W</span>hatever next? <span>N</span>eural
prediction, situated agents, and the future of cognitive
science”</span>)’</span>, <em>Frontiers in Psychology</em>, 4: 270.
</div>
<div id="ref-Clark13" class="csl-entry" role="doc-biblioentry">
——. (2013b). <span>‘Whatever next? Predictive brains, situated agents,
and the future of cognitive science’</span>, <em>Behavioral and Brain
Sciences</em>, 36: 181–253.
</div>
<div id="ref-Clark15" class="csl-entry" role="doc-biblioentry">
——. (2016). <em>Surfing uncertainty: Prediction, action, and the
embodied mind</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Clark17" class="csl-entry" role="doc-biblioentry">
——. (2017). <span>‘How to knit your own <span>M</span>arkov
blanket’</span>. Metzinger T. &amp; Wiese W. (eds) <em>Philosophy and
predictive processing</em>. MIND Group: Frankfurt am Main. DOI: <a
href="https://doi.org/10.15502/9783958573031">10.15502/9783958573031</a>
</div>
<div id="ref-ColomboWright18" class="csl-entry" role="doc-biblioentry">
Colombo, M., &amp; Wright, C. (2021). <span>‘First principles in the
life sciences: The free-energy principle, organicism, and
mechanism’</span>, <em>Synthese</em>, 198: S3463–88.
</div>
<div id="ref-CorlettFletcher14" class="csl-entry"
role="doc-biblioentry">
Corlett, P. R., &amp; Fletcher, P. C. (2014). <span>‘Computational
psychiatry: A <span>R</span>osetta <span>S</span>tone linking the brain
to mental illness’</span>, <em>The Lancet Psychiatry</em>, 1: 399–402.
</div>
<div id="ref-CorlettFrith09" class="csl-entry" role="doc-biblioentry">
Corlett, P. R., Frith, C. D., &amp; Fletcher, P. C. (2009). <span>‘From
drugs to deprivation: A <span>B</span>ayesian framework for
understanding models of psychosis’</span>, <em>Psychopharmacology</em>,
206: 515–30.
</div>
<div id="ref-CosmidesTooby89" class="csl-entry" role="doc-biblioentry">
Cosmides, L., &amp; Tooby, J. (1989). <span>‘Evolutionary psychology and
the generation of culture, part <span>II</span>: <span>C</span>ase
study: <span>A</span> computational theory of social exchange’</span>,
<em>Ethology and Sociobiology</em>, 10: 51–97.
</div>
<div id="ref-FeldmanFriston10" class="csl-entry" role="doc-biblioentry">
Feldman, H., &amp; Friston, K. (2010). <span>‘Attention, uncertainty,
and free-energy’</span>, <em>Frontiers in Human Neuroscience</em>, 4:
1–23.
</div>
<div id="ref-FletcherFrith09" class="csl-entry" role="doc-biblioentry">
Fletcher, P. C., &amp; Frith, C. D. (2009). <span>‘Perceiving is
believing: A <span>B</span>ayesian approach to explaining the positive
symptoms of schizophrenia’</span>, <em>Nature Reviews Neuroscience</em>,
10: 48–58.
</div>
<div id="ref-Friston03" class="csl-entry" role="doc-biblioentry">
Friston, K. (2003). <span>‘Learning and inference in the brain’</span>,
<em>Neural Networks</em>, 16: 1325–52.
</div>
<div id="ref-Friston05" class="csl-entry" role="doc-biblioentry">
——. (2005). <span>‘A theory of cortical responses’</span>,
<em>Philosophical Transactions of the Royal Society of London, Series
B</em>, 360: 815–36.
</div>
<div id="ref-Friston09" class="csl-entry" role="doc-biblioentry">
——. (2009). <span>‘The free-energy principle: A rough guide to the
brain?’</span>, <em>Trends in Cognitive Sciences</em>, 13: 293–301.
</div>
<div id="ref-Friston10" class="csl-entry" role="doc-biblioentry">
——. (2010). <span>‘The free-energy principle: A unified brain
theory?’</span>, <em>Nature Reviews Neuroscience</em>, 11: 127–38.
</div>
<div id="ref-Friston11" class="csl-entry" role="doc-biblioentry">
——. (2011). <span>‘What is optimal about motor control?’</span>,
<em>Neuron</em>, 72: 488–98.
</div>
<div id="ref-Friston13" class="csl-entry" role="doc-biblioentry">
——. (2013). <span>‘Life as we know it’</span>, <em>Journal of the Royal
Society Interface</em>, 10: 20130475.
</div>
<div id="ref-Friston19" class="csl-entry" role="doc-biblioentry">
——. (2019). <em>A free energy principle for a particular physics</em>.
DOI: <a
href="https://doi.org/10.48550/arXiv.1906.10184">10.48550/arXiv.1906.10184</a>
</div>
<div id="ref-FristonDaunizeau10" class="csl-entry"
role="doc-biblioentry">
Friston, K., Daunizeau, J., Kilner, J., &amp; Kiebel, S. J. (2010).
<span>‘Action and behavior: A free-energy formulation’</span>,
<em>Biological Cybernetics</em>, 102: 227–60.
</div>
<div id="ref-FristonKilner06" class="csl-entry" role="doc-biblioentry">
Friston, K., Kilner, J., &amp; Harrison, L. (2006). <span>‘A free energy
principle for the brain’</span>, <em>Journal of Physiology (Paris)</em>,
100: 70–87.
</div>
<div id="ref-FristonMattoutKilner11" class="csl-entry"
role="doc-biblioentry">
Friston, K., Mattout, J., &amp; Kilner, J. (2011). <span>‘Action
understanding and active inference’</span>, <em>Biological
Cybernetics</em>, 104: 137–60.
</div>
<div id="ref-FristonStephan07" class="csl-entry" role="doc-biblioentry">
Friston, K., &amp; Stephan, K. E. (2007). <span>‘Free-energy and the
brain’</span>, <em>Synthese</em>, 159: 417–58.
</div>
<div id="ref-FristonStephanMontague14" class="csl-entry"
role="doc-biblioentry">
Friston, K., Stephan, K. E., Montague, P. R., &amp; Dolan, R. J. (2014).
<span>‘Computational psychiatry: The brain as a phantastic
organ’</span>, <em>The Lancet Psychiatry</em>, 1: 148–58.
</div>
<div id="ref-FristonThornton12" class="csl-entry"
role="doc-biblioentry">
Friston, K., Thornton, C., &amp; Clark, A. (2012). <span>‘Free-energy
minimization and the dark-room problem’</span>, <em>Frontiers in
Psychology</em>, 3: 1–7.
</div>
<div id="ref-Hohwy13" class="csl-entry" role="doc-biblioentry">
Hohwy, J. (2013). <em>The predictive mind</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-HohwyMichael17" class="csl-entry" role="doc-biblioentry">
Hohwy, J., &amp; Michael, J. (2017). <span>‘Why should any body have a
self?’</span> Vignemont F. de &amp; Alsmith A. (eds) <em>The body and
the self, revisited</em>, pp. 363–92. MIT Press: Cambridge, MA.
</div>
<div id="ref-HohwyRoepstorff08" class="csl-entry"
role="doc-biblioentry">
Hohwy, J., Roepstorff, A., &amp; Friston, K. (2008). <span>‘Predictive
coding explains binocular rivalry: An epistemological review’</span>,
<em>Cognition</em>, 108: 687–701.
</div>
<div id="ref-HosoyaBaccus05" class="csl-entry" role="doc-biblioentry">
Hosoya, T., Baccus, S. A., &amp; Meister, M. (2005). <span>‘Dynamic
predictive coding by the retina’</span>, <em>Nature</em>, 436: 71–7.
</div>
<div id="ref-Huang08" class="csl-entry" role="doc-biblioentry">
Huang, G. T. (2008). <span>‘Is this a unified theory of the
brain?’</span>, <em>New Scientist</em>, 2658: 30–3.
</div>
<div id="ref-JeheeBallard09" class="csl-entry" role="doc-biblioentry">
Jehee, J. F. M., &amp; Ballard, D. H. (2009). <span>‘Predictive feedback
can account for biphasic responses in the lateral geniculate
nucleus’</span>, <em><span>PLoS</span> Computational Biology</em>, 5:
e1000373.
</div>
<div id="ref-KirchhoffKiverstein19" class="csl-entry"
role="doc-biblioentry">
Kirchhoff, M. D., &amp; Kiverstein, J. (2021). <span>‘How to determine
the boundaries of the mind: A <span>M</span>arkov blanket
proposal’</span>, <em>Synthese</em>, 198: 4791–810.
</div>
<div id="ref-KoelschVuustFriston19" class="csl-entry"
role="doc-biblioentry">
Koelsch, S., Vuust, P., &amp; Friston, K. (2019). <span>‘Predictive
processes and the peculiar case of music’</span>, <em>Trends in
Cognitive Sciences</em>, 23: 63–77.
</div>
<div id="ref-KokJeheeLange12" class="csl-entry" role="doc-biblioentry">
Kok, P., Jehee, J. F. M., &amp; Lange, F. P. de. (2012). <span>‘Less is
more: Expectation sharpens representations in the primary visual
cortex’</span>, <em>Neuron</em>, 75: 265–70.
</div>
<div id="ref-KokLange15" class="csl-entry" role="doc-biblioentry">
Kok, P., &amp; Lange, F. P. de. (2015). <span>‘Predictive coding in the
sensory cortex’</span>. Forstmann B. U. &amp; Wagenmakers E.-. J. (eds)
<em>An introduction to model-based cognitive neuroscience</em>, pp.
221–44. Springer: New York, NY.
</div>
<div id="ref-Kording07" class="csl-entry" role="doc-biblioentry">
Kording, K. (2007). <span>‘Decision theory: What <span>“should”</span>
the nervous system do?’</span>, <em>Science</em>, 318: 606–10.
</div>
<div id="ref-Lupyan15" class="csl-entry" role="doc-biblioentry">
Lupyan, G. (2015). <span>‘Cognitive penetrability of perception in the
age of prediction: Predictive systems are penetrable systems’</span>,
<em>Review of Philosophy and Psychology</em>, 6: 547–69.
</div>
<div id="ref-Machery18" class="csl-entry" role="doc-biblioentry">
Machery, E. (forthcoming). <span>‘Discovery and confirmation in
evolutionary psychology’</span>. Prinz J. (ed.) <em>The oxford handbook
of philosophy of psychology</em>. Oxford University Press.
</div>
<div id="ref-Marr82" class="csl-entry" role="doc-biblioentry">
Marr, D. (1982). <em>Vision</em>. San Francisco, CA: W. H. Freeman.
</div>
<div id="ref-MillerClark18" class="csl-entry" role="doc-biblioentry">
Miller, M., &amp; Clark, A. (2018). <span>‘Happily entangled:
Prediction, emotion, and the embodied mind’</span>, <em>Synthese</em>,
195: 2559–75.
</div>
<div id="ref-Muckli10" class="csl-entry" role="doc-biblioentry">
Muckli, L. (2010). <span>‘What are we missing here? Brain imaging
evidence for higher cognitive functions in primary visual cortex
<span>V</span>1’</span>, <em>International Journal of Imaging Systems
and Technology</em>, 20: 131–9.
</div>
<div id="ref-Mumford92" class="csl-entry" role="doc-biblioentry">
Mumford, D. (1992). <span>‘On the computational architecture of the
neocortex. <span>II</span> the role of cortico-cortico loops’</span>,
<em>Biological Cybernetics</em>, 66: 241–51.
</div>
<div id="ref-MurrayKersten02" class="csl-entry" role="doc-biblioentry">
Murray, S. O., Kersten, D., Olshausen, B. A., Schrater, P., &amp; Woods,
D. L. (2002). <span>‘Shape perception reduces activity in human primary
visual cortex’</span>, <em>Proceedings of the National Academy of
Sciences</em>, 99: 15164–9.
</div>
<div id="ref-OlshausenField05" class="csl-entry" role="doc-biblioentry">
Olshausen, B. A., &amp; Field, D. J. (2005). <span>‘How close are we to
understanding <span>V</span>1’</span>, <em>Neural Computation</em>, 17:
1665–99.
</div>
<div id="ref-PellicanoBurr12" class="csl-entry" role="doc-biblioentry">
Pellicano, E., &amp; Burr, D. (2012). <span>‘When the world becomes
<span>“too real”</span>: A <span>B</span>ayesian explanation of autistic
perception’</span>, <em>Trends in Cognitive Sciences</em>, 16: 504–10.
</div>
<div id="ref-PickeringClark14" class="csl-entry" role="doc-biblioentry">
Pickering, M. J., &amp; Clark, A. (2014). <span>‘Getting ahead:
<span>F</span>orward models and their place in cognitive
architecture’</span>, <em>Trends in Cognitive Sciences</em>, 18: 451–6.
</div>
<div id="ref-RamsteadKirchhoffConstant21" class="csl-entry"
role="doc-biblioentry">
Ramstead, M. J. D., Kirchhoff, M. D., Constant, A., &amp; Friston, K.
(2021). <span>‘Multiscale integration: Beyond internalism and
externalism’</span>, <em>Synthese</em>, 198: S41–70.
</div>
<div id="ref-RaoBallard99" class="csl-entry" role="doc-biblioentry">
Rao, R. P. N., &amp; Ballard, D. H. (1999). <span>‘Predictive coding in
the visual cortex: A functional interpretation of some extra-classical
receptive-field effects’</span>, <em>Nature Neuroscience</em>, 2: 79–87.
</div>
<div id="ref-RaoSejnowski02" class="csl-entry" role="doc-biblioentry">
Rao, R. P. N., &amp; Sejnowski, T. J. (2002). <span>‘Predictive coding,
cortical feedback, and spike-timing dependent plasticity’</span>. Rao R.
P. N., Olshausen B. A., &amp; Lewicki M. S. (eds) <em>Probablistic
models of the brain: Perception and neural function</em>, pp. 297–315.
MIT Press: Cambridge, MA.
</div>
<div id="ref-SchwartenbeckFitzGerald13" class="csl-entry"
role="doc-biblioentry">
Schwartenbeck, P., FitzGerald, T., Dolan, R. J., &amp; Friston, K.
(2013). <span>‘Exploration, novelty, surprise, and free energy
minimization’</span>, <em>Frontiers in Psychology</em>, 4: 1–5.
</div>
<div id="ref-SchwarzSimoncelli01" class="csl-entry"
role="doc-biblioentry">
Schwarz, O., &amp; Simoncelli, E. P. (2001). <span>‘Natural signal
statistics and sensory gain control’</span>, <em>Nature
Neuroscience</em>, 4: 819–25.
</div>
<div id="ref-Seth13" class="csl-entry" role="doc-biblioentry">
Seth, A. K. (2013). <span>‘Interoceptive inference, emotion, and the
embodied self’</span>, <em>Trends in Cognitive Sciences</em>, 17:
565–73.
</div>
<div id="ref-ShadmehrKrakauer08" class="csl-entry"
role="doc-biblioentry">
Shadmehr, R., &amp; Krakauer, J. W. (2008). <span>‘A computational
neuroanatomy for motor control’</span>, <em>Experimental Brain
Research</em>, 185: 359–81.
</div>
<div id="ref-Shagrir10a" class="csl-entry" role="doc-biblioentry">
Shagrir, O. (2010). <span>‘Marr on computational-level theories’</span>,
<em>Philosophy of Science</em>, 77: 477–500.
</div>
<div id="ref-ShagrirBechtel13" class="csl-entry" role="doc-biblioentry">
Shagrir, O., &amp; Bechtel, W. (2013). <span>‘Marr’s computational level
and delineating phenomena’</span>. Kaplan D. (ed.) <em>Integrating
psychology and neuroscience: Prospects and problems</em>. Oxford
University Press: Oxford.
</div>
<div id="ref-Spratling10" class="csl-entry" role="doc-biblioentry">
Spratling, M. W. (2010). <span>‘Predictive coding as a model of response
properties in cortical area <span>V</span>1’</span>, <em>Journal of
Neuroscience</em>, 30: 3531–43.
</div>
<div id="ref-Spratling17" class="csl-entry" role="doc-biblioentry">
——. (2017). <span>‘A review of predictive coding algorithms’</span>,
<em>Brain and Cognition</em>, 112: 92–7.
</div>
<div id="ref-Sprevak18b" class="csl-entry" role="doc-biblioentry">
Sprevak, M. (2020). <span>‘Two kinds of information processing in
cognition’</span>, <em>Review of Philosophy and Psychology</em>, 11:
591–611.
</div>
<div id="ref-Sprevak20e" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding: appendix’</span>,
<em>TBC</em>.
</div>
<div id="ref-Sprevak20d" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>IV</span>: The
implementation level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20c" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>III</span>: The
algorithmic level’</span>, <em>TBC</em>.
</div>
<div id="ref-Sprevak20a" class="csl-entry" role="doc-biblioentry">
——. (forthcoming). <span>‘Predictive coding <span>I</span>:
introduction’</span>, <em>TBC</em>.
</div>
<div id="ref-SrinivasanLaughlinDubs82" class="csl-entry"
role="doc-biblioentry">
Srinivasan, M. V., Laughlin, S. B., &amp; Dubs, A. (1982).
<span>‘Predictive coding: A fresh view of inhibition in the
retina’</span>, <em>Proceedings of the Royal Society, Series B</em>,
216: 427–59.
</div>
<div id="ref-Wiese17" class="csl-entry" role="doc-biblioentry">
Wiese, W. (2017). <span>‘Action is enabled by systematic
misrepresentation’</span>, <em>Erkenntnis</em>, 82: 1233–52.
</div>
</div>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Marr’s use of the term
‘computational’ here is not meant to imply that his other levels of
description are not computational. His use seems to derive from that in
mathematical logic, where a ‘computational theory’ tends to analyse
relationships between problems that are blind to differences in
algorithms or physical implementation – relationships staked out by the
concept of ‘computational equivalence’.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation"
data-cites="Marr82">Marr (1982)</span>, pp. 68–74. The full story about
the informal task is complex, and ‘edges’ should be understood to
include not only the boundaries of objects, but also regions of the
visual field where there are changes in reflectance, illumination,
depth, or surface orientation.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Marr thought that this task was
solved by the retinal ganglion cells: ‘Take the retina. I have argued
that from a computational point of view, it signals <span
class="math inline">\(\nabla ^2 G \ast I\)</span> (the X channels) and
its time derivative <span class="math inline">\(\partial/\partial t
(\nabla ^2 G \ast I)\)</span> (the Y channels). From a computational
point of view, this is a precise specification of what the retina does.’
<span class="citation" data-cites="Marr82">(Marr 1982 p. 337)</span>.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>See <span class="citation"
data-cites="Marr82">Marr (1982)</span>, p. 22.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>See <span class="citation"
data-cites="ShagrirBechtel13">Shagrir &amp; Bechtel (2013)</span>; <span
class="citation" data-cites="Shagrir10a">Shagrir (2010)</span> for a
helpful explanation of the ‘what’ and ‘why’ at Marr’s computational
level.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>A range of other formalisations can
be found in <span class="citation" data-cites="Bogacz17">Bogacz
(2017)</span>; <span class="citation" data-cites="Friston03">Friston
(2003)</span>; 1330–1339; <span class="citation"
data-cites="Friston05">Friston (2005)</span>, pp. 819–821; <span
class="citation" data-cites="Friston09">Friston (2009)</span>, p. 296;
<span class="citation" data-cites="Spratling17">Spratling (2017)</span>,
pp. 92–93.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 2.4.<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 5.<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20c">Sprevak (forthcoming)</span>, Section 6.1.<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20d">Sprevak (forthcoming)</span>, Section 5.<a
href="#fnref10" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13a">Clark (2013a)</span> for examples of how precision
weighting can explain a range of otherwise puzzling cases (e.g.
habit-based action and behaviour during model-free learning). See <span
class="citation" data-cites="MillerClark18">Miller &amp; Clark
(2018)</span>, p. 2568 for their response to the objection that
precision weighting is a ‘magic modulator’ that allows predictive coding
to accommodate every possible goal.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>For further discussion of this
problem, see <span class="citation" data-cites="Sprevak20d">Sprevak
(forthcoming)</span>, Section 8.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13">Clark (2013b)</span>, p. 193 for a statement of the
problem.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>See also <span class="citation"
data-cites="Hohwy13">Hohwy (2013)</span>, pp. 87, 185; <span
class="citation" data-cites="Clark15">Clark (2016)</span>,
pp. 265–268;<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>Some of these constraints are
articulated as part of proposals made by predictive coding at the
algorithmic level and implementation level <span class="citation"
data-cites="Sprevak20c Sprevak20d">(Sprevak forthcoming sec. 2.5;
forthcoming sec. 7)</span>. However, in either case what is offered is
by no means a complete or a universally agreed account of the
constraints under which the brain operates during inference or
learning.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref15" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark15">Clark (2016)</span>, pp. 265–266<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>See <span class="citation"
data-cites="Friston10">Friston (2010)</span>, pp. 133–134; <span
class="citation" data-cites="FristonDaunizeau10">Friston et al.
(2010)</span>; <span class="citation" data-cites="Clark15">Clark
(2016)</span>, Section 4.5; <span class="citation"
data-cites="Hohwy13">Hohwy (2013)</span>, Ch. 4.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>As well proposing a unified account
of the problem facing the brain in perception and motor control,
predictive coding also suggests that the algorithms that govern
perceptual and motoric processing have a great deal in common <span
class="citation" data-cites="Sprevak20c">(see Sprevak forthcoming sec.
6.1)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>For the claimed benefits of
predictive coding’s task description of motor control see <span
class="citation" data-cites="Friston11">Friston (2011)</span>, <span
class="citation" data-cites="FristonDaunizeau10">Friston et al.
(2010)</span>; <span class="citation" data-cites="Wiese17">Wiese
(2017)</span>, <span class="citation"
data-cites="PickeringClark14">Pickering &amp; Clark (2014)</span>. For
claimed benefits of alternative approaches to motor control, see <span
class="citation" data-cites="Kording07">Kording (2007)</span>; <span
class="citation" data-cites="ShadmehrKrakauer08">Shadmehr &amp; Krakauer
(2008)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref19" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>For other examples of non-classical
effects in the early visual system that appear to be predicted and
modelled by predictive coding, see <span class="citation"
data-cites="JeheeBallard09">Jehee &amp; Ballard (2009)</span>; <span
class="citation" data-cites="KokJeheeLange12">Kok et al. (2012)</span>;
<span class="citation" data-cites="HosoyaBaccus05">Hosoya et al.
(2005)</span>; <span class="citation" data-cites="RaoSejnowski02">Rao
&amp; Sejnowski (2002)</span>; <span class="citation"
data-cites="Muckli10">Muckli (2010)</span>; <span class="citation"
data-cites="KokLange15">Kok &amp; Lange (2015)</span>; <span
class="citation" data-cites="Spratling10">Spratling (2010)</span>; <span
class="citation" data-cites="AlinkSchwiedrzi10">Alink et al.
(2010)</span>; <span class="citation"
data-cites="MurrayKersten02">Murray et al. (2002)</span>. For
alternative computational-level accounts of these non-classical
phenomena (e.g. in terms of divisive normalisation), see <span
class="citation" data-cites="AitchisonLengyel17">Aitchison &amp; Lengyel
(2017)</span>, p. 224; <span class="citation"
data-cites="CarandiniHeeger12">Carandini &amp; Heeger (2012)</span>;
<span class="citation" data-cites="SchwarzSimoncelli01">Schwarz &amp;
Simoncelli (2001)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>For example, see <span
class="citation" data-cites="Allen17">Allen (2017)</span>; <span
class="citation" data-cites="BayneBrainardByrne19">Bayne et al.
(2019)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref21" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>For predictive coding as a potential
‘mark of cognitive’, see <span class="citation"
data-cites="Clark17">Clark (2017)</span>; <span class="citation"
data-cites="KirchhoffKiverstein19">Kirchhoff &amp; Kiverstein
(2021)</span>; <span class="citation"
data-cites="RamsteadKirchhoffConstant21">Ramstead et al.
(2021)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref22" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>Friston does not use these terms. He
refers to both as ‘variational’ free energy.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref23"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p><span class="citation"
data-cites="FristonStephan07">Friston &amp; Stephan (2007)</span>,
pp. 419–420, 451; <span class="citation"
data-cites="FristonKilner06">Friston et al. (2006)</span>, p. 85<a
href="#fnref24" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p>See <span class="citation"
data-cites="FristonStephan07">Friston &amp; Stephan (2007)</span>,
p. 419.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref25" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>See <span class="citation"
data-cites="Sprevak20e">Sprevak (forthcoming)</span>, Section 1 for the
connection between variational free energy and Bayesian inference.<a
href="#fnref26" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p><span class="citation"
data-cites="Sprevak18b">Sprevak (2020)</span>, pp. 602–604.<a
href="#fnref27" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn28" role="doc-endnote"><p>See <span class="citation"
data-cites="AguileraMillidgeTschantz22">Aguilera et al. (2022)</span>;
<span class="citation" data-cites="BiehlPollockKanai21">Biehl et al.
(2021)</span>; <span class="citation"
data-cites="BruinebergKiversteinRietveld18">Bruineberg et al.
(2018)</span>; <span class="citation"
data-cites="ColomboWright18">Colombo &amp; Wright (2021)</span>; <span
class="citation" data-cites="Friston19">Friston (2019)</span>; <span
class="citation" data-cites="Sprevak18b">Sprevak (2020)</span>.<a
href="#fnref28" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn29" role="doc-endnote"><p>See <span class="citation"
data-cites="Machery18">Machery (forthcoming)</span>, Section 1.1.<a
href="#fnref29" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn30" role="doc-endnote"><p>ibid.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref30"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31" role="doc-endnote"><p>ibid., pp. 53–55; <span
class="citation" data-cites="CorlettFrith09">Corlett et al.
(2009)</span>.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref31" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn32" role="doc-endnote"><p>For example, see <span
class="citation" data-cites="FletcherFrith09">Fletcher &amp; Frith
(2009)</span>, p. 55–56.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33" role="doc-endnote"><p>See <span class="citation"
data-cites="Machery18">Machery (forthcoming)</span>, Section 3.2 for a
similar point regarding evolutionary psychology.<a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#fnref33"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34" role="doc-endnote"><p>See <span class="citation"
data-cites="Clark13">Clark (2013b)</span>, pp. 200–201.<a
href="#fnref34" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div>

                            </div>
                            
                        </div>

                    </div>

                    <div class="is-col is-33">     
                        <div class="is-hidden-print is-hidden-mobile">
                            
                                <h1 style="margin-top: 0px;">Contents</h1>
                                <ul class="is-unstyled">
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#introduction"><span style="visibility: visible;">1</span> &nbsp;  Introduction</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#minimising-sensory-prediction-error"><span style="visibility: visible;">2</span> &nbsp;  Minimising sensory prediction error</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#formal-and-informal-descriptions"><span style="visibility: visible;">3</span> &nbsp;  Formal and informal descriptions</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#precision-weighting-of-prediction-errors"><span style="visibility: visible;">4</span> &nbsp;  Precision weighting of prediction errors</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#long-term-prediction-error-and-the-dark-room-objection"><span style="visibility: visible;">5</span> &nbsp;  Long-term prediction error and the dark-room objection</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#evidence-for-predictive-coding"><span style="visibility: visible;">6</span> &nbsp;  Evidence for predictive coding</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-case-based-defence"><span style="visibility: visible;">7</span> &nbsp;  The case-based defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-free-energy-defence"><span style="visibility: visible;">8</span> &nbsp;  The free-energy defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#the-instrumental-value-defence"><span style="visibility: visible;">9</span> &nbsp;  The instrumental-value defence</a>
            
        </span>
        
    </li>
    
    <li>
        
        <span style="font-size: 14px;">
            
            <a href="https://marksprevak.com/publications/predictive-coding-ii-the-computational-level-b9f5/#conclusion"><span style="visibility: visible;">10</span> &nbsp;  Conclusion</a>
            
        </span>
        
    </li>
    
</ul>

                            
                            
                        </div>
                    </div>
                </div>
            </main>

        <footer class="footer"></footer>

        </div>

        <script src="https://marksprevak.com/kube/js/kube.min.js"></script>
<script>
    $K.init();
</script>


    </body>
</html>
