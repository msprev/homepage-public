<!DOCTYPE html>
<html lang="en">
    <head>
                <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1 minimal-ui">

        <meta name="description" content="">
        <meta name="keywords" content="">

        

        
        <meta name="twitter:card" content="summary">
        
        <meta name="twitter:site" content="@msprevak">
        <meta name="twitter:title" content="Review of *The Language of Thought: A New Philosophical Direction* by Susan Schneider : marksprevak.com">
        <meta name="twitter:creator" content="@msprevak">
        <meta name="twitter:description" content="">
        <meta name="twitter:image:src" content="">
        <meta name="twitter:domain" content="marksprevak.com">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">




<link rel="stylesheet" href="http://marksprevak.com/css/stylesheet.min.css" />
<link rel="stylesheet" href="http://marksprevak.com/font-awesome/css/font-awesome.min.css">

<script type="text/javascript" src="http://marksprevak.com/scripts/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="http://marksprevak.com/kube/js/kube.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <style type="text/css">
          .hidden {display:none;}
        </style>
        <script type="text/javascript">
          $('html').addClass('hidden');
          $(document).ready(function() {
            $('html').removeClass('hidden');
           });
         </script>


<title>Mark Sprevak</title>
<base href="http://marksprevak.com/">
<link rel="canonical" href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,700%7CLato:400,700" rel="stylesheet">

        
    </head>
    <body>

        <div class="wrapper">

            <div class="row" style="padding-bottom: 8px; padding-top: 0px; margin-bottom: 12px; border-bottom: 1px solid; border-color: rgba(0, 0, 0, 0.3);">
    <div class="show-sm col col-12">
            <div class="titlebar"><a href="http://marksprevak.com/">Mark&nbsp;Sprevak</a>
                <a href="#" data-component="toggleme" data-target="#navbar" style="float: right; color: rgba(0, 0, 0, 0.8);"><i class="kube-menu"></i></a>
            </div>
    </div>

    <div class="hide-sm col col-12">
            <div class="row">
                <div class="col col-3">
                    <div class="titlebar"><a href="http://marksprevak.com/">Mark&nbsp;Sprevak</a></div>
                </div>

                <div class="col col-9">
                    <ul class="unstyled">
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/teaching/" style="text-decoration: none; border-bottom: none;">Teaching</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/mscs/" style="text-decoration: none; border-bottom: none;">MSc research</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/phds/" style="text-decoration: none; border-bottom: none;">PhD research</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/cv/" style="text-decoration: none; border-bottom: none;">CV</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/outreach/" style="text-decoration: none; border-bottom: none;">Outreach</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/talks/" style="text-decoration: none; border-bottom: none;">Talks</a>
                        </li>
                        
                        
                        
                        <li style="float: right; margin-left: 20px;"  >
                            <a href="http://marksprevak.com/publications/" style="text-decoration: none; border-bottom: none;">Publications</a>
                        </li>
                        
                        
                        
                        
                    </ul>
                </div>
            </div>
    </div>

    <nav id="navbar" class="hide show-sm">
        <ul style="float: right; text-align:right; padding-right:5px;">
            
            
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/publications/" style="text-decoration: none; border-bottom: none;">Publications</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/talks/" style="text-decoration: none; border-bottom: none;">Talks</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/outreach/" style="text-decoration: none; border-bottom: none;">Outreach</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/cv/" style="text-decoration: none; border-bottom: none;">CV</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/phds/" style="text-decoration: none; border-bottom: none;">PhD research</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/mscs/" style="text-decoration: none; border-bottom: none;">MSc research</a>
            </li>
            
            
            
            <li style=""  >
                <a href="http://marksprevak.com/teaching/" style="text-decoration: none; border-bottom: none;">Teaching</a>
            </li>
            
            
        </ul>
    </nav>
</div>


            <div class="row gutters">
                <div class="col col-8">

                    <div style="padding-bottom: 30px;">
                        <div style="margin-bottom: 10px;">
                            <h1 style="margin-top: 0px; margin-bottom: 0px; color: black;">Review of <em>The Language of Thought: A New Philosophical Direction</em> by Susan Schneider</h1>
                            
                            
                            <p class="muted" style="margin-top: 10px;">forthcoming <em>Mind</em></p>
                            
                            <p class="small" style="margin-top: 10px;">Last updated 28 May 2018</p>
                        </div>
                        <div class="hide-print">
                            
                            <a href="http://marksprevak.com/pdf/paper/Sprevak---SchneiderReview.pdf" target="_blank" class="label badge outline focus upper"><span class="fa fa-file-pdf-o"></span>&nbsp;PDF</a>
                            &nbsp;&nbsp;
                            
                            
                            
                        </div>
                    </div>

                    

                    <div>
                        
                        <div class="show-sm">
                            
                            
                            <h1 style="margin-top: 0px;" id="internal-mds-toc">Contents</h1>
                            <ul class="unstyled">
                                
                                <li>
                                    
                                    <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#introduction"><span style="font-size: 14px;">1 &nbsp; Introduction</span></a>
                                    
                                </li>
                                
                                <li>
                                    
                                    <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#central-reasoning-is-not-computational"><span style="font-size: 14px;">2 &nbsp; Central reasoning is not computational</span></a>
                                    
                                </li>
                                
                                <li>
                                    
                                    <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#what-is-a-lot-symbol"><span style="font-size: 14px;">3 &nbsp; What is a LOT symbol?</span></a>
                                    
                                </li>
                                
                                <li>
                                    
                                    <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#concepts-and-frege-cases"><span style="font-size: 14px;">4 &nbsp; Concepts and Frege cases</span></a>
                                    
                                </li>
                                
                                <li>
                                    
                                    <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#conclusion"><span style="font-size: 14px;">5 &nbsp; Conclusion</span></a>
                                    
                                </li>
                                
                            </ul>
                            
                        </div>
                        <div class="article-style">
                            <div>
<h1 id="introduction"><span class="header-section-number">1</span> Introduction</h1>
<p>The Language of Thought (LOT) is closely associated with the work of Jerry Fodor. Fodor defended the idea in his book, <em>The Language of Thought</em> <span class="citation" data-cites="Fodor75">(1975)</span>, and he continued to do so, with relatively minor revisions, throughout his career. Susan Schneider’s book does not aim to be an exegesis or defence of Fodor. Instead, it offers an alternative to Fodor’s version of LOT that she says is an improvement and a worthy replacement. Her aim is to overcome three challenges that faced his approach.</p>
<p>According to both Fodor and Schneider, LOT’s goal is to explain human thought in naturalistic, mechanical terms. Schneider defines LOT as a package of three claims to this end. First, having a thought involves tokening ‘symbols’ in your head and combining those symbols into well-formed symbolic expressions according to language-like grammatical and semantic rules. Second, thinking is a computational process involving LOT symbols and symbolic expressions. Third, the semantic value of an LOT symbol is determined by it standing in a naturalistic causal or nomic ‘locking’ relation to entities in the world.</p>
<p>Schneider says that Fodor’s version of LOT faces three challenges:</p>
<ol type="1">
<li>Central reasoning is not a computational process</li>
<li>The notion of an LOT symbol is unclear</li>
<li>LOT is unable to handle Frege cases</li>
</ol>
<p>In this review, I will describe the three challenges and Schneider’s proposed solution. As will become clear, I don’t entirely agree with everything Schneider says. Especially with respect to her answer to (2), I think that her version of LOT incurs costs that should lead us to question it. But notwithstanding this, my overall impression of her book is a positive one. Her book will undoubtedly set the agenda for future work on LOT. It places the often ignored problem of the nature of LOT symbols at the centre of the LOT debate and it shows how solutions to this problem reach out and touch many other aspects of the theory. The quality of scholarship and writing is high throughout. Unusually for a philosophy monograph, it is also fun to read.</p>
<h1 id="central-reasoning-is-not-computational"><span class="header-section-number">2</span> Central reasoning is not computational</h1>
<p>Fodor famously argued against LOT as a theory of central reasoning. Fodor defined central reasoning as non-demonstrative reasoning that is sensitive to all (or nearly all) of one’s beliefs. Central reasoning is meant to cover processes such as how we revise our beliefs in light of evidence, how we make inductive inferences, and how we construct practical plans to achieve our goals. According to Fodor, two problems stop LOT from being able to account for central reasoning: the globality problem and the relevance problem.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>First, the globality problem. Fodor said that certain properties of individual representations – their simplicity, centrality, and conservativeness – are ‘global’ in the sense that these properties vary with the surrounding context; they are not intrinsic to the representations of which they are predicated. Sometimes adding a certain belief to one’s belief set will complicate a plan; sometimes it will simplify it. A belief’s ‘simplicity’ does not supervene on the belief’s intrinsic properties. Therefore, it does not supervene on a belief’s syntactic properties. Computational processes are sensitive only to syntactic properties. So, says Fodor, reasoning that requires sensitivity to global properties cannot be a computational process, and thus falls outside the remit of LOT.</p>
<p>Schneider, in a chapter co-written with Kirk Ludwig, responds that a computer is not just sensitive to the syntax of individual representations taken singly. A computer is also sensitive to syntactic relations between representations: how a representation’s syntax relates to the syntax of other representations and how these relate to the system’s general rules of syntactic processing. The failure of an individual representation’s simplicity to supervene on its own syntax does not mean that the representation’s simplicity cannot be tracked by a computational process. Simplicity may supervene on (and be computationally tracked by following) syntactic interactions between representations. It is worth noting that <span class="citation" data-cites="Fodor00">Fodor (2000)</span> considers this possibility too in a view he labels M(CTM). However, he argues that this solution would run into the relevance problem, shifting attention to the other part of his argument.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The relevance problem arises because central reasoning has access to a large number of representations: potentially all of the system’s beliefs, desires, and thoughts. Any one of these could be relevant to the system’s reasoning about any given case, but usually only a few are. The human central reasoning system tends to focus on just those representations that are relevant to the agent’s current goals, plans, and context. How does it know <em>which</em> representations are relevant without doing an exhaustive, impracticable search through its entire database? Fodor says we do not know of any computational process that would solve this problem. (We don’t know of any non-computational process either, but never mind that.) He says that the difficulty of the relevance problem explains our failure to produce a computer with artificial general intelligence (AGI). Successful AI systems tend to excel at narrowly defined tasks (like playing Go or detecting your face), but they do not show general intelligence: they are poor at pulling together relevant pieces of information from disparate sources to make plans outside their narrowly defined area of competence.</p>
<p>Building on work by <span class="citation" data-cites="ShanahanBaars05">Shanahan and Baars (2005)</span>, Schneider argues that a solution to the relevance problem can be found within Global Workspace Theory (GWT).<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> GWT says that multiple ‘specialist’ cognitive processes compete for access to a global cognitive ‘workspace’. If granted access, the information a specialist has to offer is ‘broadcast’ back to the set of specialists. Access to the global workspace is controlled by ‘attention-like’ processes. The contents of the global workspace unfold in a largely serial manner over time. Schneider identifies the serial unfolding with central reasoning, and she argues that the relevance problem is solved by the ceaseless parallel work of the specialists.</p>
<p>I am not convinced by this solution. GWT describes a functional architecture – and in the case of its neuronal version, an anatomical architecture – that the brain could use to share and manage information. In this respect, GWT pertains to <em>part</em> of the relevance problem: in order to bring information to bear in central reasoning there must be channels to share and manage information. But, and it is an important but, GWT does not say how traffic along those channels is regulated to guarantee relevance. It does not explain how relevant, and typically only relevant, information is shepherded into the global workspace. Shanahan and Baars don’t attempt to explain this, and neither does more neurally orientated GWT work. The answer cannot be bottom-up pressure from the specialists (for there is no reason to think that the specialist who shouts loudest contains relevant information); it also cannot be top-down selection by some executive process (for that would introduce the relevance problem for the executive process). How then does the reasoning system ensure that only relevant information filters into the global workspace? If the answer is ‘attention’, what mechanism keeps attention aligned to what is relevant to the system in the current context? <span class="citation" data-cites="BaarsFranklin03">Baars and Franklin (2003)</span> describe interplay between ‘executive functions’, ‘specialist networks’, and ‘attention codelets’ that controls access of relevant information to the global workspace. Unfortunately, how these components actually work to track relevance is left largely unspecified. A computational solution to the relevance problem may be compatible with GWT; but GWT, as it currently stands, is largely silent about how relevance is computed.</p>
<p>What would it take to find a computational solution to the relevance problem? Fodor pegs this to our ability to build an AGI system. Schneider disagrees: she says this sets the bar too high. I do not think so. Building a computational model that can engage in non-demonstrative reasoning shows that we know how to solve the relevance problem; that we <em>really</em> know how to solve it and not just off-load the hard parts to an unexplained part of the model (‘executive function’, ‘attention’). Building a computational model capable of non-demonstrative inference is the hallmark that a computational solution to the relevance problem is found.</p>
<p>Fodor argued we will never do this and he cited a long history of past failure to create AGI as support for his view. However, past failure is only a guide to the future if the computational processes explored so far are representative of those that we will discover in the future. Fodor’s confidence in this strikes me as unfounded. Schneider may overreach when she says that GWT already solves the relevance problem, but her overall strategy – promoting the opportunities offered by novel computational processes – strikes me as fundamentally correct. There are more possible computational processes than are dreamt of in Fodor’s philosophy (or than we can dream of today). GWT is one example, but there are many others. Deep Q-networks, completely unrelated to GWT, show promising elements of domain-general reasoning. A single deep Q-network can play 49 Atari computer games, often at super-human levels, switching its strategy depending on the game it plays <span class="citation" data-cites="MnihKavukcuoglu15">(Mnih et al. 2015)</span>. Significantly, the network is never told which game it is playing. It works this out for itself from the pattern of pixels it ‘sees’. The network pulls together, by itself, a plan relevant for playing the game in hand. This isn’t AGI or a solution to the relevance problem, but it’s a step in the right direction.</p>
<h1 id="what-is-a-lot-symbol"><span class="header-section-number">3</span> What is a LOT symbol?</h1>
<p>LOT explains thought and thinking in terms of LOT symbols. But what is an LOT symbol? If you look inside someone’s brain, you don’t see anything that looks like a symbol. How then should we understand LOT’s talk of symbols in the head? Schneider calls this question the ‘elephant in the room’ for LOT. In all his work on LOT, Fodor said little to assuage worries about this. He focused instead on arguing for benefits that would accrue once one posits LOT symbols, whatever they are.</p>
<p>If one is puzzled about some thing, a possible opening gambit is to substitute the question of what that thing is with a question about its individuation conditions. This is what Schneider does here. Her question becomes: When are two physical tokens – two brain states – of the same LOT symbol type?</p>
<p>Schneider discards two theories of LOT symbols before proposing her own.</p>
<p>The first theory she discards is a ‘semantic’ theory. A semantic theory of LOT symbols says that two physical tokens are of the same symbol type just in case they have the same semantic content. Schneider’s objection is that a semantic theory would conflict with LOT’s ambition to give a reductive, naturalistic theory of semantic content. LOT is committed to explaining the semantic content of LOT symbols in terms of naturalistic (causal or informational relations) relations between LOT symbols and the world. This reductive project won’t work if one of the players in the reductive base – LOT symbols – themselves depend on semantic content.</p>
<p>The second theory Schneider rejects is an ‘orthographic’ theory. An orthographic theory says that two physical tokens are of the same symbol type just in case they have the same ‘shape’. The ink marks on this page can be grouped into symbol types based on their physical shape. ‘Shape’ clearly means something different for LOT symbols than it does for ink marks – you don’t find neurons shaped like the letter ‘a’. Schneider rejects the orthographic theory because it fails to provide an account of this alternative notion of ‘shape’.</p>
<p>Schneider’s preferred theory is a ‘computational role’ theory of LOT symbols. This says that two physical tokens are of the same symbol type just in case they play the same computational role within the system. Schneider defines ‘playing the same computational role’ as the tokens being physically interchangeable without affecting the computation. Two physical tokens play the same computational role just in case one physical token can be swapped with the other without affecting any (actual or possible) computational transitions of the system. A key source of support for Schneider’s view comes from John Haugeland’s account of symbol systems like chess:</p>
<blockquote>
<p>Formal tokens are freely interchangeable if and only if they are the same type. Thus it doesn’t make any difference which white pawn goes on which white-pawn square; but switching a pawn with a rook or a white pawn with a black one could make a lot of difference. <span class="citation" data-cites="Haugeland85">(Haugeland 1985, 52)</span></p>
</blockquote>
<p>Schneider argues that tokens should be typed by their <em>total</em> computational role. That means that <em>any</em> change, no matter how small, to a system’s (actual or possible) computational transitions resulting from exchanging two of its physical tokens entails that those tokens are not of the same symbol type.</p>
<p>I will not describe the arguments Schneider gives to support her theory. Instead, I wish to flag two potential problems.</p>
<p>The first is that her theory (and Haugeland’s) does not appear to work for more complex computers such as modern electronic PCs. Inside a PC, physical tokens of the same symbol type vary enormously in their physical nature and they are rarely freely interchangeable. Conversely, physical tokens of different symbol types can sometimes be interchanged without affecting the computation at all. This is because modern PCs, unlike chess sets, keep track of changes in their physical tokens and adjust their physical processing accordingly. This strategy is called ‘virtualising’ the physical hardware. It occurs at multiple levels inside a PC.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> For example, suppose that a physical token of the symbol type ‘dog’ is tokened on my PC (maybe as part of my email message). Imagine that this physical token involves electrical activity in my PC’s physical RAM locations 132, 2342, and 4562. However, these locations, and this pattern of activity, are not somehow reserved for ‘dog’ tokens within the computation. Nanoseconds later, tokening ‘dog’ may involve electrical activity in different physical RAM locations, say, 32, 42, and 234. Now tokening ‘cat’ may involve electrical activity in the old physical RAM locations of 132, 2342, and 4562. The physical memory inside my computer is constantly being ‘physically remapped’ to optimise my computer’s performance. In such a context, using interchangeablity of physical tokens within the computation to individuate symbol types would be hopeless. Tokens that play the same total computational role are rarely freely physically exchangeable (‘dog’ now and ‘dog’ after a memory remap), and tokens that are freely exchangeable without affecting the computation may play different computational roles (‘dog’ now and ‘cat’ after a memory remap).</p>
<p>What is happening inside a modern PC is that physical tokens that fall under the same symbol type vary but the PC’s <em>physical</em> principles of manipulation vary accordingly to counterbalance the effect. The PC’s <em>formal</em> principles for manipulating symbol types (its algorithm) stays constant throughout.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Imagine that during a chess match the physical board were cut up into pieces and reorganised after every move but the physical principles governing movement of the pieces were changed correspondingly to accommodate this reorganisation: black’s king’s castle can now move to different squares and it may be symbolised by a horse-shaped piece, but it can attack, and be attacked by, the same formal pieces – the state of play in the match is unaltered. Only a lunatic would cut up their chess board during a chess match. But physical remapping is both adaptive and common in electronic PCs. One might expect brains to use similar virtualising tactics given their proven benefit in optimising performance with limited computing resources.</p>
<p>In summary, the first problem is that ‘same total computational role’ does not mean ‘physical interchangeability’, at least for computers that use virtualising strategies. The second problem is that Schneider’s account does not provide stable symbol types. She foreshadows this difficulty when she says that her proposal makes it hard for symbol types to be shared between different computers. You and I are not disposed to undergo exactly the same computational transitions when thinking about dogs, so we do not have the same LOT symbols (maybe you have DOG<sub>1</sub> and I have DOG<sub>2</sub>). In a footnote on page 130, Schneider says similar worries apply inside a single human being over time. She has in mind relatively slow changes in someone’s computational roles that would occur over their lifetime. However, the difficulty comes not from slow changes, but from short-term changes produced by learning.</p>
<p>The algorithms run by electronic PCs are normally fixed, either by their hardware or by the program they are given. But computers can also modify their algorithms. Machine learning is becoming common. Computers like AlphaGo modify their (hugely complicated) algorithms in many ways in response to learning data (either labelled examples of ‘good’ behaviour or reward/punishment signals). When learning occurs, a computer modifies its algorithm; total computational roles before and after learning are different. This creates a problem for Schneider’s account of symbol identity. She indexes symbol identity to a symbol’s total computational role, but this role changes across learning events. A change, even a small one, to a symbol’s computational role will ramify. Remember that any change, no matter how small, changes a symbol’s identity. Remember too that the computational role of a symbol includes not just the symbol’s actual transitions but also any possible computational transitions that it could undergo. A change induced by learning, even a small one which does not affect the actual processing of the symbol, is almost certain to affect some <em>possible</em> transition that the symbol could enter into – perhaps by affecting the computational roles of other symbols to which the symbol is related by possible computational transitions. Unless the system is so designed as to minimise all the computational relations between its symbols (and what would be the point of a computer like that?), small changes to computational role will percolate throughout the computational system, changing symbol identities in their wake. The upshot is that Schneider’s symbol types are unlikely to survive learning.</p>
<p>Brains are learning computers. Indeed, our brains appear to keep learning even when we are asleep <span class="citation" data-cites="ONeillPlaydellBouverie10 WarmsleyStickgold10">(O’Neill et al. 2010; Warmsley and Stickgold 2010)</span>. It seems reasonable to assume that computational roles inside the brain are not fixed but are constantly shifting, adapting to new information and trying out new computational strategies. In Schneider’s account, LOT symbol types disappear across these shifts. If LOT symbol types are so ephemeral, it is hard to see how appeal to them could do useful work in science or philosophy.</p>
<p>Science needs LOT symbols that are stable across learning. Recent work on LOT proposes that the brain’s learning algorithms perform probabilistic inference over LOT expressions <span class="citation" data-cites="PiantadosiTenenbaum16 PiantadosiJacobs16">(Piantadosi, Tenenbaum, and Goodman 2016; Piantadosi and Jacobs 2016)</span>. In order for such algorithms to work, it is crucial that the identity of LOT expressions remains fixed across changes to their computational role so that the learner can consistently explore a space of hypotheses. Learning algorithms need to be defined over stable symbol types that do not themselves change during learning. Interestingly, this empirical work tends to cite Feldman’s <span class="citation" data-cites="Feldman12">(2012)</span> account of LOT symbol identity, which takes a semantic, broadly referential, approach to what makes two (noisy, probabilistic) brain states of the same LOT symbol type. Schneider herself switches to a semantic way of individuating brain states when describing computational principles shared between different humans – according to her, this is a <em>non-computational</em> way of individuating states.</p>
<h1 id="concepts-and-frege-cases"><span class="header-section-number">4</span> Concepts and Frege cases</h1>
<p>LOT says that concepts are LOT symbols and that the semantic value of a concept is purely referential. LOT therefore appears then to have a problem with Frege cases: it cannot distinguish between co-referring concepts, at least on purely semantic grounds. Fodor’s solution to this problem is to say that concepts should be individuated by both their semantic properties and their syntactic properties <span class="citation" data-cites="Fodor08">(Fodor 2008, Ch. 3)</span>. CICERO and TULLY have the same semantic value, but they are distinct concepts because they involve two different LOT symbol types.</p>
<p>Schneider argues for essentially the same solution as Fodor, but she inserts her own theory of LOT symbol types. The result is a theory of concepts very different from what Fodor intended. Fodor called ‘pragmatism’ the claim that one’s concepts depend on one’s cognitive or behavioural capacities (including recognitional, classificatory, inferential capacities). For a pragmatist, to have the concept DUCK is to be able to recognise ducks, classify ducks versus non-ducks, and perform inferences about ducks. Fodor thought that pragmatism was ‘the defining catastrophe of analytic philosophy of language and philosophy of mind in the last half of the twentieth century’ <span class="citation" data-cites="Fodor05">(Fodor 2005, 73–74)</span>. According to Schneider’s theory of LOT symbols, a concept’s identity depends on its total computational role. This means that a concept’s identity depends on its role in recognition, classification, and inference. The upshot is that Schneider’s theory of LOT symbols commits LOT to Fodor’s hated pragmatism.</p>
<p>There is a delicious irony here, but should we accept Schneider’s theory of concepts? While not disputing her arguments, I would like to strike a note of caution. Schneider’s theory would make an agent’s concepts just as unstable as her LOT symbol types. She says that unchanging semantic (referential) content provides continuity across these changes. But an agent needs stable concepts, not just stable referents. In order for an agent’s inferences to be valid, the same concepts that appear in an agent’s conclusions need to appear in her premises. This won’t happen, or at least it is unlikely to happen, on Schneider’s view. Concepts that are tokened in a premise may not be around by the time the agent tokens her conclusion. If an agent were to learn just one new thing between tokening her premises and tokening her conclusion, her inference would be invalid as her concepts would have changed. The purpose of LOT is to mechanise thought. Concepts need to be stable for this: they need to hang around long enough for an agent to use them multiple times. Individuating concepts by their total computational role makes concepts too unstable and it does not allow LOT to achieve its goal.</p>
<h1 id="conclusion"><span class="header-section-number">5</span> Conclusion</h1>
<p>This book throws into relief the difficulty, and importance, of the question of individuating LOT symbols. <em>Contra</em> Schneider, my instinct is to give a semantic answer to this question. Unlike her, I’m not worried about presupposing semantic content in an account of LOT symbols. I think that reductive, naturalistic accounts of semantics already face more serious problems than a semantically inflected notion of symbols. There are also good reasons to decouple LOT from the project of finding a reductive, naturalistic theory of content. LOT may be true and useful independent of the fate of the naturalisation project. Indeed, cognitive scientists who use LOT do not care much for this naturalising project at all.</p>
<p>Schneider’s book advances the debate on LOT. She updates the theory by integrating considerations as diverse as neurocomputational models and neo-Russellianism about names. Her book wears its learning lightly, engaging the reader with simple examples and clearly motivated considerations. Whether you end up agreeing with all its claims or not, I would encourage you to buy and read it.</p>
<h1 id="bibliography" class="unnumbered">Bibliography</h1>
<div id="refs" class="references">
<div id="ref-BaarsFranklin03">
<p>Baars, B., and S. Franklin. 2003. “How Conscious Experience and Working Memory Interact.” <em>Trends in Cognitive Sciences</em> 7: 166–72.</p>
</div>
<div id="ref-DehaeneChangeux04">
<p>Dehaene, S., and J.-P. Changeux. 2004. “Neural Mechanisms for Access to Consciousness.” In <em>The Cognitive Neurosciences, III</em>, edited by M. Gazzaniga, 1145–57. Cambridge, MA: MIT Press.</p>
</div>
<div id="ref-Feldman12">
<p>Feldman, J. 2012. “Symbolic Representation of Probabilistic Worlds.” <em>Cognition</em> 123: 61–83.</p>
</div>
<div id="ref-Fodor75">
<p>Fodor, J. A. 1975. <em>The Language of Thought</em>. Cambridge, MA: Havard University Press.</p>
</div>
<div id="ref-Fodor00">
<p>———. 2000. <em>The Mind Doesn’t Work That Way</em>. Cambridge, MA: MIT Press.</p>
</div>
<div id="ref-Fodor05">
<p>———. 2005. <em>Hume Variations</em>. Oxford: Oxford University Press.</p>
</div>
<div id="ref-Fodor08">
<p>———. 2008. <em>LOT2: The Language of Thought Revisited</em>. Oxford: Oxford University Press.</p>
</div>
<div id="ref-Haugeland85">
<p>Haugeland, J. 1985. <em>Artificial Intelligence: The Very Idea</em>. Cambridge, MA: MIT Press.</p>
</div>
<div id="ref-HennessyPatterson11">
<p>Hennessy, J. L., and D. A. Patterson. 2011. <em>Computer Organization and Design: The Hardware/Software Interface</em>. 4th ed. Waltham, MA: Morgan Kaufmann.</p>
</div>
<div id="ref-MnihKavukcuoglu15">
<p>Mnih, V., K. Kavukcuoglu, D. Silver, A. Rusu, J. Veness, M. G. Bellemare, A. Graves, et al. 2015. “Human-Level Control Through Deep Reinforcement Learning.” <em>Nature</em> 518: 529–33.</p>
</div>
<div id="ref-ONeillPlaydellBouverie10">
<p>O’Neill, J., B. Playdell-Bouverie, D. Dupret, and J. Csicsvari. 2010. “Play It Again: Reactivation of Waking Experience and Memory.” <em>Trends in Neurosciences</em> 33 (220–229).</p>
</div>
<div id="ref-PiantadosiJacobs16">
<p>Piantadosi, S. T., and R. A. Jacobs. 2016. “Four Problems Solved by the Probabilistic Language of Thought.” <em>Current Directions in Psychological Science</em> 25: 54–59.</p>
</div>
<div id="ref-PiantadosiTenenbaum16">
<p>Piantadosi, S. T., J. B. Tenenbaum, and N. D. Goodman. 2016. “The Logical Primitives of Thought: Empirical Foundations for Compositional Cognitive Models.” <em>Psychological Review</em> 123: 392–424.</p>
</div>
<div id="ref-Samuels10">
<p>Samuels, R. 2010. “Classical Computationalism and the Many Problems of Cognitive Relevance.” <em>Studies in History and Philosophy of Science</em> 41: 280–93.</p>
</div>
<div id="ref-Shanahan97">
<p>Shanahan, M. 1997. <em>Solving the Frame Problem</em>. Cambridge, MA: Bradford Books, MIT Press.</p>
</div>
<div id="ref-ShanahanBaars05">
<p>Shanahan, M., and B. Baars. 2005. “Applying Global Workspace Theory to the Frame Problem.” <em>Cognition</em> 98: 157–76.</p>
</div>
<div id="ref-WarmsleyStickgold10">
<p>Warmsley, E. J., and R. Stickgold. 2010. “Dreaming and Offline Memory Processing.” <em>Current Biology</em> 20: R1010–R1013.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>These are sometimes misleadingly called the ‘frame problem’. See <span class="citation" data-cites="Shanahan97">Shanahan (1997)</span> for a description of the frame problem.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>See <span class="citation" data-cites="Samuels10">Samuels (2010)</span> for a helpful reconstruction and criticism of Fodor’s argument here.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Schneider also discusses its neuronal implementation, the Global Neuronal Workspace Theory <span class="citation" data-cites="DehaeneChangeux04">(Dehaene and Changeux 2004)</span>.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>See <span class="citation" data-cites="HennessyPatterson11">Hennessy and Patterson (2011)</span>, Ch. 5. Virtualisation reaches its height with cloud-based computers such as those offered by Amazon Web Services.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>Later, I consider cases in which the algorithm changes too.<a href="#fnref5" class="footnote-back">↩</a></p></li>
</ol>
</section>
</div>

                        </div>
                        
                    </div>

                </div>

                <div class="col col-4">     
                    <div class="hide-print hide-sm">
                        
                        
                        <h1 style="margin-top: 0px;">Contents</h1>
                        <ul class="unstyled">
                            
                            <li>
                                
                                <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#introduction"><span style="font-size: 14px;">1 &nbsp; Introduction</span></a>
                                
                            </li>
                            
                            <li>
                                
                                <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#central-reasoning-is-not-computational"><span style="font-size: 14px;">2 &nbsp; Central reasoning is not computational</span></a>
                                
                            </li>
                            
                            <li>
                                
                                <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#what-is-a-lot-symbol"><span style="font-size: 14px;">3 &nbsp; What is a LOT symbol?</span></a>
                                
                            </li>
                            
                            <li>
                                
                                <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#concepts-and-frege-cases"><span style="font-size: 14px;">4 &nbsp; Concepts and Frege cases</span></a>
                                
                            </li>
                            
                            <li>
                                
                                <a href="http://marksprevak.com/publications/review-of-the-language-of-thought-a-new-philosophical-direction-by-susan-schneider/#conclusion"><span style="font-size: 14px;">5 &nbsp; Conclusion</span></a>
                                
                            </li>
                            
                        </ul>
                        
                    </div>
                </div>

            </div>

        </div>

        
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-600543-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 
        'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();

(function(){var j=function(a,b){return window.getComputedStyle?getComputedStyle(a).getPropertyValue(b):a.currentStyle[b]};var k=function(a,b,c){if(a.addEventListener)a.addEventListener(b,c,false);else a.attachEvent('on'+b,c)};var l=function(a,b){for(key in b)if(b.hasOwnProperty(key))a[key]=b[key];return a};window.fitText=function(d,e,f){var g=l({'minFontSize':-1/0,'maxFontSize':1/0},f);var h=function(a){var b=e||1;var c=function(){a.style.fontSize=Math.max(Math.min(a.clientWidth/(b*10),parseFloat(g.maxFontSize)),parseFloat(g.minFontSize))+'px'};c();k(window,'resize',c)};if(d.length)for(var i=0;i<d.length;i++)h(d[i]);else h(d);return d}})();
fitText(document.getElementById('title'), 1)

</script>

    </body>
</html>
